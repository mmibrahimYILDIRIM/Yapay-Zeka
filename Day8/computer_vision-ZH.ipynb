{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5eVVFxTLpVGb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from opencv-python) (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\ibrahim\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\ibrahim\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\ibrahim\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\ibrahim\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\ibrahim\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\ibrahim\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\ibrahim\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\ibrahim\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\ibrahim\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\ibrahim\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\ibrahim\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\ibrahim\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HUvNtKu2pVGc"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HjRuzl8_pVGd"
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:973: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_126396\\3445982843.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minput_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"input_1.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Hello world\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:973: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "input_1 = cv2.imread(\"input_1.jpg\")\n",
    "cv2.imshow(\"Hello world\",input_1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bh72eu4CpVGd",
    "outputId": "499fda21-76e1-4972-cd7c-5d63d295464e"
   },
   "outputs": [],
   "source": [
    "print ('Heiht of image', int(input_1.shape[0]),'pixels')\n",
    "print ('Width of image', int(input_1.shape[1]),'pixels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSGIkx0YpVGe",
    "outputId": "849843dd-8e5d-4e00-ed2c-f514bb0dc43d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "checkBoard = np.zeros((9,9))\n",
    "checkBoard[0::2,1::2]=1\n",
    "checkBoard[1::2,0::2]=1\n",
    "print(checkBoard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54qCG1WkpVGf"
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5HSW1r3pVGf",
    "outputId": "e69131f8-2a60-49de-8657-8de464a51ee2"
   },
   "outputs": [],
   "source": [
    "plt.imshow(checkBoard,cmap=\"gray\",interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sNP5_ZETpVGf",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "f93637b1-f5c8-46a3-cfb9-15ec12e19d05"
   },
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "image_of_a_bush = data.lfw_subset()\n",
    "image_of_a_bush = image_of_a_bush[0,:,:]\n",
    "print(image_of_a_bush)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ZO6hIuvpVGg",
    "outputId": "be06ed26-75ca-4c83-8a82-e8f6d1a3e684"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(image_of_a_bush,cmap=\"gray\",interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "66WXO4G2pVGg",
    "outputId": "004d5e55-f2ec-4764-997f-a1df952d8ffc"
   },
   "outputs": [],
   "source": [
    "image = data.astronaut()\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nx-jMk6EpVGh"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"input_1.jpg\")\n",
    "cv2.imshow(\"Original\",image)\n",
    "cv2.waitKey()\n",
    "\n",
    "gray_image= cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Grayscale\",gray_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CxUEaEZupVGh"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"input_1.jpg\",0)\n",
    "cv2.imshow(\"Grayscale\",img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U5DE2iqFpVGh",
    "outputId": "db60374b-6b9a-4575-805d-61cea13889da"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"input.jpg\")\n",
    "B,G,R = image[0,0]\n",
    "B,G,R = image[10,50]\n",
    "print(B,G,R)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jGJDcBkupVGi",
    "outputId": "9452ee4d-f985-4a77-ccad-90ae7e67718f"
   },
   "outputs": [],
   "source": [
    "gray_img = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "print(gray_img.shape)\n",
    "print(gray_img[10,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lWvnhvzpVGi",
    "outputId": "0b356b3b-0989-49e9-c627-d86c5258712d"
   },
   "outputs": [],
   "source": [
    "gray_img[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "spdthWb0pVGi"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"input.jpg\")\n",
    "hsv_image = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "cv2.imshow(\"HSV image\",hsv_image[:,:,:])\n",
    "cv2.imshow(\"Hue channel\",hsv_image[:,:,0])\n",
    "cv2.imshow(\"Saturation channel\",hsv_image[:,:,1])\n",
    "cv2.imshow(\"Calue channel\",hsv_image[:,:,2])\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EJUOMHEOpVGi",
    "outputId": "52e1736b-f406-4cde-f32c-be5c8f07c579"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"input_1.jpg\")\n",
    "B,G,R =cv2.split(image)\n",
    "print(B.shape)\n",
    "cv2.imshow(\"Red\",R)\n",
    "cv2.imshow(\"Green\",G)\n",
    "cv2.imshow(\"Blue\",B)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "merged = cv2.merge([B,G,R])\n",
    "cv2.imshow(\"Merged\",merged)\n",
    "merged= cv2.merge([B+100,G,R+100])\n",
    "cv2.imshow(\"Merged with Blue Amplified\",merged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XcQvJ1DpVGi"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('input.jpg')\n",
    "\n",
    "height,width = image.shape[:2]\n",
    "\n",
    "quareter_height,quareter_width = height/4,width/4\n",
    "\n",
    "T = np.float32([[1,0,quareter_width],[0,1,quareter_height]])\n",
    "\n",
    "img_translation = cv2.warpAffine(image,T,(width,height))\n",
    "cv2.imshow('Translation',img_translation)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_JtZgEoDpVGj"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('input.jpg')\n",
    "\n",
    "height,width = image.shape[:2]\n",
    "\n",
    "rotation_matrix = cv2.getRotationMatrix2D((width/2,height/2),45,.5)\n",
    "\n",
    "rotated_image = cv2.warpAffine(image,rotation_matrix,(width,height))\n",
    "\n",
    "cv2.imshow('Rotated Image',rotated_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wkc8sfQopVGj"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('input_1.jpg',0)\n",
    "\n",
    "height,width = image.shape[:2]\n",
    "\n",
    "sobel_x = cv2.Sobel(image,cv2.CV_64F,0,1,ksize = 5)\n",
    "sobel_y = cv2.Sobel(image,cv2.CV_64F,1,0,ksize = 5)\n",
    "\n",
    "cv2.imshow('Rotated Image',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Sobel X',sobel_x)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Sobel Y',sobel_y)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "sobel_OR = cv2.bitwise_or(sobel_x,sobel_y)\n",
    "cv2.imshow('sobel_OR',sobel_OR)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "laplacian = cv2.Laplacian(image,cv2.CV_64F)\n",
    "cv2.imshow('Laplacian',laplacian)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "canny = cv2.Canny(image,50,120)\n",
    "cv2.imshow('Canny',canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-IbFQdKpVGj",
    "outputId": "00b5bd8f-c326-4c53-8317-59a3ebae7b45"
   },
   "outputs": [],
   "source": [
    "def sketch(image):\n",
    "    img_gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    img_gray_blur = cv2.GaussianBlur(img_gray,(5,5),0)\n",
    "    canny_edges = cv2.Canny(img_gray_blur,10,70)\n",
    "    ret,mask = cv2.threshold(canny_edges,250,255,cv2.THRESH_BINARY_INV)\n",
    "    return mask\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    cv2.imshow('Our live Sketcher',sketch(frame))\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MFVCDZQfpVGk"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"WaldoBeach.jpg\")\n",
    "\n",
    "cv2.imshow(\"Where is Waldo\",image)\n",
    "cv2.waitKey(0)\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "template = cv2.imread(\"waldo.jpg\",0)\n",
    "\n",
    "result = cv2.matchTemplate(gray,template,cv2.TM_CCOEFF)\n",
    "minVal,maxVal,minLoc,maxLoc = cv2.minMaxLoc(result)\n",
    "\n",
    "top_left = maxLoc\n",
    "bottom_right =(top_left[0] + 50, top_left[1]+50)\n",
    "cv2.rectangle(image,top_left,bottom_right,(0,0,255),5)\n",
    "\n",
    "cv2.imshow(\"Where is Waldo\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8kjuqaXpVGk",
    "outputId": "351bfa5e-b9f3-4665-a999-cebc0d240095"
   },
   "outputs": [],
   "source": [
    "plt.imshow(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-S7xojNpVGk"
   },
   "outputs": [],
   "source": [
    "import imutils\n",
    "image = cv2.imread(\"input_1.jpg\")\n",
    "cv2.imshow(\"Original\",image)\n",
    "\n",
    "flipped = cv2.flip(image,0)\n",
    "cv2.imshow(\"Vertical Flip\",flipped)\n",
    "\n",
    "flipped = cv2.flip(image,1)\n",
    "cv2.imshow(\"Horizontal Flip\",flipped)\n",
    "\n",
    "flipped = cv2.flip(image,-1)\n",
    "cv2.imshow(\"Bot Flip\",flipped)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4AJo20JmpVGk"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"airplanes.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret,frame= cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow(\"Demo\",frame)\n",
    "    else:\n",
    "        break\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qeOMBFaJpVGk"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,frame= cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow(\"Bendeniz\",frame)\n",
    "    else:\n",
    "        break\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQe_kvw2pVGk"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret1,frame1 = cap.read()\n",
    "ret2,frame2 = cap.read()\n",
    "\n",
    "while True:\n",
    "    frame1_gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    frame2_gray = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    frame1_blur = cv2.GaussianBlur(frame1_gray,(21,21),0)\n",
    "    frame2_blur = cv2.GaussianBlur(frame2_gray,(21,21),0)\n",
    "\n",
    "    diff = cv2.absdiff(frame1_blur,frame2_blur)\n",
    "    cv2.imshow(\"Motion\",diff)\n",
    "    frame1 = frame2\n",
    "    ret,frame2 = cap.read()\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        break\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == ord(\"q\"):\n",
    "        cap.release()\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGc9tGiApVGl"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"cars.mp4\")\n",
    "\n",
    "ret1,frame1 = cap.read()\n",
    "ret2,frame2 = cap.read()\n",
    "\n",
    "while True:\n",
    "    frame1_gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    frame2_gray = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    frame1_blur = cv2.GaussianBlur(frame1_gray,(21,21),0)\n",
    "    frame2_blur = cv2.GaussianBlur(frame2_gray,(21,21),0)\n",
    "\n",
    "    diff = cv2.absdiff(frame1_blur,frame2_blur)\n",
    "    cv2.imshow(\"Motion\",diff)\n",
    "    frame1 = frame2\n",
    "    ret,frame2 = cap.read()\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        break\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == ord(\"q\"):\n",
    "        cap.release()\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1pVos3M0pVGl"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"airplanes.mp4\")\n",
    "\n",
    "ret1,frame1 = cap.read()\n",
    "ret2,frame2 = cap.read()\n",
    "\n",
    "while True:\n",
    "    frame1_gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    frame2_gray = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    frame1_blur = cv2.GaussianBlur(frame1_gray,(21,21),0)\n",
    "    frame2_blur = cv2.GaussianBlur(frame2_gray,(21,21),0)\n",
    "\n",
    "    diff = cv2.absdiff(frame1_blur,frame2_blur)\n",
    "    cv2.imshow(\"Motion\",diff)\n",
    "    frame1 = frame2\n",
    "    ret,frame2 = cap.read()\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        break\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == ord(\"q\"):\n",
    "        cap.release()\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z8lAUuLDpVGl"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"airplanes.mp4\")\n",
    "\n",
    "ret1,frame1 = cap.read()\n",
    "ret2,frame2 = cap.read()\n",
    "\n",
    "while True:\n",
    "    frame1_gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    frame2_gray = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    frame1_blur = cv2.GaussianBlur(frame1_gray,(21,21),0)\n",
    "    frame2_blur = cv2.GaussianBlur(frame2_gray,(21,21),0)\n",
    "\n",
    "    diff = cv2.absdiff(frame1_blur,frame2_blur)\n",
    "\n",
    "    thresh = cv2.threshold(diff,20,255,cv2.THRESH_BINARY)[1]\n",
    "    final = cv2.dilate(thresh,None,iterations=2)\n",
    "\n",
    "    masked = cv2.bitwise_and(frame1,frame1,mask=thresh)\n",
    "    white_pixels = np.sum(thresh) /255\n",
    "\n",
    "    rows,cols = thresh.shape\n",
    "    total= rows*cols\n",
    "    if white_pixels > 0.01*total:\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame1,\"Movement Detected - Hareket Var\",(10,50),font,1,(0,0,255),2,cv2.LINE_AA)\n",
    "    cv2.imshow(\"Motion\",frame1)\n",
    "    frame1=frame2\n",
    "    ret,frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == 27 or key == ord(\"q\"):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zlPQreyTpVGl",
    "outputId": "bfa57b7f-f2ff-425f-9be4-4dddf72228a9"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"bunchofshapes.jpg\")\n",
    "cv2.imshow(\"Input Image\",image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "edged = cv2.Canny(gray,30,200)\n",
    "cv2.imshow(\"Canny Edges\",edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "contours,hierarchy = cv2.findContours(edged,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "cv2.imshow(\"Canny Edges After Contouring\",edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(\"Number of Contours found = \" + str(len(contours)))\n",
    "\n",
    "cv2.drawContours(image,contours,-1,(0,255,0),thickness=2)\n",
    "\n",
    "cv2.imshow(\"Contours\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTMU12WMpVGl",
    "outputId": "e7caba2c-5ac2-4ce7-8b8e-1ebf8154427f"
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.imread(\"bunchofshapes.jpg\",0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dtlsFOWFpVGm"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('soduku.jpg')\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "# Grayscale and Canny Edges extracted\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 100, 170, apertureSize = 3)\n",
    "\n",
    "# Run HoughLines using a rho accuracy of 1 pixel\n",
    "# theta accuracy of np.pi / 180 which is 1 degree\n",
    "# Our line threshold is set to 240 (number of points on line)\n",
    "lines = cv2.HoughLines(edges, 1, np.pi / 180, 240)\n",
    "\n",
    "# We iterate through each line and convert it to the format\n",
    "# required by cv2.lines (i.e. requiring end points)\n",
    "for line in lines:\n",
    "    rho, theta = line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a * rho\n",
    "    y0 = b * rho\n",
    "    x1 = int(x0 + 1000 * (-b))\n",
    "    y1 = int(y0 + 1000 * (a))\n",
    "    x2 = int(x0 - 1000 * (-b))\n",
    "    y2 = int(y0 - 1000 * (a))\n",
    "    cv2.line(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow('Hough Lines', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NB2hvPeNpVGm"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('opencv.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blur = cv2.medianBlur(gray, 5)\n",
    "\n",
    "circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1.5, 20)\n",
    "\n",
    "circles = np.uint16(np.around(circles))\n",
    "\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv2.circle(image,(i[0], i[1]), i[2], (0, 255, 0), 2)\n",
    "\n",
    "    # draw the center of the circle\n",
    "    cv2.circle(image, (i[0], i[1]), 2, (0, 255, 0), 5)\n",
    "\n",
    "cv2.imshow('detected circles', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WpSJmpxApVGm"
   },
   "outputs": [],
   "source": [
    "# Read image\n",
    "image = cv2.imread(\"Sunflowers.jpg\")\n",
    "\n",
    "# Set up the detector with default par ameters.\n",
    "detector =cv2.SimpleBlobDetector_create()\n",
    "\n",
    "# Detect blobs.\n",
    "keypoints = detector.detect(image)\n",
    "\n",
    "# Draw detected blobs as red circles.\n",
    "# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of\n",
    "# the circle corresponds to the size of blob\n",
    "blank = np.zeros((1,1))\n",
    "blobs = cv2.drawKeypoints(image, keypoints, blank, (255,0,0),\n",
    "                                      cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    "\n",
    "# Show keypoints\n",
    "cv2.imshow(\"Blobs\", blobs)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzBZINgvpVGn"
   },
   "outputs": [],
   "source": [
    "# Read image\n",
    "image = cv2.imread(\"Sunflowers.jpg\")\n",
    "\n",
    "# Set up the detector with default par ameters.\n",
    "detector =cv2.SimpleBlobDetector_create()\n",
    "\n",
    "# Detect blobs.\n",
    "keypoints = detector.detect(image)\n",
    "\n",
    "# Draw detected blobs as red circles.\n",
    "# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of\n",
    "# the circle corresponds to the size of blob\n",
    "blank = np.zeros((1,1))\n",
    "blobs = cv2.drawKeypoints(image, keypoints, blank, (255,0,0),\n",
    "                                      cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    "\n",
    "# Show keypoints\n",
    "cv2.imshow(\"Blobs\", blobs)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "660ZBSGQpVGn",
    "outputId": "589b1696-9fa1-46ad-cb49-1daf4e197e62"
   },
   "outputs": [],
   "source": [
    "\n",
    "# classifier (XML file format) is stored\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load our image then convert it to grayscale\n",
    "image = cv2.imread('myself.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Our classifier returns the ROI of the detected face as a tuple\n",
    "# It stores the top left coordinate and the bottom right coordiantes\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "# When no faces detected, face_classifier returns and empty tuple\n",
    "if faces is ():\n",
    "    print(\"No faces found\")\n",
    "\n",
    "# We iterate through our faces array and draw a rectangle\n",
    "# over each face in faces\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image, (x,y), (x+w,y+h), (127,0,255), 2)\n",
    "    cv2.imshow('Face Detection', image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtomYqnxpVGn",
    "outputId": "a348ce99-6ff7-48ba-efdb-9822214945e7"
   },
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "img = cv2.imread('myself.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "# When no faces detected, face_classifier returns and empty tuple\n",
    "if faces is ():\n",
    "    print(\"No Face Found\")\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(127,0,255),2)\n",
    "    cv2.imshow('img',img)\n",
    "    cv2.waitKey(0)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(255,255,0),2)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bgvwxQDfpVGn",
    "outputId": "112623a4-b6ef-4a7c-cda0-83b539582d8f"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "def face_detector(img, size=0.5):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img\n",
    "    for (x,y,w,h) in faces:\n",
    "        x = x - 50\n",
    "        w = w + 50\n",
    "        y = y - 50\n",
    "        h = h + 50\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "        sleep(.05)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,0,255),2)\n",
    "    img = cv2.flip(img,1)\n",
    "    return img\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Our Face Extractor', face_detector(frame))\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 224,
     "status": "ok",
     "timestamp": 1711573338458,
     "user": {
      "displayName": "Meltem Uçar",
      "userId": "06415093256480859049"
     },
     "user_tz": 360
    },
    "id": "wMqW0ro-pVGn"
   },
   "outputs": [],
   "source": [
    "#pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQZYruJrpVGo",
    "outputId": "dc80359a-0731-44c6-868f-66fd98fd1554"
   },
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "def face_extractor(img):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    if faces is ():\n",
    "        return None\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h,x:x+w]\n",
    "    return cropped_face\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame),(200,200))\n",
    "        face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        file_name_path = './faces/user/' + str(count) +'.jpg'\n",
    "        cv2.imwrite(file_name_path,face)\n",
    "        cv2.putText(face,str(count),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "        cv2.imshow(\"Face Cropper\",face)\n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "    if cv2.waitKey(1) == 13 or count ==100:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('Collecting Samples Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "avTpmEk0pVGo",
    "outputId": "c04e2241-fcd6-48a2-b495-51c239a94b1c"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "\n",
    "data_path = './faces/user/'\n",
    "onlyfiles =[f for f in listdir(data_path) if isfile(join(data_path,f))]\n",
    "\n",
    "Training_Data,Labels = [],[]\n",
    "\n",
    "for i,files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images,dtype = np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "Labels = np.asarray(Labels,dtype = np.int32)\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "model.train(np.asarray(Training_Data),np.asarray(Labels))\n",
    "print(\"Model Trained Succesfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j6QTvwjIpVGo",
    "outputId": "34c747a7-2dd3-4d4d-ddc7-3b70bc24249f"
   },
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "def face_extractor(img, size = 0.5):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    if faces is ():\n",
    "        return img,[]\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi,(200,200))\n",
    "    return img,roi\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    image,face = face_extractor(frame)\n",
    "    try:\n",
    "        face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        results = model.predict(face)\n",
    "        if results[1]<500:\n",
    "            confidence = int(100 * (1-(results[1])/400))\n",
    "            display_string = str(confidence) + '% sure this guy is myself'\n",
    "        cv2.putText(image,display_string,(100,120),cv2.FONT_HERSHEY_COMPLEX,1,(255,120,150),2)\n",
    "        if confidence > 75:\n",
    "            cv2.putText(image,\"Unlocked\" ,(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            cv2.imshow(\"Face Recognition\",image)\n",
    "        else:\n",
    "            cv2.putText(image,\"Locked\" ,(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "            cv2.imshow(\"Face Recognition\",image)\n",
    "    except:\n",
    "        cv2.putText(image,\"No Face Found\" ,(220,120),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "        cv2.putText(image,\"Locked\" ,(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "        cv2.imshow(\"Face Recognition\",image)\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        cap.release()\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXcvuNeLpVGo",
    "outputId": "4b52ed70-9629-4d7a-d597-8aaa3b22823c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Ry1ePvJpVGo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYObKLnwpVGp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
