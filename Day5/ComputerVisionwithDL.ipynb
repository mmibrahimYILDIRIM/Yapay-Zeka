{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eee0a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bunla şekil resim tanıtıp nerde görse o resmi tespit edecek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de35839c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bing-image-downloader\n",
      "  Downloading bing_image_downloader-1.1.2-py3-none-any.whl (5.9 kB)\n",
      "Installing collected packages: bing-image-downloader\n",
      "Successfully installed bing-image-downloader-1.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bing-image-downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f4dfcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bing_image_downloader import downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9894300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[%] Downloading Images to C:\\Users\\ibrahim\\Documents\\Yapay Zeka\\Day5\\dataset\\tire\n",
      "\n",
      "\n",
      "[!!]Indexing page: 1\n",
      "\n",
      "[%] Indexed 40 Images on Page 1.\n",
      "\n",
      "===============================================\n",
      "\n",
      "[%] Downloading Image #1 from https://www.bikesdirect.com/products/motobecane/images/monster_cross/images/tire.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #2 from https://s3-us-west-1.amazonaws.com/visual-aids/products/tires/continental/extremecontactdws06/continental_extremecontactdws06_bw_140843_vary.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #3 from https://tyreflow.com/wp-content/uploads/2022/05/Oldtire.jpg\n",
      "[!] Issue getting: https://tyreflow.com/wp-content/uploads/2022/05/Oldtire.jpg\n",
      "[!] Error:: Remote end closed connection without response\n",
      "[%] Downloading Image #3 from https://onlinetire.ae/wp-content/uploads/tyre-angle.jpeg\n",
      "[!] Issue getting: https://onlinetire.ae/wp-content/uploads/tyre-angle.jpeg\n",
      "[!] Error:: Remote end closed connection without response\n",
      "[%] Downloading Image #3 from https://imgkit.otelz.com/placeimages/turkey/izmir/tire_tire-sehir-merkezi-c6ff39.jpg?tr=w-600,h-315\n",
      "[Error]Invalid image, not saving https://imgkit.otelz.com/placeimages/turkey/izmir/tire_tire-sehir-merkezi-c6ff39.jpg?tr=w-600,h-315\n",
      "\n",
      "[!] Issue getting: https://imgkit.otelz.com/placeimages/turkey/izmir/tire_tire-sehir-merkezi-c6ff39.jpg?tr=w-600,h-315\n",
      "[!] Error:: Invalid image, not saving https://imgkit.otelz.com/placeimages/turkey/izmir/tire_tire-sehir-merkezi-c6ff39.jpg?tr=w-600,h-315\n",
      "\n",
      "[%] Downloading Image #3 from https://www.carnewscafe.com/wp-content/uploads/2014/12/tires.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #4 from https://images.squarespace-cdn.com/content/v1/5fa8805fbca79b7a702b3cb6/1606084341067-X2VWP72OGOABN6Z5RW93/tires.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #5 from https://www.goodyear.com/content/dam/gy-com/images/learn/tips/3-tires.png\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #6 from https://www.byways.org/wp-content/uploads/2023/05/TireSizes.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #7 from http://tireworx.ca/wp-content/uploads/2016/09/tire-sizes.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #8 from https://images.simpletire.com/image/upload/f_auto,w_3840,q_auto,fl_lossy/v1596149102/steer/seo/car_owner_manuals.png\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #9 from https://static2.3birdsmarketing.com/Clients/3BIRDSMARKETING/tiresizeonsidewall.jpeg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #10 from https://towing-san-jose.com/wp-content/uploads/2013/12/Tire-sizes-guide.jpeg\n",
      "[%] File Downloaded !\n",
      "\n",
      "\n",
      "\n",
      "[%] Done. Downloaded 10 images.\n"
     ]
    }
   ],
   "source": [
    "downloader.download('tire',limit=10,adult_filter_off=True)   # adult filter ile uygunsuz resimleri indirip indirmeme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e9dae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d00e4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist=tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0b158d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images,train_labels),(test_images,test_labels)=mnist.load_data()    # Yaklaşık 80000 resim indiriyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "273122e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d37733a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91cfc4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22ec1430a90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[61],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e257200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resmi nasıl normalize edeceğiz?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "775515ad",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0]  # Bilgisayar dilinde resimler üç boyutlu bir matris yani tensordur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf584102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d51ebb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=train_images/255.0    # Resimlerde değerler 0-255 arasında değerler alıyor 255 e bölerek normalize etmiş oluyoruz\n",
    "test_images=test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd4f9f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, InputLayer,Reshape,MaxPooling2D,Flatten,Dropout,BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64f8e78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(InputLayer(shape=(28,28)))    # Resimlerin boyutu 28-28 bir matris\n",
    "model.add(Reshape(target_shape=(28,28,1)))   \n",
    "model.add(Conv2D(filters=12,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10)) # 10 fakli cevap classification 0-9 a kadar olan rakamlar\n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3999571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.8524 - loss: 0.5365 - val_accuracy: 0.9582 - val_loss: 0.1618\n",
      "Epoch 2/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.9470 - loss: 0.1793 - val_accuracy: 0.9738 - val_loss: 0.0975\n",
      "Epoch 3/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.9687 - loss: 0.1125 - val_accuracy: 0.9782 - val_loss: 0.0787\n",
      "Epoch 4/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9758 - loss: 0.0853 - val_accuracy: 0.9830 - val_loss: 0.0662\n",
      "Epoch 5/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9809 - loss: 0.0676 - val_accuracy: 0.9840 - val_loss: 0.0616\n",
      "Epoch 6/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9833 - loss: 0.0577 - val_accuracy: 0.9810 - val_loss: 0.0600\n",
      "Epoch 7/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.9844 - loss: 0.0513 - val_accuracy: 0.9825 - val_loss: 0.0622\n",
      "Epoch 8/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9866 - loss: 0.0451 - val_accuracy: 0.9842 - val_loss: 0.0577\n",
      "Epoch 9/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.9871 - loss: 0.0420 - val_accuracy: 0.9808 - val_loss: 0.0614\n",
      "Epoch 10/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.9882 - loss: 0.0388 - val_accuracy: 0.9827 - val_loss: 0.0602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22ee7c16a60>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images,train_labels, validation_split=.10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d321d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9744 - loss: 0.0765\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy=model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "689c8d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9796000123023987"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44ab5d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('benimmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bb9a927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.7.1-cp39-cp39-win_amd64.whl (216.0 MB)\n",
      "     -------------------------------------- 216.0/216.0 MB 1.2 MB/s eta 0:00:00\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.1-cp39-cp39-win_amd64.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 1.1 MB/s eta 0:00:00\n",
      "Collecting sympy>=1.13.3\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "     ---------------------------------------- 6.3/6.3 MB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from torch) (2022.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Installing collected packages: sympy, torch, torchvision\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.10.1\n",
      "    Uninstalling sympy-1.10.1:\n",
      "      Successfully uninstalled sympy-1.10.1\n",
      "Successfully installed sympy-1.14.0 torch-2.7.1 torchvision-0.22.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "802f6dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.1070\n",
      "Epoch [2/10], Loss: 0.0441\n",
      "Epoch [3/10], Loss: 0.0144\n",
      "Epoch [4/10], Loss: 0.0620\n",
      "Epoch [5/10], Loss: 0.1411\n",
      "Epoch [6/10], Loss: 0.0709\n",
      "Epoch [7/10], Loss: 0.0361\n",
      "Epoch [8/10], Loss: 0.0020\n",
      "Epoch [9/10], Loss: 0.0047\n",
      "Epoch [10/10], Loss: 0.0375\n",
      "Accuracy of the model on the test images: 98.07%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Verilerin normalizasyonu ve yüklenmesi\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Modelin tanımlanması\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 12, kernel_size=3)  # Aktivasyon burada yok\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(12 * 13 * 13, 10)  # 28x28 -> 12x26 -> 12x13\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))  # Aktivasyon burada uygulanıyor\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 12 * 13 * 13)  # Düzleştir\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "# Model ve optimizer tanımlanması\n",
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Modelin eğitilmesi\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()  # Gradients sıfırlanıyor\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Modelin test edilmesi\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the model on the test images: {100 * correct / total:.2f}%')\n",
    "\n",
    "# Modelin kaydedilmesi\n",
    "torch.save(model.state_dict(), 'benimmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7697b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Burda yaptığımız şey modeli eğittik yeni bir el yazması yazarsak yüzde kaç doğrulukla bunu tanıyacak bunu belirledik.\n",
    "# Keras yazdığımız kodu poe de bunu torch olarak yaz diyerek çevirdik aynı kodu hem keras hemde torch ile yazmış olduk.\n",
    "# Bunlar DeepLearning modelleridir. Kreas ve Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1df712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
