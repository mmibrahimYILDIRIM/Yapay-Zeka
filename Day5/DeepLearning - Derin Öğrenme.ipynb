{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b257d71d",
   "metadata": {},
   "source": [
    "# Deep Learning - Yapay Sinir Ağları"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b739792",
   "metadata": {},
   "source": [
    "Bugün insan beyninin öğrenme modelini taklit ederek öğrenen yapay sinir ağlarını derinlemesine öğreneceğiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8b77cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorflow) (1.73.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.8)\n",
      "Collecting numpy<2.2.0,>=1.26.0\n",
      "  Using cached numpy-2.0.2-cp39-cp39-win_amd64.whl (15.9 MB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorflow) (63.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: namex in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: rich in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.9)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Erişim engellendi: 'C:\\\\Users\\\\ibrahim\\\\anaconda3\\\\Lib\\\\site-packages\\\\~-mpy\\\\.libs\\\\libopenblas64__v0.3.21-gcc_10_3_0.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368fa5b2",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26a12cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.1-cp39-cp39-win_amd64.whl (11.4 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.5.3\n",
      "    Uninstalling pandas-1.5.3:\n",
      "      Successfully uninstalled pandas-1.5.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Erişim engellendi: 'C:\\\\Users\\\\ibrahim\\\\anaconda3\\\\Lib\\\\site-packages\\\\~-ndas\\\\_libs\\\\algos.cp39-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade numpy pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9de9266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 2.0.2\n",
      "Uninstalling numpy-2.0.2:\n",
      "  Successfully uninstalled numpy-2.0.2\n",
      "Found existing installation: pandas 2.3.1\n",
      "Uninstalling pandas-2.3.1:\n",
      "  Successfully uninstalled pandas-2.3.1\n",
      "Collecting numpy==1.24.4\n",
      "  Using cached numpy-1.24.4-cp39-cp39-win_amd64.whl (14.9 MB)\n",
      "Collecting pandas==1.5.3\n",
      "  Using cached pandas-1.5.3-cp39-cp39-win_amd64.whl (10.9 MB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from pandas==1.5.3) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from pandas==1.5.3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ibrahim\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\n",
      "Installing collected packages: numpy, pandas\n",
      "Successfully installed numpy-1.24.4 pandas-1.5.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.24.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall numpy pandas -y\n",
    "!pip install numpy==1.24.4 pandas==1.5.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3169adcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "405288bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.13\n"
     ]
    }
   ],
   "source": [
    "!python --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e286716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f81d58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('pima-indians-diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e83ec929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b50b5063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()    # Datadaki her şey rakam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c21d440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pima kampında bulunan kızılderili kadınlara ait veriler Kaç kez hamile kaldı şekeri ne gibi outcome şeker hastası olup olmadığı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e23b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bir kişi şeker hastası mı değil mi sorusunun cevabı evet hayır olduğu için clustering örğeeni;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb368b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()    # Datada boş veri yok "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "954b258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53bcdb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e3cc8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('Outcome',axis=1)    # Outcome stününun silip x e eşitledik\n",
    "y=df[['Outcome']]      # y ye de Outcome stünunu eşitledik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc1e95b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  \n",
       "0                     0.627   50  \n",
       "1                     0.351   31  \n",
       "2                     0.672   32  \n",
       "3                     0.167   21  \n",
       "4                     2.288   33  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()    # Outcome silindiğini ve x e eşitlendiğini görebiliriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd071b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns    # Stün isimlerini görebiliriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e83f6bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "       'BMI', 'DiabetesPedigreeFunction', 'Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54ebde0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df[['Outcome']]    # Outcome hedef ve tahmin eidlecek veri olduğu için y ye eşitledik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3463755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# İki farklı şekilde x ve y yi belirledik 1. de drop ile yaptık 2. de stün isimlerini columns ile bulduk ve ayrı ayrı tanımladık"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2edb6f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Outcome\n",
       "0          1\n",
       "1          0\n",
       "2          1\n",
       "3          0\n",
       "4          1\n",
       "..       ...\n",
       "763        0\n",
       "764        0\n",
       "765        0\n",
       "766        1\n",
       "767        0\n",
       "\n",
       "[768 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a08490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,0:8]   # ilk 8 stünü seçer\n",
    "y=df.iloc[:,8]    # 8 den sonraki stünları seçer\n",
    "# Bu da x ve y yi belirlerken 3. yöntem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92695f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  \n",
       "0                     0.627   50  \n",
       "1                     0.351   31  \n",
       "2                     0.672   32  \n",
       "3                     0.167   21  \n",
       "4                     2.288   33  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40bd86cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  \n",
       "0                       0.627   50  \n",
       "1                       0.351   31  \n",
       "2                       0.672   32  \n",
       "3                       0.167   21  \n",
       "4                       2.288   33  \n",
       "..                        ...  ...  \n",
       "763                     0.171   63  \n",
       "764                     0.340   27  \n",
       "765                     0.245   30  \n",
       "766                     0.349   47  \n",
       "767                     0.315   23  \n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5da75adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "763    0\n",
       "764    0\n",
       "765    0\n",
       "766    1\n",
       "767    0\n",
       "Name: Outcome, Length: 768, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f189c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "544aee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()   \n",
    "model.add(Dense(80,activation='relu'))     #İlk 120 neronu bağlamış olduk,, relu veri önemliyse 1 in üstnde geliyor önemsizse es geçiyor\n",
    "model.add(Dense(120,activation='relu'))     # 2. layerı oluşturuyoruz\n",
    "model.add(Dense(64,activation='relu'))     # 3. layerı oluşturduk\n",
    "model.add(Dense(30,activation='relu'))      # 4. layerı oluşturduk\n",
    "model.add(Dense(4,activation='relu'))       # 5. layerı oluşturduk\n",
    "model.add(Dense(1,activation='sigmoid'))    # Son layerı oluşturduk Classifaction da sonuç evet veya hayır olacağı için sigmoid kullandık\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9755dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rakamlar tamamen hayal ürünü\n",
    "# Fakat giriş kısımında ki 120 yerine x de kaç tane stün varsa o kadarla girmek tercih ediliyor ideal olan bu\n",
    "# Sonuç 1 veya 0 olacaksa son layerda 1 e inmemiz lazım ve sigmoid kullanmamız lazım \n",
    "# Cevapta evet hayır varsa binary_corressentropy seçiyoruz\n",
    "# adams ile optimum noktaya gelirken küçük adımlar kullanıyor akıllı hareket ediyor\n",
    "# relu aktivasyon fonksiyonu veri önemliyse bir sonrakine aktarmayı sağlıyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92752cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.4894 - loss: 1.5594 - val_accuracy: 0.5974 - val_loss: 0.6499\n",
      "Epoch 2/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6418 - loss: 0.6255 - val_accuracy: 0.5844 - val_loss: 0.6744\n",
      "Epoch 3/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6545 - loss: 0.6104 - val_accuracy: 0.5714 - val_loss: 0.6560\n",
      "Epoch 4/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6443 - loss: 0.6146 - val_accuracy: 0.5974 - val_loss: 0.6559\n",
      "Epoch 5/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6719 - loss: 0.6122 - val_accuracy: 0.5974 - val_loss: 0.6736\n",
      "Epoch 6/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6595 - loss: 0.5734 - val_accuracy: 0.5974 - val_loss: 0.6668\n",
      "Epoch 7/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6550 - loss: 0.5873 - val_accuracy: 0.5974 - val_loss: 0.6579\n",
      "Epoch 8/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6573 - loss: 0.5867 - val_accuracy: 0.5844 - val_loss: 0.6706\n",
      "Epoch 9/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6645 - loss: 0.6256 - val_accuracy: 0.5844 - val_loss: 0.6866\n",
      "Epoch 10/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6540 - loss: 0.5834 - val_accuracy: 0.5844 - val_loss: 0.6682\n",
      "Epoch 11/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6721 - loss: 0.6100 - val_accuracy: 0.5714 - val_loss: 0.6689\n",
      "Epoch 12/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6709 - loss: 0.5694 - val_accuracy: 0.5714 - val_loss: 0.6786\n",
      "Epoch 13/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6355 - loss: 0.5964 - val_accuracy: 0.5844 - val_loss: 0.6997\n",
      "Epoch 14/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6608 - loss: 0.5943 - val_accuracy: 0.5844 - val_loss: 0.6780\n",
      "Epoch 15/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6687 - loss: 0.5887 - val_accuracy: 0.5714 - val_loss: 0.6949\n",
      "Epoch 16/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6879 - loss: 0.6081 - val_accuracy: 0.6494 - val_loss: 0.6770\n",
      "Epoch 17/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6695 - loss: 0.6155 - val_accuracy: 0.5714 - val_loss: 0.6692\n",
      "Epoch 18/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6466 - loss: 0.5822 - val_accuracy: 0.5844 - val_loss: 0.7041\n",
      "Epoch 19/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6983 - loss: 0.5444 - val_accuracy: 0.6364 - val_loss: 0.6659\n",
      "Epoch 20/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7339 - loss: 0.5434 - val_accuracy: 0.6364 - val_loss: 0.6989\n",
      "Epoch 21/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7051 - loss: 0.5582 - val_accuracy: 0.6623 - val_loss: 0.6793\n",
      "Epoch 22/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6827 - loss: 0.5778 - val_accuracy: 0.6494 - val_loss: 0.6797\n",
      "Epoch 23/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7240 - loss: 0.5300 - val_accuracy: 0.7013 - val_loss: 0.6508\n",
      "Epoch 24/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7169 - loss: 0.5316 - val_accuracy: 0.5974 - val_loss: 0.6903\n",
      "Epoch 25/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7098 - loss: 0.5294 - val_accuracy: 0.6494 - val_loss: 0.6690\n",
      "Epoch 26/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7036 - loss: 0.5435 - val_accuracy: 0.6883 - val_loss: 0.6498\n",
      "Epoch 27/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6838 - loss: 0.5562 - val_accuracy: 0.6494 - val_loss: 0.6832\n",
      "Epoch 28/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6835 - loss: 0.5694 - val_accuracy: 0.6753 - val_loss: 0.6552\n",
      "Epoch 29/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6896 - loss: 0.5640 - val_accuracy: 0.5844 - val_loss: 0.6764\n",
      "Epoch 30/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6843 - loss: 0.5880 - val_accuracy: 0.6883 - val_loss: 0.6647\n",
      "Epoch 31/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6850 - loss: 0.5443 - val_accuracy: 0.6883 - val_loss: 0.6643\n",
      "Epoch 32/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7061 - loss: 0.5474 - val_accuracy: 0.6753 - val_loss: 0.6531\n",
      "Epoch 33/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6964 - loss: 0.5411 - val_accuracy: 0.7013 - val_loss: 0.6494\n",
      "Epoch 34/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7153 - loss: 0.5299 - val_accuracy: 0.6883 - val_loss: 0.6432\n",
      "Epoch 35/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7087 - loss: 0.5222 - val_accuracy: 0.6234 - val_loss: 0.6816\n",
      "Epoch 36/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7235 - loss: 0.5290 - val_accuracy: 0.6753 - val_loss: 0.6572\n",
      "Epoch 37/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6952 - loss: 0.5418 - val_accuracy: 0.7143 - val_loss: 0.6290\n",
      "Epoch 38/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6706 - loss: 0.5318 - val_accuracy: 0.6104 - val_loss: 0.7168\n",
      "Epoch 39/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6904 - loss: 0.5599 - val_accuracy: 0.6234 - val_loss: 0.8214\n",
      "Epoch 40/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7073 - loss: 0.5606 - val_accuracy: 0.6494 - val_loss: 0.6697\n",
      "Epoch 41/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6924 - loss: 0.5456 - val_accuracy: 0.6883 - val_loss: 0.6459\n",
      "Epoch 42/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6983 - loss: 0.5288 - val_accuracy: 0.7143 - val_loss: 0.6356\n",
      "Epoch 43/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7083 - loss: 0.5304 - val_accuracy: 0.7013 - val_loss: 0.6528\n",
      "Epoch 44/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7350 - loss: 0.5066 - val_accuracy: 0.7013 - val_loss: 0.6432\n",
      "Epoch 45/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6820 - loss: 0.5289 - val_accuracy: 0.6883 - val_loss: 0.6496\n",
      "Epoch 46/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7257 - loss: 0.4976 - val_accuracy: 0.7143 - val_loss: 0.6363\n",
      "Epoch 47/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7057 - loss: 0.5284 - val_accuracy: 0.7013 - val_loss: 0.6404\n",
      "Epoch 48/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6958 - loss: 0.5352 - val_accuracy: 0.6234 - val_loss: 0.6760\n",
      "Epoch 49/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7186 - loss: 0.5067 - val_accuracy: 0.6883 - val_loss: 0.6380\n",
      "Epoch 50/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6918 - loss: 0.5275 - val_accuracy: 0.6883 - val_loss: 0.6299\n",
      "Epoch 51/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6969 - loss: 0.5319 - val_accuracy: 0.6494 - val_loss: 0.6415\n",
      "Epoch 52/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7188 - loss: 0.4907 - val_accuracy: 0.6883 - val_loss: 0.6324\n",
      "Epoch 53/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7138 - loss: 0.5326 - val_accuracy: 0.7013 - val_loss: 0.6294\n",
      "Epoch 54/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7315 - loss: 0.5166 - val_accuracy: 0.6883 - val_loss: 0.6480\n",
      "Epoch 55/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7200 - loss: 0.5095 - val_accuracy: 0.6883 - val_loss: 0.6511\n",
      "Epoch 56/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7333 - loss: 0.5019 - val_accuracy: 0.6623 - val_loss: 0.6395\n",
      "Epoch 57/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7617 - loss: 0.5048 - val_accuracy: 0.7013 - val_loss: 0.6446\n",
      "Epoch 58/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7122 - loss: 0.5258 - val_accuracy: 0.6623 - val_loss: 0.6542\n",
      "Epoch 59/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7093 - loss: 0.5024 - val_accuracy: 0.6104 - val_loss: 0.6714\n",
      "Epoch 60/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7163 - loss: 0.5164 - val_accuracy: 0.7273 - val_loss: 0.6301\n",
      "Epoch 61/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7225 - loss: 0.4940 - val_accuracy: 0.6753 - val_loss: 0.6434\n",
      "Epoch 62/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7249 - loss: 0.5108 - val_accuracy: 0.6623 - val_loss: 0.6580\n",
      "Epoch 63/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7059 - loss: 0.5040 - val_accuracy: 0.7013 - val_loss: 0.6527\n",
      "Epoch 64/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7162 - loss: 0.5085 - val_accuracy: 0.7013 - val_loss: 0.6408\n",
      "Epoch 65/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7163 - loss: 0.5130 - val_accuracy: 0.6623 - val_loss: 0.6694\n",
      "Epoch 66/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7188 - loss: 0.4655 - val_accuracy: 0.6753 - val_loss: 0.6177\n",
      "Epoch 67/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7185 - loss: 0.5027 - val_accuracy: 0.6883 - val_loss: 0.6510\n",
      "Epoch 68/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7265 - loss: 0.4838 - val_accuracy: 0.7273 - val_loss: 0.6232\n",
      "Epoch 69/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7352 - loss: 0.4967 - val_accuracy: 0.6753 - val_loss: 0.6719\n",
      "Epoch 70/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7127 - loss: 0.5107 - val_accuracy: 0.6883 - val_loss: 0.6493\n",
      "Epoch 71/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7351 - loss: 0.4993 - val_accuracy: 0.6883 - val_loss: 0.6296\n",
      "Epoch 72/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7267 - loss: 0.5112 - val_accuracy: 0.6753 - val_loss: 0.6719\n",
      "Epoch 73/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7093 - loss: 0.5034 - val_accuracy: 0.6623 - val_loss: 0.6972\n",
      "Epoch 74/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7178 - loss: 0.4909 - val_accuracy: 0.6753 - val_loss: 0.6437\n",
      "Epoch 75/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7161 - loss: 0.4834 - val_accuracy: 0.6753 - val_loss: 0.6341\n",
      "Epoch 76/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7039 - loss: 0.5049 - val_accuracy: 0.6753 - val_loss: 0.6267\n",
      "Epoch 77/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7146 - loss: 0.4893 - val_accuracy: 0.6883 - val_loss: 0.6473\n",
      "Epoch 78/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7153 - loss: 0.4897 - val_accuracy: 0.6753 - val_loss: 0.6263\n",
      "Epoch 79/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6990 - loss: 0.4981 - val_accuracy: 0.6753 - val_loss: 0.6396\n",
      "Epoch 80/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7279 - loss: 0.4705 - val_accuracy: 0.6494 - val_loss: 0.6220\n",
      "Epoch 81/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7356 - loss: 0.4700 - val_accuracy: 0.6883 - val_loss: 0.6660\n",
      "Epoch 82/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7252 - loss: 0.4923 - val_accuracy: 0.6364 - val_loss: 0.6584\n",
      "Epoch 83/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7100 - loss: 0.5075 - val_accuracy: 0.6494 - val_loss: 0.6701\n",
      "Epoch 84/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7264 - loss: 0.4752 - val_accuracy: 0.6494 - val_loss: 0.6703\n",
      "Epoch 85/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7342 - loss: 0.4687 - val_accuracy: 0.6623 - val_loss: 0.6497\n",
      "Epoch 86/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7028 - loss: 0.4891 - val_accuracy: 0.6753 - val_loss: 0.7164\n",
      "Epoch 87/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7016 - loss: 0.4889 - val_accuracy: 0.6883 - val_loss: 0.6521\n",
      "Epoch 88/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7258 - loss: 0.4690 - val_accuracy: 0.6623 - val_loss: 0.6165\n",
      "Epoch 89/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6881 - loss: 0.5230 - val_accuracy: 0.6753 - val_loss: 0.8157\n",
      "Epoch 90/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7228 - loss: 0.5099 - val_accuracy: 0.6623 - val_loss: 0.6805\n",
      "Epoch 91/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7084 - loss: 0.4906 - val_accuracy: 0.6623 - val_loss: 0.6464\n",
      "Epoch 92/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7452 - loss: 0.4568 - val_accuracy: 0.6494 - val_loss: 0.6519\n",
      "Epoch 93/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7183 - loss: 0.4731 - val_accuracy: 0.6623 - val_loss: 0.7165\n",
      "Epoch 94/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7464 - loss: 0.4378 - val_accuracy: 0.6104 - val_loss: 0.7096\n",
      "Epoch 95/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6972 - loss: 0.4765 - val_accuracy: 0.6623 - val_loss: 0.6489\n",
      "Epoch 96/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7330 - loss: 0.4328 - val_accuracy: 0.6364 - val_loss: 0.6998\n",
      "Epoch 97/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7303 - loss: 0.5076 - val_accuracy: 0.6104 - val_loss: 0.7108\n",
      "Epoch 98/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7503 - loss: 0.5021 - val_accuracy: 0.6623 - val_loss: 0.6358\n",
      "Epoch 99/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7073 - loss: 0.4859 - val_accuracy: 0.6753 - val_loss: 0.6175\n",
      "Epoch 100/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7192 - loss: 0.4971 - val_accuracy: 0.6883 - val_loss: 0.6503\n",
      "Epoch 101/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7297 - loss: 0.4583 - val_accuracy: 0.6753 - val_loss: 0.6139\n",
      "Epoch 102/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7287 - loss: 0.4654 - val_accuracy: 0.6883 - val_loss: 0.6274\n",
      "Epoch 103/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7229 - loss: 0.4874 - val_accuracy: 0.6753 - val_loss: 0.7038\n",
      "Epoch 104/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7224 - loss: 0.4553 - val_accuracy: 0.6753 - val_loss: 0.6478\n",
      "Epoch 105/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7139 - loss: 0.4532 - val_accuracy: 0.6623 - val_loss: 0.6289\n",
      "Epoch 106/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6935 - loss: 0.4649 - val_accuracy: 0.7013 - val_loss: 0.7024\n",
      "Epoch 107/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7209 - loss: 0.4585 - val_accuracy: 0.6753 - val_loss: 0.6493\n",
      "Epoch 108/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7422 - loss: 0.4403 - val_accuracy: 0.6883 - val_loss: 0.6376\n",
      "Epoch 109/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7318 - loss: 0.4349 - val_accuracy: 0.6364 - val_loss: 0.6842\n",
      "Epoch 110/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7249 - loss: 0.4379 - val_accuracy: 0.6364 - val_loss: 0.7425\n",
      "Epoch 111/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6984 - loss: 0.4601 - val_accuracy: 0.6883 - val_loss: 0.6032\n",
      "Epoch 112/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7388 - loss: 0.4442 - val_accuracy: 0.6494 - val_loss: 0.6633\n",
      "Epoch 113/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7399 - loss: 0.4371 - val_accuracy: 0.6753 - val_loss: 0.6399\n",
      "Epoch 114/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7047 - loss: 0.4468 - val_accuracy: 0.6883 - val_loss: 0.6141\n",
      "Epoch 115/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7183 - loss: 0.4421 - val_accuracy: 0.6753 - val_loss: 0.6431\n",
      "Epoch 116/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7037 - loss: 0.4829 - val_accuracy: 0.7013 - val_loss: 0.6731\n",
      "Epoch 117/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7319 - loss: 0.4519 - val_accuracy: 0.6753 - val_loss: 0.6303\n",
      "Epoch 118/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7094 - loss: 0.4544 - val_accuracy: 0.6494 - val_loss: 0.6729\n",
      "Epoch 119/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7274 - loss: 0.4632 - val_accuracy: 0.6883 - val_loss: 0.6390\n",
      "Epoch 120/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7454 - loss: 0.4158 - val_accuracy: 0.6753 - val_loss: 0.5999\n",
      "Epoch 121/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7371 - loss: 0.4409 - val_accuracy: 0.6104 - val_loss: 0.6544\n",
      "Epoch 122/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7045 - loss: 0.4903 - val_accuracy: 0.6494 - val_loss: 0.6441\n",
      "Epoch 123/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7186 - loss: 0.4895 - val_accuracy: 0.6883 - val_loss: 0.6212\n",
      "Epoch 124/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7752 - loss: 0.4694 - val_accuracy: 0.7273 - val_loss: 0.6506\n",
      "Epoch 125/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7787 - loss: 0.4110 - val_accuracy: 0.7013 - val_loss: 0.6268\n",
      "Epoch 126/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7492 - loss: 0.4473 - val_accuracy: 0.7143 - val_loss: 0.6748\n",
      "Epoch 127/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7764 - loss: 0.4500 - val_accuracy: 0.6883 - val_loss: 0.7546\n",
      "Epoch 128/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7806 - loss: 0.4299 - val_accuracy: 0.7403 - val_loss: 0.6839\n",
      "Epoch 129/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7654 - loss: 0.4791 - val_accuracy: 0.6883 - val_loss: 0.7369\n",
      "Epoch 130/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7792 - loss: 0.4551 - val_accuracy: 0.6623 - val_loss: 0.6493\n",
      "Epoch 131/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7705 - loss: 0.4462 - val_accuracy: 0.7143 - val_loss: 0.6649\n",
      "Epoch 132/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7398 - loss: 0.4557 - val_accuracy: 0.6883 - val_loss: 0.6112\n",
      "Epoch 133/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7749 - loss: 0.4361 - val_accuracy: 0.7013 - val_loss: 0.6701\n",
      "Epoch 134/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7840 - loss: 0.4243 - val_accuracy: 0.6883 - val_loss: 0.7861\n",
      "Epoch 135/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7726 - loss: 0.4597 - val_accuracy: 0.6623 - val_loss: 0.6761\n",
      "Epoch 136/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7854 - loss: 0.4180 - val_accuracy: 0.7273 - val_loss: 0.6574\n",
      "Epoch 137/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7816 - loss: 0.4377 - val_accuracy: 0.7013 - val_loss: 0.6645\n",
      "Epoch 138/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7730 - loss: 0.4067 - val_accuracy: 0.6883 - val_loss: 0.6629\n",
      "Epoch 139/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7608 - loss: 0.4316 - val_accuracy: 0.7013 - val_loss: 0.6273\n",
      "Epoch 140/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7905 - loss: 0.4059 - val_accuracy: 0.7143 - val_loss: 0.6821\n",
      "Epoch 141/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8161 - loss: 0.3835 - val_accuracy: 0.6623 - val_loss: 0.7796\n",
      "Epoch 142/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7877 - loss: 0.4096 - val_accuracy: 0.6104 - val_loss: 0.6493\n",
      "Epoch 143/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7582 - loss: 0.4469 - val_accuracy: 0.7532 - val_loss: 0.6289\n",
      "Epoch 144/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7911 - loss: 0.4020 - val_accuracy: 0.7013 - val_loss: 0.6580\n",
      "Epoch 145/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7821 - loss: 0.4290 - val_accuracy: 0.7662 - val_loss: 0.5938\n",
      "Epoch 146/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8053 - loss: 0.3804 - val_accuracy: 0.7013 - val_loss: 0.6429\n",
      "Epoch 147/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8261 - loss: 0.3641 - val_accuracy: 0.7403 - val_loss: 0.6416\n",
      "Epoch 148/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8285 - loss: 0.3653 - val_accuracy: 0.7532 - val_loss: 0.6843\n",
      "Epoch 149/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7944 - loss: 0.3894 - val_accuracy: 0.7273 - val_loss: 0.5985\n",
      "Epoch 150/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8032 - loss: 0.3856 - val_accuracy: 0.7532 - val_loss: 0.5901\n",
      "Epoch 151/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8075 - loss: 0.3709 - val_accuracy: 0.7273 - val_loss: 0.6476\n",
      "Epoch 152/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8046 - loss: 0.3833 - val_accuracy: 0.7143 - val_loss: 0.6851\n",
      "Epoch 153/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8299 - loss: 0.3467 - val_accuracy: 0.7532 - val_loss: 0.6236\n",
      "Epoch 154/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8247 - loss: 0.3787 - val_accuracy: 0.7273 - val_loss: 0.6103\n",
      "Epoch 155/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7946 - loss: 0.3924 - val_accuracy: 0.7143 - val_loss: 0.7178\n",
      "Epoch 156/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7895 - loss: 0.4287 - val_accuracy: 0.7273 - val_loss: 0.6192\n",
      "Epoch 157/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8236 - loss: 0.3751 - val_accuracy: 0.7532 - val_loss: 0.6379\n",
      "Epoch 158/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8315 - loss: 0.3613 - val_accuracy: 0.7532 - val_loss: 0.5841\n",
      "Epoch 159/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8244 - loss: 0.3732 - val_accuracy: 0.7273 - val_loss: 0.5817\n",
      "Epoch 160/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8301 - loss: 0.3551 - val_accuracy: 0.6753 - val_loss: 0.6820\n",
      "Epoch 161/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8388 - loss: 0.3581 - val_accuracy: 0.7013 - val_loss: 0.6134\n",
      "Epoch 162/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8308 - loss: 0.3541 - val_accuracy: 0.7532 - val_loss: 0.6002\n",
      "Epoch 163/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8181 - loss: 0.3540 - val_accuracy: 0.7403 - val_loss: 0.6465\n",
      "Epoch 164/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8129 - loss: 0.3623 - val_accuracy: 0.7922 - val_loss: 0.5312\n",
      "Epoch 165/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8283 - loss: 0.3493 - val_accuracy: 0.6883 - val_loss: 0.6765\n",
      "Epoch 166/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8489 - loss: 0.3485 - val_accuracy: 0.7273 - val_loss: 0.6618\n",
      "Epoch 167/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8261 - loss: 0.3612 - val_accuracy: 0.7273 - val_loss: 0.6506\n",
      "Epoch 168/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8487 - loss: 0.3290 - val_accuracy: 0.6623 - val_loss: 0.6178\n",
      "Epoch 169/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8145 - loss: 0.3739 - val_accuracy: 0.6883 - val_loss: 0.6159\n",
      "Epoch 170/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8345 - loss: 0.3380 - val_accuracy: 0.7662 - val_loss: 0.6859\n",
      "Epoch 171/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8508 - loss: 0.3303 - val_accuracy: 0.7273 - val_loss: 0.6564\n",
      "Epoch 172/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8205 - loss: 0.3347 - val_accuracy: 0.7273 - val_loss: 0.5904\n",
      "Epoch 173/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8311 - loss: 0.3411 - val_accuracy: 0.7403 - val_loss: 0.6592\n",
      "Epoch 174/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8411 - loss: 0.3256 - val_accuracy: 0.7143 - val_loss: 0.5809\n",
      "Epoch 175/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8377 - loss: 0.3272 - val_accuracy: 0.7273 - val_loss: 0.7100\n",
      "Epoch 176/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8143 - loss: 0.3219 - val_accuracy: 0.6623 - val_loss: 0.5940\n",
      "Epoch 177/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8646 - loss: 0.3004 - val_accuracy: 0.7273 - val_loss: 0.6200\n",
      "Epoch 178/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8568 - loss: 0.3353 - val_accuracy: 0.7273 - val_loss: 0.6911\n",
      "Epoch 179/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8554 - loss: 0.3030 - val_accuracy: 0.7532 - val_loss: 0.6591\n",
      "Epoch 180/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8787 - loss: 0.2940 - val_accuracy: 0.7792 - val_loss: 0.6213\n",
      "Epoch 181/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8486 - loss: 0.3162 - val_accuracy: 0.7013 - val_loss: 0.5841\n",
      "Epoch 182/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8326 - loss: 0.3334 - val_accuracy: 0.7013 - val_loss: 0.6998\n",
      "Epoch 183/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8552 - loss: 0.2867 - val_accuracy: 0.7143 - val_loss: 0.6060\n",
      "Epoch 184/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8479 - loss: 0.3253 - val_accuracy: 0.7662 - val_loss: 0.7240\n",
      "Epoch 185/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8162 - loss: 0.3449 - val_accuracy: 0.7662 - val_loss: 0.6116\n",
      "Epoch 186/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8276 - loss: 0.3341 - val_accuracy: 0.7662 - val_loss: 0.6517\n",
      "Epoch 187/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8616 - loss: 0.2855 - val_accuracy: 0.7792 - val_loss: 0.6443\n",
      "Epoch 188/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8344 - loss: 0.3164 - val_accuracy: 0.7792 - val_loss: 0.6094\n",
      "Epoch 189/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8620 - loss: 0.2890 - val_accuracy: 0.7013 - val_loss: 0.7136\n",
      "Epoch 190/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8436 - loss: 0.3083 - val_accuracy: 0.7792 - val_loss: 0.6282\n",
      "Epoch 191/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8533 - loss: 0.3008 - val_accuracy: 0.6753 - val_loss: 0.6690\n",
      "Epoch 192/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8347 - loss: 0.3494 - val_accuracy: 0.7273 - val_loss: 0.7147\n",
      "Epoch 193/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8498 - loss: 0.2977 - val_accuracy: 0.7273 - val_loss: 0.7026\n",
      "Epoch 194/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8719 - loss: 0.3052 - val_accuracy: 0.7532 - val_loss: 0.5283\n",
      "Epoch 195/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8574 - loss: 0.2973 - val_accuracy: 0.7662 - val_loss: 0.6324\n",
      "Epoch 196/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8957 - loss: 0.2345 - val_accuracy: 0.7532 - val_loss: 0.7213\n",
      "Epoch 197/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8925 - loss: 0.2517 - val_accuracy: 0.7273 - val_loss: 0.8145\n",
      "Epoch 198/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8621 - loss: 0.2713 - val_accuracy: 0.7532 - val_loss: 0.6636\n",
      "Epoch 199/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8414 - loss: 0.2854 - val_accuracy: 0.7922 - val_loss: 0.6808\n",
      "Epoch 200/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8741 - loss: 0.2563 - val_accuracy: 0.7013 - val_loss: 0.6782\n",
      "Epoch 201/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8562 - loss: 0.2821 - val_accuracy: 0.7013 - val_loss: 0.7435\n",
      "Epoch 202/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8470 - loss: 0.3180 - val_accuracy: 0.7403 - val_loss: 0.6225\n",
      "Epoch 203/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8305 - loss: 0.3349 - val_accuracy: 0.7662 - val_loss: 0.6099\n",
      "Epoch 204/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8807 - loss: 0.2983 - val_accuracy: 0.7662 - val_loss: 0.6745\n",
      "Epoch 205/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8845 - loss: 0.2348 - val_accuracy: 0.7532 - val_loss: 0.6694\n",
      "Epoch 206/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8837 - loss: 0.2503 - val_accuracy: 0.7273 - val_loss: 0.6938\n",
      "Epoch 207/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8751 - loss: 0.2485 - val_accuracy: 0.7532 - val_loss: 0.6967\n",
      "Epoch 208/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8689 - loss: 0.2511 - val_accuracy: 0.7403 - val_loss: 0.8333\n",
      "Epoch 209/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8400 - loss: 0.2771 - val_accuracy: 0.7532 - val_loss: 0.6739\n",
      "Epoch 210/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8730 - loss: 0.2404 - val_accuracy: 0.7922 - val_loss: 0.7761\n",
      "Epoch 211/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8501 - loss: 0.2939 - val_accuracy: 0.7792 - val_loss: 0.8233\n",
      "Epoch 212/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8544 - loss: 0.2498 - val_accuracy: 0.7662 - val_loss: 0.7761\n",
      "Epoch 213/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8673 - loss: 0.2830 - val_accuracy: 0.7532 - val_loss: 0.7813\n",
      "Epoch 214/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9084 - loss: 0.2452 - val_accuracy: 0.7662 - val_loss: 0.7509\n",
      "Epoch 215/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8864 - loss: 0.2292 - val_accuracy: 0.7662 - val_loss: 0.7308\n",
      "Epoch 216/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8828 - loss: 0.2564 - val_accuracy: 0.7403 - val_loss: 0.8605\n",
      "Epoch 217/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8881 - loss: 0.2276 - val_accuracy: 0.7532 - val_loss: 0.8397\n",
      "Epoch 218/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9065 - loss: 0.2146 - val_accuracy: 0.7532 - val_loss: 0.7881\n",
      "Epoch 219/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9072 - loss: 0.2171 - val_accuracy: 0.7792 - val_loss: 0.7660\n",
      "Epoch 220/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9050 - loss: 0.2135 - val_accuracy: 0.7792 - val_loss: 0.7755\n",
      "Epoch 221/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9058 - loss: 0.2115 - val_accuracy: 0.7532 - val_loss: 0.8607\n",
      "Epoch 222/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8993 - loss: 0.2129 - val_accuracy: 0.7273 - val_loss: 1.0133\n",
      "Epoch 223/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8859 - loss: 0.2207 - val_accuracy: 0.7532 - val_loss: 0.8691\n",
      "Epoch 224/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9242 - loss: 0.1996 - val_accuracy: 0.6753 - val_loss: 1.0575\n",
      "Epoch 225/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8839 - loss: 0.2785 - val_accuracy: 0.7403 - val_loss: 0.8481\n",
      "Epoch 226/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8308 - loss: 0.3508 - val_accuracy: 0.7273 - val_loss: 0.7955\n",
      "Epoch 227/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8302 - loss: 0.3592 - val_accuracy: 0.7403 - val_loss: 0.6969\n",
      "Epoch 228/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8875 - loss: 0.2688 - val_accuracy: 0.7532 - val_loss: 0.8946\n",
      "Epoch 229/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8748 - loss: 0.2447 - val_accuracy: 0.7662 - val_loss: 1.0307\n",
      "Epoch 230/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9230 - loss: 0.1922 - val_accuracy: 0.7662 - val_loss: 0.9195\n",
      "Epoch 231/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9027 - loss: 0.2072 - val_accuracy: 0.7403 - val_loss: 0.8599\n",
      "Epoch 232/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9165 - loss: 0.2087 - val_accuracy: 0.7792 - val_loss: 0.9608\n",
      "Epoch 233/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9154 - loss: 0.1855 - val_accuracy: 0.7273 - val_loss: 1.0504\n",
      "Epoch 234/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9294 - loss: 0.1676 - val_accuracy: 0.7403 - val_loss: 1.2515\n",
      "Epoch 235/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8964 - loss: 0.2155 - val_accuracy: 0.7403 - val_loss: 0.9080\n",
      "Epoch 236/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9211 - loss: 0.1828 - val_accuracy: 0.7792 - val_loss: 0.9359\n",
      "Epoch 237/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9332 - loss: 0.1668 - val_accuracy: 0.7403 - val_loss: 1.0401\n",
      "Epoch 238/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9258 - loss: 0.1612 - val_accuracy: 0.7792 - val_loss: 1.0964\n",
      "Epoch 239/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9486 - loss: 0.1549 - val_accuracy: 0.7532 - val_loss: 1.1266\n",
      "Epoch 240/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9387 - loss: 0.1678 - val_accuracy: 0.7792 - val_loss: 1.0361\n",
      "Epoch 241/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9576 - loss: 0.1377 - val_accuracy: 0.8052 - val_loss: 1.1284\n",
      "Epoch 242/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9259 - loss: 0.1478 - val_accuracy: 0.7662 - val_loss: 1.0572\n",
      "Epoch 243/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9355 - loss: 0.1408 - val_accuracy: 0.7662 - val_loss: 1.1759\n",
      "Epoch 244/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9393 - loss: 0.1379 - val_accuracy: 0.7532 - val_loss: 1.0885\n",
      "Epoch 245/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9375 - loss: 0.1590 - val_accuracy: 0.7662 - val_loss: 1.1726\n",
      "Epoch 246/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9399 - loss: 0.1461 - val_accuracy: 0.8052 - val_loss: 1.3216\n",
      "Epoch 247/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8800 - loss: 0.2360 - val_accuracy: 0.7532 - val_loss: 0.9769\n",
      "Epoch 248/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9100 - loss: 0.2241 - val_accuracy: 0.7662 - val_loss: 1.0333\n",
      "Epoch 249/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9177 - loss: 0.1982 - val_accuracy: 0.8052 - val_loss: 0.9625\n",
      "Epoch 250/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9206 - loss: 0.1932 - val_accuracy: 0.8182 - val_loss: 1.0343\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x,y, epochs=250,batch_size=32,validation_split=0.1,verbose=1)   # Verbose 0 dersek aşağıdaki sonucu göstermez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9268edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split yerine validation_split=0.1 dediğimizde bu işlem yüzde 10 unu eğitmek ve test etmek için ayırıyor\n",
    "# epochs sokaklar arasında yani layerlar arasında kaç defa gidip gelmemiz gerektiğini söylüyor\n",
    "# Accuracy oranına bakarak epoch kaç kez olması gerektiğne karar veriyoruz\n",
    "# histroy = diyerek modeli hafızaya kaydedecek\n",
    "# modeli sürekli eğiterek başarı artıyor 1 çıkarsa iyi değil\n",
    "# batch size ile datayı 32 ye bölüp yani 32 farklı kamyonla taşıyoruz bu şekilde çok ram yiyen data daha rahat çözülebiliyor\n",
    "#verbose ise aşağıdaki rakamların gözüküp gözükmeyeceğini sağlıyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e541ddfe",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5918958187103271,\n",
       " 0.6613603234291077,\n",
       " 0.6628075242042542,\n",
       " 0.6512300968170166,\n",
       " 0.6570188403129578,\n",
       " 0.6570188403129578,\n",
       " 0.659913182258606,\n",
       " 0.6613603234291077,\n",
       " 0.6642547249794006,\n",
       " 0.6642547249794006,\n",
       " 0.670043408870697,\n",
       " 0.6729377508163452,\n",
       " 0.670043408870697,\n",
       " 0.670043408870697,\n",
       " 0.6685962080955505,\n",
       " 0.6874095797538757,\n",
       " 0.6657018661499023,\n",
       " 0.6743849515914917,\n",
       " 0.6888567209243774,\n",
       " 0.6975398063659668,\n",
       " 0.6874095797538757,\n",
       " 0.6989869475364685,\n",
       " 0.6903039216995239,\n",
       " 0.6960926055908203,\n",
       " 0.6917510628700256,\n",
       " 0.7033284902572632,\n",
       " 0.700434148311615,\n",
       " 0.7047756910324097,\n",
       " 0.6801736354827881,\n",
       " 0.6888567209243774,\n",
       " 0.6931982636451721,\n",
       " 0.6917510628700256,\n",
       " 0.700434148311615,\n",
       " 0.7047756910324097,\n",
       " 0.6975398063659668,\n",
       " 0.6989869475364685,\n",
       " 0.7076700329780579,\n",
       " 0.6874095797538757,\n",
       " 0.700434148311615,\n",
       " 0.6989869475364685,\n",
       " 0.6989869475364685,\n",
       " 0.6989869475364685,\n",
       " 0.7149059176445007,\n",
       " 0.7018813490867615,\n",
       " 0.7047756910324097,\n",
       " 0.7062228918075562,\n",
       " 0.7062228918075562,\n",
       " 0.6946454644203186,\n",
       " 0.7149059176445007,\n",
       " 0.7091172337532043,\n",
       " 0.7120115756988525,\n",
       " 0.7033284902572632,\n",
       " 0.6975398063659668,\n",
       " 0.7149059176445007,\n",
       " 0.7149059176445007,\n",
       " 0.7279305458068848,\n",
       " 0.7279305458068848,\n",
       " 0.7033284902572632,\n",
       " 0.713458776473999,\n",
       " 0.7120115756988525,\n",
       " 0.7018813490867615,\n",
       " 0.7206946611404419,\n",
       " 0.7018813490867615,\n",
       " 0.7120115756988525,\n",
       " 0.7120115756988525,\n",
       " 0.7047756910324097,\n",
       " 0.7178003191947937,\n",
       " 0.7091172337532043,\n",
       " 0.740955114364624,\n",
       " 0.7120115756988525,\n",
       " 0.7178003191947937,\n",
       " 0.7163531184196472,\n",
       " 0.7120115756988525,\n",
       " 0.7076700329780579,\n",
       " 0.7178003191947937,\n",
       " 0.7149059176445007,\n",
       " 0.7149059176445007,\n",
       " 0.7091172337532043,\n",
       " 0.7120115756988525,\n",
       " 0.7062228918075562,\n",
       " 0.7149059176445007,\n",
       " 0.7264833450317383,\n",
       " 0.7206946611404419,\n",
       " 0.713458776473999,\n",
       " 0.7192474603652954,\n",
       " 0.7149059176445007,\n",
       " 0.7091172337532043,\n",
       " 0.7206946611404419,\n",
       " 0.7192474603652954,\n",
       " 0.7149059176445007,\n",
       " 0.7178003191947937,\n",
       " 0.7206946611404419,\n",
       " 0.7235890030860901,\n",
       " 0.7120115756988525,\n",
       " 0.7076700329780579,\n",
       " 0.7076700329780579,\n",
       " 0.7091172337532043,\n",
       " 0.7250362038612366,\n",
       " 0.7163531184196472,\n",
       " 0.7221418023109436,\n",
       " 0.7279305458068848,\n",
       " 0.7192474603652954,\n",
       " 0.7264833450317383,\n",
       " 0.7120115756988525,\n",
       " 0.7221418023109436,\n",
       " 0.713458776473999,\n",
       " 0.7250362038612366,\n",
       " 0.7322720885276794,\n",
       " 0.713458776473999,\n",
       " 0.7091172337532043,\n",
       " 0.7149059176445007,\n",
       " 0.7264833450317383,\n",
       " 0.7178003191947937,\n",
       " 0.7120115756988525,\n",
       " 0.7221418023109436,\n",
       " 0.7250362038612366,\n",
       " 0.7221418023109436,\n",
       " 0.7178003191947937,\n",
       " 0.7178003191947937,\n",
       " 0.7322720885276794,\n",
       " 0.7351664304733276,\n",
       " 0.713458776473999,\n",
       " 0.7235890030860901,\n",
       " 0.7568740844726562,\n",
       " 0.7670043706893921,\n",
       " 0.7626628279685974,\n",
       " 0.7800289392471313,\n",
       " 0.7612156271934509,\n",
       " 0.7785817384719849,\n",
       " 0.7800289392471313,\n",
       " 0.7800289392471313,\n",
       " 0.740955114364624,\n",
       " 0.7756873965263367,\n",
       " 0.7887120246887207,\n",
       " 0.7641099691390991,\n",
       " 0.7887120246887207,\n",
       " 0.7916063666343689,\n",
       " 0.7670043706893921,\n",
       " 0.774240255355835,\n",
       " 0.7901591658592224,\n",
       " 0.7945007085800171,\n",
       " 0.7756873965263367,\n",
       " 0.7727930545806885,\n",
       " 0.7800289392471313,\n",
       " 0.784370481967926,\n",
       " 0.8031837940216064,\n",
       " 0.8205499053001404,\n",
       " 0.814761221408844,\n",
       " 0.7858176827430725,\n",
       " 0.8002894520759583,\n",
       " 0.8089724779129028,\n",
       " 0.8191027641296387,\n",
       " 0.8104196786880493,\n",
       " 0.8162084221839905,\n",
       " 0.7829232811927795,\n",
       " 0.8060781359672546,\n",
       " 0.8133140206336975,\n",
       " 0.8219971060752869,\n",
       " 0.8191027641296387,\n",
       " 0.8306801915168762,\n",
       " 0.8118668794631958,\n",
       " 0.8089724779129028,\n",
       " 0.8162084221839905,\n",
       " 0.814761221408844,\n",
       " 0.8104196786880493,\n",
       " 0.8191027641296387,\n",
       " 0.8350217342376709,\n",
       " 0.814761221408844,\n",
       " 0.8219971060752869,\n",
       " 0.8277857899665833,\n",
       " 0.8277857899665833,\n",
       " 0.8176555633544922,\n",
       " 0.8292329907417297,\n",
       " 0.8465991020202637,\n",
       " 0.8277857899665833,\n",
       " 0.8306801915168762,\n",
       " 0.8335745334625244,\n",
       " 0.8538350462913513,\n",
       " 0.8523878455162048,\n",
       " 0.8596237301826477,\n",
       " 0.8379160761833191,\n",
       " 0.8437047600746155,\n",
       " 0.8335745334625244,\n",
       " 0.8393632173538208,\n",
       " 0.8321273326873779,\n",
       " 0.855282187461853,\n",
       " 0.8509406447410583,\n",
       " 0.8350217342376709,\n",
       " 0.8625180721282959,\n",
       " 0.8494935035705566,\n",
       " 0.845151960849762,\n",
       " 0.845151960849762,\n",
       " 0.8480463027954102,\n",
       " 0.8465991020202637,\n",
       " 0.8596237301826477,\n",
       " 0.8712011575698853,\n",
       " 0.885672926902771,\n",
       " 0.8523878455162048,\n",
       " 0.8625180721282959,\n",
       " 0.8625180721282959,\n",
       " 0.8567293882369995,\n",
       " 0.8408104181289673,\n",
       " 0.8263386487960815,\n",
       " 0.8581765294075012,\n",
       " 0.8813313841819763,\n",
       " 0.8827785849571228,\n",
       " 0.8712011575698853,\n",
       " 0.8639652729034424,\n",
       " 0.855282187461853,\n",
       " 0.8813313841819763,\n",
       " 0.8755427002906799,\n",
       " 0.8683068156242371,\n",
       " 0.8769898414611816,\n",
       " 0.8842257857322693,\n",
       " 0.8900144696235657,\n",
       " 0.8943560123443604,\n",
       " 0.8755427002906799,\n",
       " 0.9001446962356567,\n",
       " 0.9001446962356567,\n",
       " 0.9073805809020996,\n",
       " 0.9073805809020996,\n",
       " 0.9030390977859497,\n",
       " 0.9102749824523926,\n",
       " 0.898697555065155,\n",
       " 0.8668596148490906,\n",
       " 0.8422576189041138,\n",
       " 0.8306801915168762,\n",
       " 0.8827785849571228,\n",
       " 0.8885672688484192,\n",
       " 0.9102749824523926,\n",
       " 0.898697555065155,\n",
       " 0.9175108671188354,\n",
       " 0.9232995510101318,\n",
       " 0.9001446962356567,\n",
       " 0.8914616703987122,\n",
       " 0.9102749824523926,\n",
       " 0.9218524098396301,\n",
       " 0.9247467517852783,\n",
       " 0.9377713203430176,\n",
       " 0.9377713203430176,\n",
       " 0.9406657218933105,\n",
       " 0.9131693243980408,\n",
       " 0.9276410937309265,\n",
       " 0.9392185211181641,\n",
       " 0.9247467517852783,\n",
       " 0.9175108671188354,\n",
       " 0.8943560123443604,\n",
       " 0.8900144696235657,\n",
       " 0.9131693243980408,\n",
       " 0.9247467517852783]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23965356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kural:Datayı derin öğrenmeden önce Normalize etmemiz gerekiyor Bunun için tekrardan bir python açıp NormalizationPCA açtık ve burda hazırlık yapacağız"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86d2863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize,scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75b45606",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=scale(x)   # x in yeni değeri scale edilmiş haline çevirdik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ee78097",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6647 - loss: 1.7959 - val_accuracy: 0.5714 - val_loss: 0.6921\n",
      "Epoch 2/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6688 - loss: 0.6171 - val_accuracy: 0.5844 - val_loss: 0.6605\n",
      "Epoch 3/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7004 - loss: 0.5696 - val_accuracy: 0.6104 - val_loss: 0.6386\n",
      "Epoch 4/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7356 - loss: 0.4978 - val_accuracy: 0.7143 - val_loss: 0.5715\n",
      "Epoch 5/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7561 - loss: 0.4722 - val_accuracy: 0.8052 - val_loss: 0.5228\n",
      "Epoch 6/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7955 - loss: 0.4114 - val_accuracy: 0.7922 - val_loss: 0.5250\n",
      "Epoch 7/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7760 - loss: 0.4439 - val_accuracy: 0.7662 - val_loss: 0.5557\n",
      "Epoch 8/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8090 - loss: 0.3968 - val_accuracy: 0.7922 - val_loss: 0.5096\n",
      "Epoch 9/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7957 - loss: 0.3864 - val_accuracy: 0.7922 - val_loss: 0.5273\n",
      "Epoch 10/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7879 - loss: 0.4022 - val_accuracy: 0.8052 - val_loss: 0.5266\n",
      "Epoch 11/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7950 - loss: 0.3994 - val_accuracy: 0.8052 - val_loss: 0.5229\n",
      "Epoch 12/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8383 - loss: 0.3839 - val_accuracy: 0.8052 - val_loss: 0.5362\n",
      "Epoch 13/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8357 - loss: 0.3563 - val_accuracy: 0.7662 - val_loss: 0.5680\n",
      "Epoch 14/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8380 - loss: 0.3573 - val_accuracy: 0.8442 - val_loss: 0.5352\n",
      "Epoch 15/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8248 - loss: 0.3632 - val_accuracy: 0.8182 - val_loss: 0.5325\n",
      "Epoch 16/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8496 - loss: 0.3212 - val_accuracy: 0.7922 - val_loss: 0.5666\n",
      "Epoch 17/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8520 - loss: 0.3303 - val_accuracy: 0.8182 - val_loss: 0.5383\n",
      "Epoch 18/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8758 - loss: 0.3179 - val_accuracy: 0.7922 - val_loss: 0.5634\n",
      "Epoch 19/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8475 - loss: 0.3263 - val_accuracy: 0.8052 - val_loss: 0.5747\n",
      "Epoch 20/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8555 - loss: 0.3117 - val_accuracy: 0.8052 - val_loss: 0.5600\n",
      "Epoch 21/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8665 - loss: 0.3180 - val_accuracy: 0.8052 - val_loss: 0.5761\n",
      "Epoch 22/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8754 - loss: 0.2943 - val_accuracy: 0.7922 - val_loss: 0.5727\n",
      "Epoch 23/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8642 - loss: 0.3018 - val_accuracy: 0.7922 - val_loss: 0.5952\n",
      "Epoch 24/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8529 - loss: 0.3084 - val_accuracy: 0.7922 - val_loss: 0.6130\n",
      "Epoch 25/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8634 - loss: 0.3082 - val_accuracy: 0.7922 - val_loss: 0.5677\n",
      "Epoch 26/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8896 - loss: 0.2584 - val_accuracy: 0.7662 - val_loss: 0.6460\n",
      "Epoch 27/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8771 - loss: 0.2846 - val_accuracy: 0.7792 - val_loss: 0.6443\n",
      "Epoch 28/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8743 - loss: 0.2937 - val_accuracy: 0.7532 - val_loss: 0.6664\n",
      "Epoch 29/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8722 - loss: 0.3016 - val_accuracy: 0.7662 - val_loss: 0.6403\n",
      "Epoch 30/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8670 - loss: 0.2837 - val_accuracy: 0.7792 - val_loss: 0.6571\n",
      "Epoch 31/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8950 - loss: 0.2781 - val_accuracy: 0.7662 - val_loss: 0.6934\n",
      "Epoch 32/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8805 - loss: 0.2686 - val_accuracy: 0.7792 - val_loss: 0.6892\n",
      "Epoch 33/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9178 - loss: 0.2471 - val_accuracy: 0.7792 - val_loss: 0.6871\n",
      "Epoch 34/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9065 - loss: 0.2429 - val_accuracy: 0.7792 - val_loss: 0.6816\n",
      "Epoch 35/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8952 - loss: 0.2555 - val_accuracy: 0.7532 - val_loss: 0.7188\n",
      "Epoch 36/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9013 - loss: 0.2334 - val_accuracy: 0.7532 - val_loss: 0.7049\n",
      "Epoch 37/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9074 - loss: 0.2420 - val_accuracy: 0.7792 - val_loss: 0.6907\n",
      "Epoch 38/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8875 - loss: 0.2386 - val_accuracy: 0.7532 - val_loss: 0.7495\n",
      "Epoch 39/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9116 - loss: 0.2203 - val_accuracy: 0.7532 - val_loss: 0.7602\n",
      "Epoch 40/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9222 - loss: 0.2202 - val_accuracy: 0.7922 - val_loss: 0.7287\n",
      "Epoch 41/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9120 - loss: 0.2149 - val_accuracy: 0.7532 - val_loss: 0.7413\n",
      "Epoch 42/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9137 - loss: 0.2248 - val_accuracy: 0.7792 - val_loss: 0.7314\n",
      "Epoch 43/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9099 - loss: 0.2317 - val_accuracy: 0.7403 - val_loss: 0.8080\n",
      "Epoch 44/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9190 - loss: 0.2155 - val_accuracy: 0.7532 - val_loss: 0.8249\n",
      "Epoch 45/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9246 - loss: 0.1904 - val_accuracy: 0.7532 - val_loss: 0.7971\n",
      "Epoch 46/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9229 - loss: 0.2088 - val_accuracy: 0.7532 - val_loss: 0.8268\n",
      "Epoch 47/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9479 - loss: 0.1555 - val_accuracy: 0.7532 - val_loss: 0.8336\n",
      "Epoch 48/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9298 - loss: 0.1815 - val_accuracy: 0.7532 - val_loss: 0.8437\n",
      "Epoch 49/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9261 - loss: 0.2028 - val_accuracy: 0.7273 - val_loss: 0.8873\n",
      "Epoch 50/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9562 - loss: 0.1465 - val_accuracy: 0.7532 - val_loss: 0.8587\n",
      "Epoch 51/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9414 - loss: 0.1735 - val_accuracy: 0.7792 - val_loss: 0.8702\n",
      "Epoch 52/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9387 - loss: 0.1852 - val_accuracy: 0.7662 - val_loss: 0.9300\n",
      "Epoch 53/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9194 - loss: 0.2022 - val_accuracy: 0.7532 - val_loss: 0.9042\n",
      "Epoch 54/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9269 - loss: 0.2039 - val_accuracy: 0.7403 - val_loss: 0.9034\n",
      "Epoch 55/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9445 - loss: 0.1592 - val_accuracy: 0.7532 - val_loss: 0.9170\n",
      "Epoch 56/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9264 - loss: 0.1797 - val_accuracy: 0.7273 - val_loss: 0.9772\n",
      "Epoch 57/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9316 - loss: 0.1815 - val_accuracy: 0.7662 - val_loss: 0.9139\n",
      "Epoch 58/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9285 - loss: 0.1763 - val_accuracy: 0.7403 - val_loss: 0.9674\n",
      "Epoch 59/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9434 - loss: 0.1467 - val_accuracy: 0.7662 - val_loss: 0.9845\n",
      "Epoch 60/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9439 - loss: 0.1533 - val_accuracy: 0.7662 - val_loss: 0.9700\n",
      "Epoch 61/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9444 - loss: 0.1490 - val_accuracy: 0.7662 - val_loss: 0.9923\n",
      "Epoch 62/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9373 - loss: 0.1497 - val_accuracy: 0.7403 - val_loss: 1.0471\n",
      "Epoch 63/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9403 - loss: 0.1559 - val_accuracy: 0.7662 - val_loss: 0.9870\n",
      "Epoch 64/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9447 - loss: 0.1482 - val_accuracy: 0.7532 - val_loss: 1.0398\n",
      "Epoch 65/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9545 - loss: 0.1413 - val_accuracy: 0.7662 - val_loss: 0.9955\n",
      "Epoch 66/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9592 - loss: 0.1165 - val_accuracy: 0.7403 - val_loss: 1.0596\n",
      "Epoch 67/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9534 - loss: 0.1311 - val_accuracy: 0.7792 - val_loss: 1.0704\n",
      "Epoch 68/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9568 - loss: 0.1123 - val_accuracy: 0.7532 - val_loss: 1.0881\n",
      "Epoch 69/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9568 - loss: 0.1169 - val_accuracy: 0.7532 - val_loss: 1.0613\n",
      "Epoch 70/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9522 - loss: 0.1185 - val_accuracy: 0.7273 - val_loss: 1.1310\n",
      "Epoch 71/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9540 - loss: 0.1152 - val_accuracy: 0.7662 - val_loss: 1.1226\n",
      "Epoch 72/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9524 - loss: 0.1099 - val_accuracy: 0.7792 - val_loss: 1.1301\n",
      "Epoch 73/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9740 - loss: 0.0902 - val_accuracy: 0.7532 - val_loss: 1.2036\n",
      "Epoch 74/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9622 - loss: 0.1065 - val_accuracy: 0.7532 - val_loss: 1.2183\n",
      "Epoch 75/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9567 - loss: 0.1045 - val_accuracy: 0.7662 - val_loss: 1.1400\n",
      "Epoch 76/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9602 - loss: 0.1095 - val_accuracy: 0.7532 - val_loss: 1.1806\n",
      "Epoch 77/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9574 - loss: 0.1228 - val_accuracy: 0.7792 - val_loss: 1.1671\n",
      "Epoch 78/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9735 - loss: 0.0958 - val_accuracy: 0.7403 - val_loss: 1.1085\n",
      "Epoch 79/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9497 - loss: 0.1456 - val_accuracy: 0.7662 - val_loss: 1.2277\n",
      "Epoch 80/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9184 - loss: 0.1860 - val_accuracy: 0.7532 - val_loss: 1.1431\n",
      "Epoch 81/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9458 - loss: 0.1291 - val_accuracy: 0.7662 - val_loss: 1.0979\n",
      "Epoch 82/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9701 - loss: 0.0969 - val_accuracy: 0.7662 - val_loss: 1.1048\n",
      "Epoch 83/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9800 - loss: 0.0764 - val_accuracy: 0.7662 - val_loss: 1.1076\n",
      "Epoch 84/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9660 - loss: 0.0795 - val_accuracy: 0.7532 - val_loss: 1.1722\n",
      "Epoch 85/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9639 - loss: 0.0938 - val_accuracy: 0.7922 - val_loss: 1.1831\n",
      "Epoch 86/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9664 - loss: 0.0997 - val_accuracy: 0.7662 - val_loss: 1.1881\n",
      "Epoch 87/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9810 - loss: 0.0663 - val_accuracy: 0.7792 - val_loss: 1.2114\n",
      "Epoch 88/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9773 - loss: 0.0775 - val_accuracy: 0.7662 - val_loss: 1.2090\n",
      "Epoch 89/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9784 - loss: 0.0648 - val_accuracy: 0.7662 - val_loss: 1.2595\n",
      "Epoch 90/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9726 - loss: 0.0811 - val_accuracy: 0.7273 - val_loss: 1.2152\n",
      "Epoch 91/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9659 - loss: 0.0900 - val_accuracy: 0.7532 - val_loss: 1.2295\n",
      "Epoch 92/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9794 - loss: 0.0633 - val_accuracy: 0.7662 - val_loss: 1.2709\n",
      "Epoch 93/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9873 - loss: 0.0475 - val_accuracy: 0.7792 - val_loss: 1.2750\n",
      "Epoch 94/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9867 - loss: 0.0535 - val_accuracy: 0.7532 - val_loss: 1.3090\n",
      "Epoch 95/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9596 - loss: 0.0883 - val_accuracy: 0.7403 - val_loss: 1.3164\n",
      "Epoch 96/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9750 - loss: 0.0677 - val_accuracy: 0.7403 - val_loss: 1.3248\n",
      "Epoch 97/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9773 - loss: 0.0540 - val_accuracy: 0.7532 - val_loss: 1.3250\n",
      "Epoch 98/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9830 - loss: 0.0581 - val_accuracy: 0.7792 - val_loss: 1.3582\n",
      "Epoch 99/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9783 - loss: 0.0488 - val_accuracy: 0.7532 - val_loss: 1.3941\n",
      "Epoch 100/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9821 - loss: 0.0529 - val_accuracy: 0.7792 - val_loss: 1.4014\n",
      "Epoch 101/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9875 - loss: 0.0445 - val_accuracy: 0.7532 - val_loss: 1.4278\n",
      "Epoch 102/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9710 - loss: 0.0692 - val_accuracy: 0.7532 - val_loss: 1.3740\n",
      "Epoch 103/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9628 - loss: 0.0819 - val_accuracy: 0.7403 - val_loss: 1.4471\n",
      "Epoch 104/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9753 - loss: 0.0663 - val_accuracy: 0.7662 - val_loss: 1.4344\n",
      "Epoch 105/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9878 - loss: 0.0410 - val_accuracy: 0.7792 - val_loss: 1.4194\n",
      "Epoch 106/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9728 - loss: 0.0534 - val_accuracy: 0.7532 - val_loss: 1.4788\n",
      "Epoch 107/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9708 - loss: 0.0690 - val_accuracy: 0.7792 - val_loss: 1.4561\n",
      "Epoch 108/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9789 - loss: 0.0533 - val_accuracy: 0.7532 - val_loss: 1.3982\n",
      "Epoch 109/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9871 - loss: 0.0418 - val_accuracy: 0.7792 - val_loss: 1.4802\n",
      "Epoch 110/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9850 - loss: 0.0400 - val_accuracy: 0.7662 - val_loss: 1.4827\n",
      "Epoch 111/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9941 - loss: 0.0289 - val_accuracy: 0.7792 - val_loss: 1.4723\n",
      "Epoch 112/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9784 - loss: 0.0489 - val_accuracy: 0.7662 - val_loss: 1.5044\n",
      "Epoch 113/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9864 - loss: 0.0393 - val_accuracy: 0.7532 - val_loss: 1.5130\n",
      "Epoch 114/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9908 - loss: 0.0285 - val_accuracy: 0.7662 - val_loss: 1.5254\n",
      "Epoch 115/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9829 - loss: 0.0360 - val_accuracy: 0.7662 - val_loss: 1.5555\n",
      "Epoch 116/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9901 - loss: 0.0282 - val_accuracy: 0.7532 - val_loss: 1.6243\n",
      "Epoch 117/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9804 - loss: 0.0436 - val_accuracy: 0.7273 - val_loss: 1.6420\n",
      "Epoch 118/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9823 - loss: 0.0428 - val_accuracy: 0.7532 - val_loss: 1.5820\n",
      "Epoch 119/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9807 - loss: 0.0500 - val_accuracy: 0.7273 - val_loss: 1.7727\n",
      "Epoch 120/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9567 - loss: 0.1276 - val_accuracy: 0.7273 - val_loss: 1.6672\n",
      "Epoch 121/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9642 - loss: 0.0957 - val_accuracy: 0.7273 - val_loss: 1.8081\n",
      "Epoch 122/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9747 - loss: 0.0721 - val_accuracy: 0.7532 - val_loss: 1.5911\n",
      "Epoch 123/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9825 - loss: 0.0472 - val_accuracy: 0.7662 - val_loss: 1.5258\n",
      "Epoch 124/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9691 - loss: 0.0757 - val_accuracy: 0.7792 - val_loss: 1.5207\n",
      "Epoch 125/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9800 - loss: 0.0494 - val_accuracy: 0.7403 - val_loss: 1.5947\n",
      "Epoch 126/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9714 - loss: 0.1271 - val_accuracy: 0.7143 - val_loss: 1.8217\n",
      "Epoch 127/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9604 - loss: 0.0946 - val_accuracy: 0.7532 - val_loss: 1.3752\n",
      "Epoch 128/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9688 - loss: 0.0559 - val_accuracy: 0.7922 - val_loss: 1.4236\n",
      "Epoch 129/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9859 - loss: 0.0399 - val_accuracy: 0.7532 - val_loss: 1.4326\n",
      "Epoch 130/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0344 - val_accuracy: 0.7403 - val_loss: 1.4607\n",
      "Epoch 131/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9895 - loss: 0.0272 - val_accuracy: 0.7403 - val_loss: 1.4628\n",
      "Epoch 132/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9857 - loss: 0.0301 - val_accuracy: 0.7922 - val_loss: 1.4859\n",
      "Epoch 133/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9955 - loss: 0.0233 - val_accuracy: 0.7273 - val_loss: 1.5297\n",
      "Epoch 134/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9924 - loss: 0.0211 - val_accuracy: 0.7792 - val_loss: 1.5745\n",
      "Epoch 135/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9897 - loss: 0.0346 - val_accuracy: 0.7532 - val_loss: 1.5540\n",
      "Epoch 136/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9876 - loss: 0.0305 - val_accuracy: 0.7792 - val_loss: 1.5608\n",
      "Epoch 137/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9934 - loss: 0.0167 - val_accuracy: 0.7922 - val_loss: 1.6078\n",
      "Epoch 138/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9865 - loss: 0.0249 - val_accuracy: 0.7792 - val_loss: 1.6000\n",
      "Epoch 139/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9944 - loss: 0.0237 - val_accuracy: 0.7792 - val_loss: 1.6121\n",
      "Epoch 140/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9964 - loss: 0.0160 - val_accuracy: 0.7662 - val_loss: 1.6076\n",
      "Epoch 141/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9975 - loss: 0.0139 - val_accuracy: 0.7662 - val_loss: 1.6274\n",
      "Epoch 142/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9948 - loss: 0.0165 - val_accuracy: 0.7792 - val_loss: 1.6369\n",
      "Epoch 143/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9945 - loss: 0.0173 - val_accuracy: 0.7792 - val_loss: 1.6811\n",
      "Epoch 144/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9960 - loss: 0.0177 - val_accuracy: 0.7532 - val_loss: 1.7297\n",
      "Epoch 145/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9946 - loss: 0.0216 - val_accuracy: 0.7922 - val_loss: 1.6998\n",
      "Epoch 146/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9879 - loss: 0.0266 - val_accuracy: 0.7792 - val_loss: 1.6526\n",
      "Epoch 147/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9916 - loss: 0.0228 - val_accuracy: 0.7922 - val_loss: 1.6953\n",
      "Epoch 148/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9962 - loss: 0.0119 - val_accuracy: 0.7532 - val_loss: 1.7152\n",
      "Epoch 149/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9911 - loss: 0.0195 - val_accuracy: 0.7403 - val_loss: 1.7072\n",
      "Epoch 150/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9981 - loss: 0.0186 - val_accuracy: 0.8182 - val_loss: 1.8012\n",
      "Epoch 151/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9956 - loss: 0.0173 - val_accuracy: 0.7792 - val_loss: 1.7722\n",
      "Epoch 152/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9957 - loss: 0.0131 - val_accuracy: 0.7922 - val_loss: 1.7905\n",
      "Epoch 153/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9944 - loss: 0.0136 - val_accuracy: 0.7662 - val_loss: 1.8158\n",
      "Epoch 154/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9945 - loss: 0.0137 - val_accuracy: 0.7662 - val_loss: 1.8429\n",
      "Epoch 155/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9963 - loss: 0.0138 - val_accuracy: 0.7792 - val_loss: 1.8180\n",
      "Epoch 156/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9975 - loss: 0.0093 - val_accuracy: 0.7662 - val_loss: 1.8493\n",
      "Epoch 157/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9965 - loss: 0.0122 - val_accuracy: 0.7792 - val_loss: 1.8398\n",
      "Epoch 158/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9968 - loss: 0.0087 - val_accuracy: 0.7662 - val_loss: 1.8799\n",
      "Epoch 159/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9996 - loss: 0.0114 - val_accuracy: 0.7662 - val_loss: 1.8233\n",
      "Epoch 160/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9901 - loss: 0.0160 - val_accuracy: 0.7792 - val_loss: 1.8915\n",
      "Epoch 161/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9970 - loss: 0.0084 - val_accuracy: 0.7922 - val_loss: 1.8716\n",
      "Epoch 162/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9927 - loss: 0.0199 - val_accuracy: 0.7403 - val_loss: 1.9133\n",
      "Epoch 163/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9892 - loss: 0.0300 - val_accuracy: 0.7532 - val_loss: 1.9725\n",
      "Epoch 164/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9829 - loss: 0.0365 - val_accuracy: 0.7403 - val_loss: 1.8839\n",
      "Epoch 165/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9755 - loss: 0.0677 - val_accuracy: 0.7403 - val_loss: 1.9835\n",
      "Epoch 166/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9785 - loss: 0.0423 - val_accuracy: 0.7403 - val_loss: 1.9009\n",
      "Epoch 167/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9916 - loss: 0.0264 - val_accuracy: 0.7403 - val_loss: 2.0148\n",
      "Epoch 168/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9966 - loss: 0.0145 - val_accuracy: 0.7532 - val_loss: 1.9365\n",
      "Epoch 169/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9914 - loss: 0.0179 - val_accuracy: 0.7662 - val_loss: 1.9432\n",
      "Epoch 170/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9926 - loss: 0.0123 - val_accuracy: 0.7662 - val_loss: 1.9891\n",
      "Epoch 171/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9982 - loss: 0.0068 - val_accuracy: 0.7662 - val_loss: 1.9996\n",
      "Epoch 172/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9997 - loss: 0.0082 - val_accuracy: 0.7662 - val_loss: 2.0128\n",
      "Epoch 173/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9989 - loss: 0.0084 - val_accuracy: 0.7532 - val_loss: 2.0412\n",
      "Epoch 174/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9930 - loss: 0.0109 - val_accuracy: 0.7403 - val_loss: 2.0223\n",
      "Epoch 175/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9961 - loss: 0.0097 - val_accuracy: 0.7532 - val_loss: 2.0355\n",
      "Epoch 176/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9960 - loss: 0.0098 - val_accuracy: 0.7662 - val_loss: 2.1080\n",
      "Epoch 177/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9972 - loss: 0.0119 - val_accuracy: 0.7532 - val_loss: 2.0058\n",
      "Epoch 178/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9988 - loss: 0.0074 - val_accuracy: 0.7662 - val_loss: 2.1071\n",
      "Epoch 179/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0098 - val_accuracy: 0.7792 - val_loss: 2.0148\n",
      "Epoch 180/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9973 - loss: 0.0074 - val_accuracy: 0.7662 - val_loss: 2.0869\n",
      "Epoch 181/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9975 - loss: 0.0095 - val_accuracy: 0.7922 - val_loss: 2.0590\n",
      "Epoch 182/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9997 - loss: 0.0066 - val_accuracy: 0.7922 - val_loss: 2.0685\n",
      "Epoch 183/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9998 - loss: 0.0038 - val_accuracy: 0.7662 - val_loss: 2.1027\n",
      "Epoch 184/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9998 - loss: 0.0076 - val_accuracy: 0.7792 - val_loss: 2.0889\n",
      "Epoch 185/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9997 - loss: 0.0043 - val_accuracy: 0.7792 - val_loss: 2.1064\n",
      "Epoch 186/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.7662 - val_loss: 2.1236\n",
      "Epoch 187/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9977 - loss: 0.0079 - val_accuracy: 0.7532 - val_loss: 2.1608\n",
      "Epoch 188/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0055 - val_accuracy: 0.7792 - val_loss: 2.1503\n",
      "Epoch 189/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9999 - loss: 0.0042 - val_accuracy: 0.7792 - val_loss: 2.1619\n",
      "Epoch 190/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9970 - loss: 0.0061 - val_accuracy: 0.7792 - val_loss: 2.1521\n",
      "Epoch 191/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9989 - loss: 0.0047 - val_accuracy: 0.7792 - val_loss: 2.1732\n",
      "Epoch 192/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0066 - val_accuracy: 0.7792 - val_loss: 2.1738\n",
      "Epoch 193/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9989 - loss: 0.0039 - val_accuracy: 0.7792 - val_loss: 2.1974\n",
      "Epoch 194/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9997 - loss: 0.0027 - val_accuracy: 0.8052 - val_loss: 2.1986\n",
      "Epoch 195/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9996 - loss: 0.0025 - val_accuracy: 0.7662 - val_loss: 2.2125\n",
      "Epoch 196/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9989 - loss: 0.0093 - val_accuracy: 0.7792 - val_loss: 2.3085\n",
      "Epoch 197/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9973 - loss: 0.0116 - val_accuracy: 0.7403 - val_loss: 2.2325\n",
      "Epoch 198/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.7662 - val_loss: 2.1886\n",
      "Epoch 199/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9997 - loss: 0.0066 - val_accuracy: 0.7792 - val_loss: 2.2185\n",
      "Epoch 200/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9987 - loss: 0.0041 - val_accuracy: 0.7662 - val_loss: 2.2604\n",
      "Epoch 201/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.7662 - val_loss: 2.2677\n",
      "Epoch 202/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.7922 - val_loss: 2.2556\n",
      "Epoch 203/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9987 - loss: 0.0037 - val_accuracy: 0.7662 - val_loss: 2.3016\n",
      "Epoch 204/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9974 - loss: 0.0052 - val_accuracy: 0.7662 - val_loss: 2.3305\n",
      "Epoch 205/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.7792 - val_loss: 2.2722\n",
      "Epoch 206/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9974 - loss: 0.0075 - val_accuracy: 0.7662 - val_loss: 2.2821\n",
      "Epoch 207/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.7792 - val_loss: 2.2909\n",
      "Epoch 208/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.7662 - val_loss: 2.3160\n",
      "Epoch 209/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9978 - loss: 0.0056 - val_accuracy: 0.7662 - val_loss: 2.3762\n",
      "Epoch 210/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9963 - loss: 0.0081 - val_accuracy: 0.7792 - val_loss: 2.3008\n",
      "Epoch 211/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9991 - loss: 0.0036 - val_accuracy: 0.8052 - val_loss: 2.3125\n",
      "Epoch 212/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.7662 - val_loss: 2.3376\n",
      "Epoch 213/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.7662 - val_loss: 2.3507\n",
      "Epoch 214/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9970 - loss: 0.0087 - val_accuracy: 0.7662 - val_loss: 2.3879\n",
      "Epoch 215/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9999 - loss: 0.0016 - val_accuracy: 0.7662 - val_loss: 2.3590\n",
      "Epoch 216/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9966 - loss: 0.0103 - val_accuracy: 0.7403 - val_loss: 2.8592\n",
      "Epoch 217/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9381 - loss: 0.2459 - val_accuracy: 0.7013 - val_loss: 2.6544\n",
      "Epoch 218/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9064 - loss: 0.4838 - val_accuracy: 0.6753 - val_loss: 2.0266\n",
      "Epoch 219/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9544 - loss: 0.1254 - val_accuracy: 0.7792 - val_loss: 1.6528\n",
      "Epoch 220/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9780 - loss: 0.0766 - val_accuracy: 0.7143 - val_loss: 1.7298\n",
      "Epoch 221/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9818 - loss: 0.0480 - val_accuracy: 0.7532 - val_loss: 1.6793\n",
      "Epoch 222/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9958 - loss: 0.0225 - val_accuracy: 0.7532 - val_loss: 1.6438\n",
      "Epoch 223/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9960 - loss: 0.0222 - val_accuracy: 0.7662 - val_loss: 1.7699\n",
      "Epoch 224/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9972 - loss: 0.0113 - val_accuracy: 0.7662 - val_loss: 1.7773\n",
      "Epoch 225/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0124 - val_accuracy: 0.7662 - val_loss: 1.7655\n",
      "Epoch 226/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9993 - loss: 0.0077 - val_accuracy: 0.7662 - val_loss: 1.7895\n",
      "Epoch 227/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9976 - loss: 0.0116 - val_accuracy: 0.7662 - val_loss: 1.8086\n",
      "Epoch 228/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.0069 - val_accuracy: 0.7532 - val_loss: 1.8234\n",
      "Epoch 229/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.7532 - val_loss: 1.8429\n",
      "Epoch 230/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.7792 - val_loss: 1.8461\n",
      "Epoch 231/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0067 - val_accuracy: 0.7403 - val_loss: 1.8802\n",
      "Epoch 232/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9937 - loss: 0.0124 - val_accuracy: 0.7532 - val_loss: 1.8661\n",
      "Epoch 233/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9998 - loss: 0.0054 - val_accuracy: 0.7662 - val_loss: 1.8827\n",
      "Epoch 234/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.7532 - val_loss: 1.9113\n",
      "Epoch 235/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9991 - loss: 0.0059 - val_accuracy: 0.7662 - val_loss: 1.9271\n",
      "Epoch 236/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9993 - loss: 0.0047 - val_accuracy: 0.7403 - val_loss: 1.9482\n",
      "Epoch 237/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9980 - loss: 0.0060 - val_accuracy: 0.7662 - val_loss: 1.9280\n",
      "Epoch 238/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9976 - loss: 0.0050 - val_accuracy: 0.7662 - val_loss: 1.9440\n",
      "Epoch 239/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9983 - loss: 0.0048 - val_accuracy: 0.7532 - val_loss: 1.9482\n",
      "Epoch 240/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9946 - loss: 0.0069 - val_accuracy: 0.7662 - val_loss: 1.9530\n",
      "Epoch 241/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9988 - loss: 0.0036 - val_accuracy: 0.7792 - val_loss: 1.9625\n",
      "Epoch 242/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.7532 - val_loss: 1.9758\n",
      "Epoch 243/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9972 - loss: 0.0047 - val_accuracy: 0.7532 - val_loss: 2.0002\n",
      "Epoch 244/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9990 - loss: 0.0067 - val_accuracy: 0.7662 - val_loss: 2.0256\n",
      "Epoch 245/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.7532 - val_loss: 2.0396\n",
      "Epoch 246/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.7662 - val_loss: 1.9984\n",
      "Epoch 247/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9989 - loss: 0.0039 - val_accuracy: 0.7532 - val_loss: 2.0250\n",
      "Epoch 248/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9996 - loss: 0.0023 - val_accuracy: 0.7662 - val_loss: 2.0103\n",
      "Epoch 249/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9974 - loss: 0.0044 - val_accuracy: 0.7662 - val_loss: 2.0328\n",
      "Epoch 250/250\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0022 - val_accuracy: 0.7662 - val_loss: 2.0482\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x,y, epochs=250,batch_size=32,validation_split=0.1,verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba9da544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a5544b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f7d27cfb20>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAACE5UlEQVR4nO2dd5hbxdn2b0kraXvv6/W613UBGxuMTcfgBAKBgCGEFiA4tFDClxDevKST6pCEkvAGQuikACGhxYAxNsYVg3tdr9deb++r7dL5/hiNTtHRWtpV2XL/rkuXpKNzdOa0mXue55lnLIqiKCCEEEIIiRHWWBeAEEIIIaMbihFCCCGExBSKEUIIIYTEFIoRQgghhMQUihFCCCGExBSKEUIIIYTEFIoRQgghhMQUihFCCCGExJS4WBcgGDweD44fP46UlBRYLJZYF4cQQgghQaAoCtra2lBYWAirNbD9Y1iIkePHj6O4uDjWxSCEEELIADh69CjGjBkT8PdhIUZSUlIAiINJTU2NcWkIIYQQEgytra0oLi72teOBGBZiRLpmUlNTKUYIIYSQYcaJQiwYwEoIIYSQmEIxQgghhJCYQjFCCCGEkJhCMUIIIYSQmEIxQgghhJCYQjFCCCGEkJhCMUIIIYSQmEIxQgghhJCYQjFCCCGEkJgSshj56KOPcPHFF6OwsBAWiwWvv/76CbdZs2YN5s2bh/j4eEyYMAF//OMfB1JWQgghhIxAQhYjLpcLc+bMwaOPPhrU+ocPH8YXvvAFLFmyBNu2bcP3vvc93HXXXfjnP/8ZcmEJIYQQMvIIeW6aZcuWYdmyZUGv/8c//hFjx47FI488AgCYPn06tmzZgl//+te4/PLLQ909IYQQQkYYEZ8o75NPPsHSpUt1yy644AI89dRT6O3thd1u99umu7sb3d3dvu+tra2RLiYhhJAg2VnZgo8O1OGaBSVIS/SvwwfKugP1OFjbhqsWjEW83ab77fOjzVh/qAHXnDoWqfFin+3dfXhhwxFMzEnGudNzfZOxfbS/DjuPt+CahSVIS9CX72BtG/6xtRLdfW6kJzjwtVPHIivZGbZj6I/1B+vx/t5aeBQF47KScNWCYjjj9Me5ubwRGw414KoFY5GTEny52rv78PKmCswek44F4zN9y9ceqMOH++rgURRMyE7C8lPGwhE39MJFIy5GqqurkZeXp1uWl5eHvr4+1NfXo6CgwG+bhx9+GD/84Q8jXTRCCIkIlc2d2FnZgvOn58Fq1c9W2tzRg48PNuDc6bl+DW442FLeiB2VLQCARROzMTW//6nbe/o8eH9PDeaOTUdBWoJv+a7jLdh0uNFv/YO17XhpUwU8CrB2fz2eu2kBth5pwu4q0WlcMD4TMwvT/Lb7tKIJnx9t9lvujLPhwtJ8HKhpww1/2YQ+j4KnPy7HT79ciiWTc9DW1YtfvbsPz204AkUB1h+qxzM3LsD7e2rw0Bu7UNXSBQA4d1ouFk/OxubyRry1oxoA8PS6cjx08QxcNLsA3X0ePLb6IP645hB63Ypv/8+sP4yvnz4eyfFxWDI5G5Ny+z9fA6GurRs/eXM3/vXZcd3yZz8px8++PAsLJ2ShuaMHD7+1F69sOQoA+PM6Ua7UBNFMWy0WnD4pC5NyU1DV0omNZY1YOjMPiY44rNpdg4f+tRPHW7rgiLPinysWIS/ViR/+Zzfe3F6l2+dzG47gyvnFsFn9Z9E9c0oOJuQkh/34g8GiKIpy4tUCbGyx4LXXXsOll14acJ0pU6bgxhtvxAMPPOBb9vHHH2Px4sWoqqpCfn6+3zZmlpHi4mK0tLQgNTV1oMUlhJCwU17vQll9Oxw2GxZOyIQFwIW/W4uDte2485xJuG/pVACAoih4/bNK/Pg/e9Do6sHlJ4/Bb66cE7Zy1Ld340f/3o03PlcbvOxkJz7+7tl+vW/J1iONeODVHdhf046CtHi8ccdiOO1W/FrT+AfCbrOg161gYk4SDtW5fMstFuDaU0tw1tQcAICiAG/uqMKrn1YG/K+MRDssFgsaXT2+/wWAC2bm4bOjzahpFe1BnNWCPo9+n/mp8WhwdesEhs1qQX5qPCqbOwEASyZn41hTJw7Xi23OnJKD0qJUvL+nFnur23zbOeOs+MeKRZg1xl9MBaKr1439NW2YVZQGi8WChvZufH6s2ff7kYYOPPLeAbR09sJqAb580hhkpzjwz62VqG8Xx/WFWfnYWNaIBlcPAGBMRgKONXX67SvOasEXZxdg1e4adPS4UZSegGn5KXh/by0A9ZrkpDjR1etGW1cfbFYLLj+5CBmJDvxj6zHfPsz4/dUn4UtzCoM+9mBobW1FWlraCdvviFtG8vPzUV1drVtWW1uLuLg4ZGVlmW7jdDrhdEbHbEYIGZ20dPQiJT4OVqsFiqKgpbMX6YmOkP7j3V3V+ObzW+HxtoMLxmXi4rmFOFjbDgD4wwcHMTYzEZNyk/Gb/+7HuoP1vm1f3XYMt5wxHuOzk9DV4wnJ3dHc0YP69m7EWa0Ym5kIV08flv/pExyqc8FqAc6ZloctRxpR396N/+6qwcUmDczGsgZc8+eN6PMWvqqlCzf8ZRPq2rpR2yYayTOm5Pi5Oew2Cy6dW4SOnj6seP5THKpzwWa14Jxpueju8+Cj/XV49pMjePaTI7rtLBbgnKm5SHTqm529Va044D1f0/JT8OxNC/DEh4fw1/XleHdXDQBgXFYifvrlWahv78a3Xv4Mh+pciLNacMsZE3DXOZNxrKkDT39cjvbuPiTabbj2tBJMzkvGHz8sw2OrD2LtAXHec1Oc+OGXZuLC0nxYLBbcfd4UvLDhCLZWNONQbTt2V7Xi1ue24N93Lg7adfOTN3fj+Q0V+MYZE3DFvDG47PH1aOvu81tvZmEqHr5sFmaPSQcA3HbmJPzi3b14cWOFz5IzOTcZD182C3OL0/HSpgpsKm/ybV/X1oUNZY0+60q83YrK5k5UNnf6zsWNi8bhqic3oMwrumaPScPPvjwLpUVCXK04cyL+9FGZT6QZKUqPD+qYI0HELSPf+c538O9//xu7d+/2LfvmN7+Jzz77DJ988klQ+wlWWRFCiBk9fR4oEFVdR7cbK1ftx/Mbj2DJ5Bw8df183PPKZ/jP9ipcdnIR/ueLM5CZJESJoii+OAQA6HV74PFWmeX1Hbj8ifVo7+7DhJwkVLd0oaPHDYtFWAMm5Sb7RInEGWfFXedOxvZjzXh3Vw1mFaWhtq0LTa5e3H72JKw4a0JAK4bkaGMHzlu5Bt19HgDAnDFpSE2wY+2BeuSnxuP/rpuPWWPSsPK/+/D7Dw5i0cQsvHjLqehze+D2lr22tRtffvxj1Lf34LzpufjmWRNx/dOb0e5tRMdnJ+Gnl5Zi0aTsfsvy/IYj+PhgPe44Z5LPNbP+YD2eWHMIrZ29vvUykxy469zJOGlsht9/9Lo9+Ov6cmwpb8KDX5yO4sxEAMD2Y834/fsHUVqUihVnTvS5tP7y8WFsKW/CnedOwrT8E7cHh+rasfK/+1GQFo+7zpvsizcx0trVi0sf/Rhl9S5cdlIRVi6fe8L/bu3qxYKfvoeuXnEtspMdqG/vQUFaPHK98R42qwVfnF2I608rQZzNP1ZjS3kjHv/wEE4Zl4mbFo/vN55j1e4aPL/hCJaV5uPiOYV4/MODOFjbjnvOn+I7F4fq2vHzt/di8aRsfO3UElN3TDQJtv0OWYy0t7fj4MGDAICTTjoJK1euxNlnn43MzEyMHTsWDzzwACorK/Hss88CEEN7S0tLceutt+KWW27BJ598ghUrVuCll14KejQNxQghZCAoioIf/2cPnll/2Ge9MDItP0Vnqs9ItON7X5iOrl4hWqbkpeDe86fgxU0V+Pfnx/3+Z+H4TDx/80J8tL8ONz+7BYoCFKUn4L/3nIEfvLEL7+0Rvft5JRn4/kUzUJKVhEN17Vj624/gNvzZqRMy8dItp+oEkJEXNh7Bg6/thMPbsPW4RUPoiLPi77eehjnF6QCAY00dWPLL1VAU4EtzCvHWjiqfFUQyvSAVr35zERIcNny4rxY/fXMPLizNx+1nT4pIPMtQ552d1Vjx/FbMHpOGN+5YfML1n/ukHN//1y6da6kwLT4ky8pIJ2Jumi1btuDss8/2fb/33nsBANdffz2eeeYZVFVVoaKiwvf7+PHj8dZbb+Gee+7BY489hsLCQvz+97/nsF5CyIB54/PjeHz1Qfzi8tm+xteMZ9aX4+mPD/stn5iThIvnFOKR9w74hMg3z5qI1XtFDMH9/9juW3fj4UYsf3KD6f9Py0/BY9ecDLvNinOn5+GBZdPwq3f34X++OB1Jzjj86grzmJCJOcm47ayJeHrdYdy0ZAIm5iTh/r9vx4ayRhyud/UbRLjVa7pfceYEfO3UEvzwP7vxwZ5a/OyyUt25GJORiLOm5GD1vjpdHIlkXFYinrx2HhIcQnScNTUXZ03NDbjf0UBqvGgSu72Wjv5QFAUvbBRt3XcunIbtx0TA75+unU8hMgAG5aaJFrSMEEIk2yqasPxPG9Dj9mD2mDT86/bTYbFYUNHQgd++tx+V3sA/BQo+rWiG26PggWXTcPXCsb7/SHHGwWKx4Ler9uN37x/ADYvG4QdfmoletwdPrTuMR97bjzirFXedOwkbyxrx/t5alBal4seXlGJirioUkh1xfqNlPB7Fb1kgtG6gq5/cgE/KGvDjS2bi2tPGBdzmzF+txpGGDjxz4yk+8RBon+sP1uPapzdhXFYifnxpqS92AACSHHExN+EPNbYeacTlT3yCkqxErLn/7H7X3VbRhC8/vh7OOCs2fu9cpCc6Qrr2o4UhE8BKCCHhoqyuHd98/lOfa2L7sRb8e3sVjjV14HfvHfDFUWi5dG4hvnHGBFPXxz3nT8H1i8b5YkTsNitWnDkRV51SDKvVgtR4O25ZMgGVzZ0oSEsIqvEOpTHSlmnx5Gx8UtaAdQfrA4qRurZuHGnogMUCXfxFoH0umpSNzQ+eh7QEO4VHEMh4nWAsI6t2C/fbBTPzfYHPFCIDh2KEEBKQ8noX1h6ow0WzC5GRZD7SpKG9G2/trMblJxch0RGZKqWnz4M/rTmEP6w+iJ4+DyblJuPMKTl4at1h3PXSNt96iyZm4eoFY30Nb2q8HYsmZvUbg5FpclzaUTUWiwVjMhLDeDTmLJ6UjV+9uw/rDzXA7VFMxcPWI8JFMyU3xW+USyDMjo+YE28XcTjdfe4TriuvxemTzEeFktCgGCGE+OH2KHhs9UE86m38f/veAdx+9iRkJzswJS8F0wuEubWr143rnt6EXcdbsauyBT+/fHbYylDT2oUNZQ3o7vXgybVlvpEpSyZn4xeXz0ZKfBxe21aJRlcPMhLt+J8vzsBlJxf1KzyGMqVFaUiNj0NrVx92VLZgrkkszKcVogE8ucR/VAoZPNIy0nUCy0iv2+PLJTKP1yIsUIwQQgCI3BUWiwVpCXY8s74cK1ftBwCkJdjR6OrBj/8jhuc74qx4/94zMSYjAQ+8ugO7jovMm3/bchQ3L5mASbnhyeD4jWe34PNjLb7v2ckO/O/FM3Hx7AKf4Hjq+vlYf6gBVy8YO+wtADarBYsmZuOdXdV4fVslHDYrphek6MTVlnKREXU+G8CI4IxTLSPGYd1adh9vRVevB+mJdkzIjk3G0pHG0EtQTwiJOm1dvThv5UdY9shHaO3qxXOflAMA7r9gKjY/eB6+94VpWDI5G0XpCcJSsmo//vJxOV7bVgmb1YLpBanwKMDKVfvCUp6ePg92ekXOqRMycfPi8Xj/3rPwpTmFugbipLEZuP3sScNeiEhOnyzyejyzvhxf+P1aPLb6oO+3w/Uu7KwU54S98cjg9A5n9ijwGwatRbpoTh6bwTiRMEHLCCEEq/fV+VJTr3huK8obOpDsjMONp4+DI86Kb5wxEd84YyK2H2vGlx79GK99Vol/eYeLfu8L07F4UjYu/N1HeGtHNXYfb8WMwsGNejvS4ILboyDJYTth3o2RxEWzCvDGZ5Uoq3OhwdWDbRXNAMQkaN94dgt63B4sGJ+JkqzIx7CMRpyahGNdvW7YTZKUAaoYoSgMH7SMEDJEaWjvxqWPfYzf/PfE1ob9NW244Lcf4bv/3I6mfuae0PK3zUex9LdrsLe6Fe/uVKdsWH+oAQBw6UmFfgGps8ek44uzCqAoIq7k0rmF+Prp4zA1PwUXzhTzTJnltAgVGR8yMTd51AgRAMhIcuDvKxb55qyR85P88I1dOFDbjtwUJx69+qRRdU6iiVaMmI3MAsRw7C1HhLuMYiR8UIwQMkR5cWMFPjvajCc/KkNXrz663+NR8PO39+LB13agu8+NH/9nN/bVtOHlzUdx7so12O11cWg53tyJm/+6Bf/6TExY9vTHh7G/ph3ff30nVu8TE23lparJmq5eMNbvPwDg2xdMRYozDnOL0/HwZbN9DeMXZokZuN/dVY3Bpi86VCfEyKQYzSAaa+ToncrmTiiKgv96h5H++oo5yE2N3fwhIx2LxaKJGzEXI8dbulDT2g2b1YI53nlmyOChm4aQIYjbo+DlzWIq8e4+Dz490qSbJ+SR9/bjj2sOAQAO1LZj0+FG2G0WjM1MxKE6F/68rgwrr5zrW7+r141bn9uKHZUt2FPVirOn5WJfjcg8utmb0bMwLR6/uXIuvvbURswvyTCdBh4Q85ZsfPBc2G1WnRn77Gm5cNisOFzvwoHadkzJG/hU7FrLyGikKD0BgHDPHGnoQIt3npf549gTjzTOOCu6+zx+HQDJ9qPNAET2XZm9lgweihFCosyb26uQ6LDh7Gn+qbc/O9qMHZUtyEl26GbWXHewHmOzEvHixgo0d/bixY3qlAubDguT8TULS3D+jDxc8+eN+PhgvW40wIOv7cSOSjEypbK5E//67Ljf9PBLZ+bjtIlZeP/eM5GV3H9AqFk+kWRnHJZMzsb7e2vxzs7qE4qRXrcHr356DLkp8X7n4qC0jIxSMZLgsCEryYEGV49vpt/81PiI5XEhKk67DejqC5j4TE4fMKOA2cDDCe9sQqLI0cYO3P7ip7BYgKdvOAVna+YCae7owbVPbURblzr9eGFaPI63dGHdwXpsKW/CJu/QTgC4YdE45KQ48at39yHRYcMd50xCsjMOzjgralq7caiuHZNyU7CnqhX//PQYrBagIC0Blc2deMI7SuPMKTnYeqQJ7d19PjfLuOykAR/fBaX5PjFy17mTA663s7IF3/7759hb3QZnnBWfP7TUNzGbx6PgUK2YAn20ihEAGJORIMTIASFGxmUzaDUanCjx2T6vGJmaP3DLH/GHYoSQMHK8uRMJdlvAbKWbvWJCUYBvvbQNv/zKHKQl2HFySTqeWHNIJ0QA4BdfmY1rn9qE7d58G844K65fNA7jspJwxfwxiLNakJPsxLjsJGR7J+c6ZVwm1h2sx7oD9ZiUm4K3vcGp503Pw6yiNPxm1X4cb+kCAJw/Iw93nTsZRxpcWDA+c9DHf970PFgtwO6qVhxt7PBNB6+lu8+NG5/ZjLq2bu93D/ZVt/kmeTve0onOXjfsNgtKTLYfLRRlJODzYy1Yf0iIkfGDEIkkeE6U+GxvtYjHmpZPy0g4oRghJExUNnfi/JVrMDYzEW9/a4npiAc5JNBqAVq7+rDi+a0AgAnZST63zO+vPglHGzuQkejAksk5mJSb7IuhuGHRODzwhem6/7zylGLd99MnZQsxcrABN5w+Hv/dJcTIBTPzMT4nCb/xJjMDxGiA6QWpYRsVkJnkwMLxWfikrAHv7qrGzUsm+K3z3101qGvrRl6qE0XpCfi0QrimpBiRxzouKwlxAYZWjgZkEGurV6COy6IYiQbaxGdGOnr6cKSxAwAwrYCWkXAyep90QsLM2zuq0NHjxt7qNl28hxYpRn7wpZlYVpqPGQWpyEi0o6zehe4+D+aXZODi2QW4/exJ+Kp3ltnF3sDVlPg4fPOsiScsh1x/Q1kDDta2YW91G+KsFpw7PRezi9KQ4hR9kBRn3KCCTANxYakY4vuOZriwlpc2iXiX5aeMxakTxLweu46rmValGBnNLhpADWKV0DISHaS70Gw0zYGadiiKyAYsLZEkPFCMEBImtI2vFB1aWrt6fSNYLizNxxNfm4e3vrUEa/7f2bj+tBJMzUvBD74008+i8tWFYzEhJwk/uHimbgK3QMwsTEV6oh3t3X24/x/bAQCnTcxCeqIDcTYrTp0oBMDcsekRmcl16cw8AMDWiibUtnXpfjtc78L6Qw2wWIDlpxRjlndKexlcCwCH6hgvAoiYES0UI9FBWkbMRtPQRRM5KEYICQO1bV3YWqEKEDMx8llFMxQFGJuZiNwUNVdEarwdP7ykFO/ecwZKi/yH007JS8EH952Fy+eNCaosVqsFV3jXlRk8L/AmJAOAry4YC4fNiq8E+X+hUpCWgDnF6VAUdZp1ycteq8hZU3JQlJ7gO9591W0+s3iZdyTNhJzR3fgWacSIxQLT+BsSfvrLM7KXwasRg2KEkCDoc3vwP6/vwKufHjP9fdXuGigKEOe1NGjFyAd7a3D3y9vw961i22hkbXxg2XQ8fNkspMbHITPJoRMjZ0/Lxf6fLsMlc4sitn+ZjVVrLapv78ZzG44AEMOQAdH7T0+0o9etYH+1ECHlDcIyMn6UT0CmddMUpiX43AcksvTnpuFImshBMUJIEGw50oTnN1Tg1++ap2aXje413jiPPVWtcHX34fOjzVjx/Kd4/bPj+Lc3TXo0pn+3Wi24esFYbPzeefjgvjORkxJd//b5M4SrZmNZI3rdolJ/9IOD6OhxY86YNJw7XQxptlgsOldNR08falrFKJvxozxgMyXejrQEOwC6aKKJzzJicNMoiuKzjEynmybsUIwQEgRl3jiG+vYev1TnfW4PNpaJIbvXnjYORekJ8CgiLfqK57eip8+j6+UuDMMQ2mBJcNiCijMJNxNzkpAaH4cetwf7a9pwtLEDL2wUVpHvXDhNFxdTqhEj5fVipEJGoh1pifaol3uoIeNGKEaihxzaa7SMNHX0otE779PkvNFttYsEHNpLCIRbpbqlC444KxZPyvZL8yxdBz1uD9q6+5AarzaURxo70OP2INFhw4TsJMwryUBlcyfu/dvnAETsw79uPx27j7eiqaMnIiNYhhoWiwWlRWlYf6gBOytbcKjOhV63gsWTsnVp7QFgtleMbD/WjPIG8dtgEq+NJMZlJWHX8dZRH8wbTXxJzwyWkaoWMUIuO9lBl1kEoBgho55tFU24/In1vu83LR6P7180Q7fO4XqX73Nje49OjMihqBNykmC1WjCvJMM3c+2sojQ8+tWTkBJvx0LvMNbRwiyvGNlR2YIt3vlvlhtyogBiVA8gggN3ekfVjHYXjeTu8yZjfHYSvnxy5OJ7iB6nV2h0GSwjNa1iZFgeJyqMCBQjZNTz/h4xY22iw4aOHje2mIyEKdeIkQZXt67n7suL4Z1h9pK5hdh6pAnzSjLwtVNLIjJ8djgg3S8f7a9HhTdR1OkGqwggRt8UpSf45swBaBmRTM5LwbcvmBrrYowqAsWMVLeIWKaCNIqRSMCYETLqkRORXXfaOADA/uo2eDxqXIjbo+BIQ4fve0N7j277Q4YkXemJDvz+6pNw/aJxo1aIAPAFpkohMrMwFZkB0uTLoF6ZLI5ihMSKQKNpqr1uGlpGIgPFCBkVfLC3Buf85kOs3lurW97S2Yvtx5oBiJEwzjgrOnvdvgYUEPPN9LjViqnBpRcjo32G2UCUZCUiJV41vi42sYpI5htGGNFNQ2JFoKRn1V43TT7FSESgGCEjnv01bbjjxW0oq3PhTx8d0v22oawBHkXEexRnJvqi5OUQPkANXpU0asSIoih+lhEisFgsKC1Uk7iZuWgkxtwrnKGWxApnIMuId8h5Ht00EYFihIxIWjp78at39+L2Fz/FDU9vQkeP6OVsOtyIhvZu33ofe100stc+NU/kD9inFSP1ejFSr9m+qqULrh434qwWlLA378esMUKMOGxWnDIu8JDmafkpSPSOYMpOdiIlnsN6SWwIlIG1xjvTNWNGIgPFCBlxfLivFuf+Zg0eW30Ib26vwvGWLhSlJ2BSbjI8CvDeHjVFuYwXkb326d6ZOOUcFABw2Jv7wuGtpLSWERm8WpKVCPsonmE2EDKnyumTsvyGS2uJs1kx1ztr73haRUgMCeSmkUN76aaJDKw9yYiiz+3BXS9tQ317NybmJOH7F83ATy4txb/uOB2Xzi0EoGZLPdrYgbI6F6wW+GaPlWme95m4aeZ4e/naANZDjBfpl3Om5eIvN56CX10x54TrLhyvvwaExAKzANbOHjdau/oA0E0TKTi0l4wo9la3obWrDynxcXjrW0t82RQBMVPur/+7Hx8fbEBrVy/e3SVEycLxWb6027IhLG9wobPHjQSHzZdjZF5JJjaXN+kCWDndff9YLBacPTU3qHW/ccYEJDlt+JJXNBISC1Q3jWoZkcGriQ4bUpxsNiMBzyoZUcgJ6k4em6ETIgAwKTcFE3KSUFbnwlvbq3wWkgu8U94DQE6yE1lJDjS4evBJWT22H2vxWUZkkKU25kRaRibmUIwMlgSHDTcvmRDrYpBRjqw3unpVy4jPRZMWr5vKgIQPumnIiEKKkUAz417lzQC6ctV+bK0Q6y7VzGhrsVh81pGvP7MFj7x3AIoCXHZSEUqLRHBro0udn6auTSZCUueeIYQMX3zp4DWWkRoO6404FCNkRCHFiDFvheS608YhL9WJ2rZuKAowpzgdhel6IXHl/GKkxsch3m7F2MxEPPrVk/CbK+f4Enb1eRS0dgr/cVNHLwAgI4mjPwgZCfgmytNYRmT2VYqRyEE3DRm21LR24Vsvb8M1C0tw8ZxCVLV0orK5EzarBXO8IzOMxNttuPu8KXjg1R0A9C4ayaUnFeHSk/znAnHGCX9xW3cfGlzdSImPQ3OHiB/JjMHMuISQ8OO0+4+m8c1Lw+DViEHLCBm2/GPrMWwoa8T3Xt2BJlePzyoyvSAFSf0EmV0xbwymF6QiwW7DxbNDC5bMShaio8HVg7auPsis8ekUI4SMCMxG08iYEeYYiRy0jJBhixQfbd19eGLNIbi6hetk3lhzF40kzmbF31echo7uPuSGaHbNTHKgvKEDDe09aEwWVpEkh82Xg4QQMrzRJj1TFAUWi0XNvko3TcSgGCHDgqONHdhf04Zzpwu3isej4NMKdXbdP68t81kpZM6Q/kh2xiF5AEP0spKdAMTMvU0d4nNGgMnfCCHDD6emY9Hd50G83YZ6b6B6boozVsUa8bA7R2JOo6vHN0TWDEVRcOMzm3HTX7dgY1kDAKCs3oXmjl4446yYX5IBjwJYLcAtS8bjAs3omHCT5RUeje09aPLmG8mgi4aQEYN00wCqq6bda3XlNAWRg5YREnNu+utm7KxswXv3nmk6v8snZQ2+5GKbyxuxcEIWth5pBCBGw/x2+Vw8+0k5LppV6JsLJVJoY0bUkTQUI4SMFOKsFlgtgEeRw3vt6PTObZXYz5QGZHBQjJCYUtXSiW0VzQCAbRXNpmLkpU1HfZ93VLYA0A/hLUpPwAPLpke+sAAyk4SZtr69W2MZYW+JkJGCxWKBM86Gzl43uns96OnzoMctLCRJDjaZkYJuGhJT1h2o932W1g8tDe3deNebKRUAdlaKCey2nCC5WaSQeQaqW7rQ1EE3DSEjEW3iM2kVAdDvZI9kcFCMkIjyy3f24sa/bEJHT5/p7x8f7F+MvLSpAj1uj2/ul8rmThysbUdZnUjRfvIJRs6Em6IMkSDtWFMnxQghIxRtSviOXlF32W0WjpqLIDyzJGL0uT34v7VlWL2vDv/67Ljf74qiYN3BBt/3g3Xt6Op1466XtmHlqv1Ye6AOj7x3AACw4syJGJclppb/+dt7AQDTC1KjHq8xxitGatq6UOsd7sfsq4SMLJway4irW8aL0EUTSXh2ScQ40tiBXrcYb/vSpgpcvWCs7vf9Ne2ob+/2BYuV17vw9s4qvPG5Xrh8cXYBLj+5CGv216G8oQPv7akBAFw5f0x0DkRDVpID8XYruno92F0lXEa0jBAysojXpITvsAnLSBJdNBGFlhESFvrcHryyuQIVDR2+ZYc0bpftx1qw0xt8KlnnddGcPikbiQ4b+jwKXtxYAQCQE2NOy0/Br74yGxaLBbO8E9UBIhfAl01Stkcai8WCIu9cNlUtIkU0xQghIwvVMuJBhzdmhPEikYVihISFJ9eW4Tv/3IE7XvrUt+ygIXfIS5sqfJ+bXD34y8eHAQBLJmdjYo6ICdlcLgJTH736ZPzuqrl48ZZTfebR0iJ12O4XZxXELAV7UUai7jvdNISMLGTis65ety/erb8pJsjgoRghg6a5owdPfHgIgLCA7DgmLCAyIHXRRJER9Z+fHsOeqla4PQruenkbjjV1YmxmIpbPH+sLUAVEoNjZ03Jwydwi30y5gBAj0mLy1YV6l080KTLM8kvLCCEjC+38NGrMCC0jkYRSjwyaJ9YcQluXOlrmxU0VeHjMLJ+b5munlsBmtWDtgXrc+txW5KU6sbm8CQl2G568bh7SEu2YmKPmFzl5bIZpsFhqvB0/ubQULZ29UR/Sq0UGsUooRggZWajz07hhgegBMYA1stAyQgZFc0cPnvm4HADwjTMmAADe+KwS7d19OOQdfjs5Nxl/uPokFGcmoKKxwydEHrlqLqblizgQrWVk8aTsgPu7ZmEJbjtrEizSRBIDtGIk3m6lL5mQEYZ2aK/L66ahZSSyUIyQQfH5sRZ093kwLisRDyybhgnZSXD1uPGnNYfQ3t0Hm9WCkqwkpCc68OS18zE+OwkXzMzDqnvP0M0hoxUjp08OLEaGAloxQqsIISMP7dBeGcDK7KuRhWeXDIq93uGtMwvTYLFY8LVTS/Cj/+z2xZCUZCX6EgVNL0jF6m+fZfo/47KSMDUvBTarBbOLIju/zGApSlcDWClGCBl5ODVDe7v6OJomGlCMkEGxr7oNgBiCC4jA0v9bW+Yb9jopJzngtlribFa8c/cSeBTAZo2dCyYYclOcsNss6HUrHElDyAjEN5pGk/QsyUkxEknopiGDYo9XjEz1ipF4uw13nzfZ9/vE3ODECCByeAx1IQIAVqsFhd4RNbSMEDLy8I2m6fX4hvYygDWyUIyQAdPr9vhGzEwvUBOSXX7yGN/omJmFqabbDneKKEYIGbHIifI6etWYEQawRhZKPTJgyutd6HF7kOSw6XJvxNmseObGBfjoQB2WlRbEsISRoyQrEesPNSAnxRnrohBCwozsZDR39KCr1wOAAayRhmeXDBjpopmSnwKrwb1SnJmIaxaWxKJYUeEbZ0xEoiMOy08pjnVRCCFhRk7A2ejqgSKm10IiY0YiCsUICQlFUXw5PvZVi5E0MlfIaGJ8dhK+f9GMWBeDEBIBsjRiRMaP0E0TWRgzQoLm9W2VmPWD/+JH/94NV3ef30gaQggZCUg3TaOrF65uBrBGA55d4oeiKPj237ejx+3B76+a67OE/Hd3Ndq7+/D0x4fxty1H0dUrArumUowQQkYQWclCjDR19CDO64JmzEhkoWWE+FHR2IF/fnoM//78OGpau3XLASDJYUN7dx/6PArSE+262XQJIWS4k54o8ge5PQrq2kUdyKRnkYVSj/ix9UiT7/Pxlk7kp8UDACoahBh55dbTYLVY4FEUFGckIplTaxNCRhDOOBtSnHFo6+6D2yMiWJn0LLKwFSF+aMVIVXMXMBZo6ehFq3dm3ok5yewlEEJGNBlJDrR1q7ORM2YkstBNQ/zQiZGWTgCqiyYnxUkhQggZ8cjhvRKOpoksFCNER2tXL/bVtPm+VzbrxcjYzETT7QghZCSRpREjDpsVdhuby0jCs0t0fFbR7EvyA3jdNKAYIYSMLrRTPTDhWeShGCE6pItGRpMb3TTFFCOEkFGAHN4LAIl2ipFIQzFCdHxaIcTIstJ8AMDxFmEZOUrLCCFkFKG3jDB4NdJQjBAdB2rELLznz8gDANS1daO7z003DSFkVKGNGUli8GrEoRghPnrdHtS0CUtIaWEanHHi9qhs6vQFslKMEEJGA9rRNBxBGHkGJEYef/xxjB8/HvHx8Zg3bx7Wrl3b7/qPPfYYpk+fjoSEBEydOhXPPvvsgApLIktNaxcUBbDbLMhOdqLAm+xs65EmuD0KHHFW5KY4Y1xKQgiJPJlJdt9npoKPPCGLkVdeeQV33303HnzwQWzbtg1LlizBsmXLUFFRYbr+E088gQceeAA/+MEPsGvXLvzwhz/E7bffjn//+9+DLjwZHGsP1PkCVAGgyhsfUpCWAKvVgoK0BADAxsONAIDiDLGcEEJGOplJaseLMSORJ2QxsnLlStx00024+eabMX36dDzyyCMoLi7GE088Ybr+c889h1tvvRXLly/HhAkTcNVVV+Gmm27CL37xi0EXngRHV68b6w/WY83+OhysFTEhG8sacO1Tm3D1kxvQ0+cBABz3umKkRaQwXYiRD/fVAgBKspKiXXRCCIkJmYkcTRNNQpJ7PT092Lp1K7773e/qli9duhTr16833aa7uxvx8fG6ZQkJCdi0aRN6e3tht9tNt+nuVidoa21tDaWYxMD//msn/rblGAAgzmrBqnvPxAd7hcAob+jAK5srcO1p43Dcm1NEipDCdHHd6tt7AABfmlMY7aITQkhMSE2Ig81qgdujMM9IFAjJMlJfXw+32428vDzd8ry8PFRXV5tuc8EFF+DPf/4ztm7dCkVRsGXLFjz99NPo7e1FfX296TYPP/ww0tLSfK/i4uJQikk0KIqC1fvqAIiI8D6Pgrd2VGHdQfXc/+79g+jo6fO5bKRlRLppAGBafgrFCCFk1GCxWHzDexkzEnkGFMBqsejjBhRF8Vsm+f73v49ly5bh1FNPhd1uxyWXXIIbbrgBAGCzmavNBx54AC0tLb7X0aNHB1JMAuBYUyfq2roRZ7Xg/gumAgD+vuUodh0X1qb81HjUt3fj2U+O+CwjBV7LSEG6atH6zoXTGC9CCBlVyOG9HE0TeUISI9nZ2bDZbH5WkNraWj9riSQhIQFPP/00Ojo6UF5ejoqKCowbNw4pKSnIzs423cbpdCI1NVX3IgNDZlSdWZSGi+YUwmoRrhlAWDvuOGcSAOCDPbU+y0ih1zJyUnE6clOcWFaaj7Om5sSg9IQQEjsyvCNqmGck8oQkRhwOB+bNm4dVq1bplq9atQqLFi3qd1u73Y4xY8bAZrPh5ZdfxkUXXQSrlWlOIo0UI/NLMpCd7MT8cZm+3xZPysZpE7MAAJ8fa/ZlWZUxI+mJDmz83rl47KsnB7R8EULISGVWURoAYEp+SoxLMvIJ2RF277334tprr8X8+fNx2mmn4cknn0RFRQVWrFgBQLhYKisrfblE9u/fj02bNmHhwoVoamrCypUrsXPnTvz1r38N75EQU6QYmVeSAQC4cGY+NnmH6p4+ORsTspOQnmhHc0cvur2jago1sSIWiwXUIYSQ0cgDy6bjpsUTkJ8Wf+KVyaAIWYwsX74cDQ0N+NGPfoSqqiqUlpbirbfeQklJCQCgqqpKl3PE7XbjN7/5Dfbt2we73Y6zzz4b69evx7hx48J2EMSc9u4+7K0WsSFSjFxQmo+fvbUHjjgrFozLhMViwbyxGXjfO7om0WFDagKDtQghxGq1UIhECYuiaCeMH5q0trYiLS0NLS0tjB8Jkg1lDdh0uBErV+3HmIwErPvOObrfHHFWnDxWCJTHPzyIX76zDwAwMScJ7993ViyKTAghZIQRbPvNLvAI5MN9tbjhL5t936VVRHLqhCzd93lj1d9lvAghhBASLShGRiBvfH4cgJjUbkJOEm49Y2K/688pTkec1YI+j6KLFyGEEEKiAcXICKPX7cF7u2sAAL++Yg4WjM88wRZAvN2GmUVp+Pxosy63CCGEEBINOLZ2hLGhrAGtXX3ISnL4uWf6Y/n8YmQk2nHGFOYTIYQQEl1oGRnmvL2jCv/67Dge+tIMFKQl4J2dIiHd0pl5sIWQMfWrC8fi6gXFzCdCCCEk6lCMDHN+9/4B7K1uw/GWTvz5uvn4r9dFc8HM/JD/i0KEEEJILKAYGcb09HlwqK4dALD9WAsW/fwD9HkUZCTasWiieap9QgghZKjBmJFhTFl9O3rdChw2K6wWoM+jYGJOEp6+4RQ44nhpCSGEDA9oGRnG7KtuAwDMHpOGO86ZhMrmTnxl3hg44zipEyGEkOEDxcgwZq9XjEzNT8FZU3NjXBpCCCFkYNCWP4zZWyXmnZlWwBT5hBBChi8UI8MY6aaZxumtCSGEDGMoRoYpLR29ON7SBUC4aQghhJDhCsXIMGVfjbCKFKUnIDXeHuPSEEIIIQOHAazDjM4eNx7/8CC2HmkCQBcNIYSQ4Q/FyDDjn58ewx8+OOj7XlqUFsPSEEIIIYOHYmSYsbm8EQBwxpQcLJmUjStPKY5xiQghhJDBQTEyBPF4FNS7upGbEu/325Zy4Z75xpIJWDyZKd8JIYQMfxjAOgR55P0DWPDT9/HkR4d0y6tbulDZ3AmrBZg7Nj02hSOEEELCDMXIEKOr142/ri8HADz89l6s2V/n++3TChm0mopkJ41ahBBCRgYUI0OMd3ZWo6WzFwCgKMBdL21DVUsnANVFM68kI2blI4QQQsINxcgQ48WNFQCAO8+ZhNlj0tDS2YtHVh0AAGytoBghhBAy8qAYGUJsq2jCpvJGWC3ANQtL8NDFMwEAf996FJvLG7GrsgUAxQghhJCRBcXIEOEP7x/AlX/6BABw3vQ85KfFY15JBs6fkQePAlzxx0/Q51FQnJmAMRkJMS4tIYQQEj4oRoYAnx9txm9W7UevW8G503Lx0y/P8v12/wVTYbGIz1PykvHENfNgkQsIIYSQEQCHZAwBDtS2AwAWjs/En6+frxMbU/JS8H/Xzkd9ezcuO3kMHHHUj4QQQkYWFCNDgGNNHQCA8dlJplaP82bkRbtIhBBCSNRgN3sIUNkkhu4WpTMWhBBCyOiDYmQIUNnsFSMMTCWEEDIKoRgZAhzzWkbGZCTGuCSEEEJI9KEYiTFuj+LLsErLCCGEkNEIxUiMqW3rQq9bQZzVgrwUZ6yLQwghhEQdjqaJEUcaXKhs7oTDJvRgflo84mzUhoQQQkYfFCMx4tbntmJvdRtuWDQOAJhVlRBCyKiFXfEY0N7dh73VbQCAlzeLifGK0hm8SgghZHRCMRJJjm8D6g/4Ld5f0+b73NXrAcDgVUIIIaMXipFI0dUKPHUB8MxFgKLoftpX3ea3Ot00hBBCRisUI5GiowFwdwPt1UC3XnzsrWr1W30Ms68SQggZpVCMRIq+bvWzq073k4wXWTI527eMCc8IIYSMVihGIkVfl/q5vdb3UVEUnxi57axJSE+0IyfFify0+GiXkBBCCBkScGhvpHD3qJ9ddejo6cNr2yoxtzgdLZ29sFktOGlsOv5z52JYLRY44qgLCSGEjE4oRiKF1jLiqsUTHx7CHz44iNR4ccrHZych3m6je4YQQsioh93xSNGnWkaU9lq8ub0KANDa1QcAmJafEpNiEUIIIUMNipFIobGMtNQdR1m9C3FWC+KsFgAUI4QQQoiEbppI4VZH0zTUHgMgRs9cMrcIL2w8gkvmFsWqZIQQQsiQgmIkUmiG9nY11wAALpiZj0tPKsKlJ1GIEEIIIRK6aSKFxk2T2NMAqwU4b0ZeDAtECCGEDE0oRiKFJoA129KK0ydlIzvZGcMCEUIIIUMTipEwcrjehec2HIHbo+gsIymWTvzsokkxLBkhhBAydGHMSBj5n9d34OODDUiNj8NZ7e1I0/xW7HQByIpV0QghhJAhCy0jYcLjUfBZRTMA4NMjTahrMkyG117nvxEhhBBCaBkJF2X1Lrh63ACAHZUtaLTqZ+qFq9ZkK0IIIYRQjISJnZUtvs+7q1rRlGIUI7SMEEIIIWbQTRMmdmjESFevB81tBjHSTssIIYQQYgbFSJjQihEAsEPMQaPYvMN5aRkhhBBCTKEYCQMej4Ldx0XA6pLJ2QAAJ0SeEUuaN9uq1jKiKFEtHyEkzPAZJiSsUIyEgcMNLrR39yHebvXNOeNEr/gxrVi8S8vIpv8DfjURqPo8BiUlhAya//4P8NtSwNUQ65IQMmKgGAkDMnh1ekEq5hanAwAcXjeNnxjZ+ybQ0QCUfRjdQhJCwsO+t4HWY8DxT2NdEkJGDBQjYWCX10UzqygNE7KTkBofB6dFWkbGiHfpppGihAGthAxP5FQPXS39r0cICRqKkTBwsLYdADAlLwVWqwWPXXMyJmbYxY9SjHQ2Au5eVYy46mNQUkLIoJFTPXS39r8eISRomGckDEgxMjEnGQCwZHIOEK8ALQBSCwCLFVA8QohIEcIkaIQMT9zd4p2WEULCBi0jg6Sr142jTR0AgEm5yeoPsvdkTwQSxQgb1O0DFJGllenhCRmm9EkxQssIIeGCYmSQlNW5oChAWoId2ckO9QfpV45zAsm54nPNLvV3WkYIGX4oCt00hEQAipFBcrBOuGgm5SbDYrGoP8gKy+YEkryWEZ0YqQc8niiVkhASFty96mdaRggJG4wZGSBPfnQIxRmJvniRSTnJ+hWkXzkuHkjyWkZqNWJEcQOdTUBSVhRKSwgJC7KTAdAyQkgYoRgZAHurW/Gzt/bCYbNiXkkGAEO8CKD6leMcqpumbp9+HVctxQghwwl3j/qZlhFCwgbFSCCaK4B/3QGcehsw9ULdT+X1LgBAmrsR3zr2Q/zI0YrCLfHA9jghPL7ytNqDiosHknLEZ22vChC5RjY9CZR/rC6LcwDn/gCYfF6EDowQMmC0zzBH04SOxw28eguQMx048/7o7rutBnjtG8D8m4AZX4ruvskJGVDMyOOPP47x48cjPj4e8+bNw9q1a/td/4UXXsCcOXOQmJiIgoIC3HjjjWhoGOKplFc/DBxeA7y03O+nikYxemaZbSNOte7BZGslkloPAfX7gPK1wL631JW1AaxGjn8KbHlabCdf1TuADY9F4ogIIYNFWjwBumkGQu0eYOc/gY8fif6+978tMl9v/nP0901OSMhi5JVXXsHdd9+NBx98ENu2bcOSJUuwbNkyVFRUmK6/bt06XHfddbjpppuwa9cu/P3vf8fmzZtx8803D7rwEUUOwQX8JsWSYmSaRRzzPz1nwn3df4DxZ4oVtMN2bU7VMmLk0GrxnjUZuOFN4OLfie81uwddfEJIBNCKEbppQkeOIuxpB9x90d23rJdp0RqShCxGVq5ciZtuugk333wzpk+fjkceeQTFxcV44oknTNffsGEDxo0bh7vuugvjx4/H4sWLceutt2LLli2DLnxEyRivfm6r1v1U0dgJAJgZdwwAsD9lIWwTlgCZ3m20w3bjTMRI2ljvH20Q70UnA+MWA6WXi+/t1ZyEi5ChiDGAlSPiQkPbUYu2ZUnWyxQjQ5KQxEhPTw+2bt2KpUuX6pYvXboU69evN91m0aJFOHbsGN566y0oioKamhr84x//wBe/+MWA++nu7kZra6vuFXUsmlOjHQUDoKLBBQs8mGETYmTGSYvED85U8S5TvtscgMXi76bJmyne5Ygb+d2ZAmSMM90nIWQIoA1ghSJ6+CR4tB21aIsCOR8Y3WtDkpDESH19PdxuN/Ly8nTL8/LyUF1dbbrNokWL8MILL2D58uVwOBzIz89Heno6/vCHPwTcz8MPP4y0tDTfq7i4OJRihge3xhyryQ/i9ig41tSJMZY62N2dgM2JS85eIn6M94oRqf7j4sW70TIixYckd6b/Z7pqCBl6GIPQ2csODe0EoVG3jEg3Tauf653EngEFsOqSewFQFMVvmWT37t2466678L//+7/YunUr3nnnHRw+fBgrVqwI+P8PPPAAWlpafK+jR48OpJiDQ9sD0giDqpZO9HkUzPJaRZAzFbB5ByXFp4t3qf7jnOLdZgcSMtT/y5uh35dWnMjPNTsHV35CSPjp69F/Zy87NFwaN020Y26kEPL0+otKEnNCGtqbnZ0Nm83mZwWpra31s5ZIHn74YZx++um4/34xjGv27NlISkrCkiVL8JOf/AQFBQV+2zidTjidzlCKFn60lY7GMiKDV+cnVgE90AsJ6aaRN71NcwxJOSLJmSMFSC9RlydkACn56ncpVGppGSFkyOFnGaEYCQlXLGNGDELInhDd/ZN+Ccky4nA4MG/ePKxatUq3fNWqVVi0aJHpNh0dHbBa9bux2WwAhEVlyKK1jNTv86WBPuoVI6U2r7VGK0akm6arWbzHacWIN24kKVtNDw8AeaUirkT7HRBD4BgcR8jQQjuaBqBlJFTaYxQz0tej1ssAr9sQJGQ3zb333os///nPePrpp7Fnzx7cc889qKio8LldHnjgAVx33XW+9S+++GK8+uqreOKJJ1BWVoaPP/4Yd911FxYsWIDCwsLwHUm40YoRdw/QcBCAahkZ7zkifsvVuFykZUSiFSPJ3riR5FxVmBi3B4DMCSLWpLcDaDo8mCMghIQbt0GM0DISGrFy07gMs6Qz1mfIEXIG1uXLl6OhoQE/+tGPUFVVhdLSUrz11lsoKRGuh6qqKl3OkRtuuAFtbW149NFHcd999yE9PR3nnHMOfvGLX4TvKCKB2+AbrtkF5E5H7uF/4Q/2D5DV7Y0ZkZYMQLWMSEwtIzmAIxFwJItIfGMwq9UG5EwDqj4D3rhLPxLHYgFmXgZMv2hQhxYUW/8qfKunDPF8MEOZ5grgk8eBU78JZJSceH0iqN4BfPYScMa3gcRM/W8djcBHvwbmfhXILzXfvrcL+OhXwIxLgILZoe1775ti/2d+R2QLXf1TYPwSYOI54nc/N00zsPpnQMFcYNoXQtuXZPcbQN1e4Iz79VbSWHH8M2DDE6IOzJ4MnPVAeMrl8QzOTVO9A/jsRXGejPfFiTDOkk4xMuQYUDr42267Dbfddpvpb88884zfsjvvvBN33nnnQHYVO4zm2PoDgMeDq6p/DafNK1RSx+jFgtEyoo0ZyZqof88cLx6uonn++x4zX4iRI+v8fzuyPvJipLcL+M89gOIBZl0BxKdFdn8jlS1PAxufEALzgp/GujTDh7UrgV2vimfllJv0v+16VWQodtUBl/+f+fbbXwbW/ho4uhG44T+h7fud7woROeEs0WCtWwkcWAV8U4oRQydl/7vAwVVAWvHAxIiiAG/cIfY14xIREB9r1vxCn0V6yoUiF9Jg6WoGPJpEZ6EKgrW/AXa9JnJALfxGaNu2GywjdNMMOTg3TSDkVOEphUDbccBVi027D2IBRGVUfdoPkH/ShfoeQ3+WkZOvE8Jlwtni+xV/BRrLzHt35/yPsLhoBVGvC3j/R0B7jeixWW1hOMgAdDWrGWg7myhGBoqrXry3mQ97JwHo8J63jkb/3zqbxXt/jUnVdvFevUM09qH06mWyweodaoxBhyYBodEyIhMXtlWFvi9ACB/ZKMtjizWtx/Xfw3X/Gl0loQqC1ipveaoGv2+614YcFCOBkL7htCKg7Tj2HSrDgx+vxion0IpkZJ77LSDOEHLjFzMSr362JwAzv6x+z5qoWkmMJGQA8280lKcPeP/HwlrR0ajGoEQC7YPKh3bgyMrWaCIm/SPvuW6TnnNvh/e9M/D2ciRaV7NouFKDjE1z9wnRL//DTPgYLaY9beLd0yeEe6juA+2oObnvWCMb7qQc8Tlc92+70VUSYt0iyzGQ8hi3oWVkyDGgPCOjAmkZSRsDAGhrOI5si6gck7IK4DAKEUBYKxwp6vc4R/jKY4tTK7pIN27aB5UP7cCRla3RREz6R95zZo1Vj7fBDiRGFEU3FF/3Odj9yu3ktj3twhoJaAJYTSwgxt53MGjzCfUMATGiKOpxyHi2cN2/g43bkOUYSHmM27CTNeSgGAmEtwdUbxUWiGy04LpZYly6Ldk8pwoAvatGaxkJBzII1tjDCDfaSoIP7cChZWRg+Cwj/YiRvgBipOWov6gIFuN23hF0ut+kZUQ7PF8yIDGisYz0dIS+fbjpalaD92U26HDdv9JtKevFUDo6vZ2qFWowlpGB7JtEBYqRQHgfyE/qxc2bZ2vDBeO8cRr9uUi0rhpbmBO3yf3KhzpSaMUIH9qBIxvVjsboz1A6XFEU9f4z6zn7LCMBMmgap1EIRYxo99fTrp+5W/7mEyOG+aaAgXUStOUbCm4aWbc4U4F07zQcAxFZZsjzkzlBvIfS0dGWYSD1n9++OZpmqEExEgivGDnYLYI3E5QOWFu8ic7MKiKJzjISZjEi9xtNNw0tIwPHV+Ep+iBIEpi+LjGkHDC/92TMSKB03tLtkeB1aYaSybi/e73LYBkx65CE2mj3dumtL0PBTSMb7aQcdU6tcLtpZKxcKB0dbRnaa0OfW0YKGLlv1mtDDoqRQHjFyCFXPLoVu1gmezHGie+0OCPpppGVQ6TdNFoxwh7EgNFWtnTVBIf23uvPTRMoZkSKDxksXqdmTz4h/TWO8jcZM2JWB4T6XNbv01tfhoKbxmUiRsIWwOoVFFmTxHtIlhFNGdzdoVtsfUJosninxXfIQTESCG8+gSqXB/XwCgwpRvpz02iHwYYzgFW733CZTQOhC2ClGBkQfT363nukBeRI4URWOV/MSCDLiPcZnXKhCCb39IocQcEQlGXEu1+tddQ3QWaIz6XRpdTTHtr2kUAKhuQcNYdSuO5dl0GM9HX6520JWC5DGUKx1njcqmXSJ4RYrw01OLQ3EF7LSKfbhgZrGoosDWr+g6DdNBEKYHXViTiEvW+KREnafR7+SFSOBbNFBfr5y2rgFyB6BjO+pH7v6RCJhCYvVcWOcWhvXw+w8x8iR0qq/8SGQXHgPVHO4gUD234g7P8vkJRlnlhOcmi1uE4lpwVe58h60buecGbw+zb2vFz1oqFsrwUmnn3i7Q9/BMAisn8GomKjiDOYeI4o345/iPW9I8D88HiAHX8DiheKpHstlcDhNUDpV4RwPvQBEJcgzoW7TyQYm3Re6MNVg6Hqc6DlGDDti/rlJ7KMGIf2NhwCjm8DSi8Xz6wUHnkzxaSTRzcCHz8CjFsisrbK/DweD/D5S0B7NWBPBGYvV/cXn6Y2Vs40Icj7C2Adfwaw5w29GGk6AlRvB6ZdJHKPlH0IJGbr8woZZ+bujZFlRFGAPf8GCudqhvVqpq3oahZ1wO7XRYCwzQnMvlKf8PHIeqDik/7301gm3jM1KQ1ajwHlHwPTLwYS0tXl5R+LdAgy2ZpR6LlqgWyvsNj/X3E/Z08Ww7H3vyssY7Iz2NEgUiLAItYDQreM1OwGGg+JcoaDyq2iDp98fnj+7/BaAIq4F4cpFCOB8Jpju2FHW1wGoJ2zLrkfMaILYA23ZUTTU1m3Elj/B/GQLrlXLG8+Cjx7KZCYBdy3D9j4R5HO2sgdW9UH+fMXgTfvA065Bfjir8Uy49De3a8Dr38TmHM18OU/hl5uVwPw4pUiBf7/KxPDlCNNey3w0nLRANwfoGfc0Qi8cIWI7fnOEfNy9fUAz39F5JH4zmHAkRTc/o09L1ct8OJyoLUSuGNL4BwzgGiQn/8KYLEC3ykH7Cai1uMBXviKaMDuPwiUrQFeXwHMuBS48q/m/3twFfDarcDEc4FrXwVW/a8QmXFOYNL5wAtXinv2/5UB254D3vo2MP/rwEW/De6Yg0VRgJeuFufiW9v1qfK1k5n1dgiRZbOry6QrQ3GL3/79LaB8LZBaJESE4hbvqYVA/mwhRra/Il4JGWr24oOrgH9pski3VavXduwiYP87gDUOKD4FOPieScxIHmC1i/ti4tlCjGh772/cIQTltd6Moc99GUjOB+7drSZGk1aczAmioY6Vm+bQ+8DfrhVZZzPGiWXJueJ8WWzinO79N/DqLeo2dXuASx4Tn9294n4NNgA3vRiwJ4n1Vz8sBHLLUeDs74nf2+uA5y4VYuT+Q+L6+4kR7/fj24AXrxBJIr/5sUjNv+lPQoCc5r2+MklaYpY4JiD0mJFXbxHi8Y4tQvQMlheXizLet3/wOaO624DnLxf31f87LKYbGYZQjATC62fuRRx64rMAbT1hNqxPElHLiHe/rjqgcpv43FSu/l71mag4XLVASwVQ+alYXnK6qPD2vSUegOZyVYw0Hvb/H+PQXrlOa+XAyt1yVJSru0VUujlTBvY/odBWJXpDrlpRyZs9oNU7hBm/p1eclxSTIduuWrWS7WgcuBip3iHOAyAq0P7ESO1uNTbBVQukj/Vfp7NRFY2tx9Xrp72ORuT94FtXc+1bj4tz4ekF6vcDxzaL3+R7OGmvVe+ltiq9GDH2WLtahXVLonVl9HaqDU1TuXr9UotExXz6t4SgK18rzunxbaoYkefCYhX3SVO5alHKngTM+rN4fve/4y2HYTSNMxm4VDN/C6A2kB4PcGyr+Hxsi+itKx6Rybn1uEikCKjxLWMWeMVIjNw0x7Z437cKKxEg6hqrVby31whrA6DOqXX8M3V7V514RixWYO41/e+rcK44z/FpYpuy1WK5tm6p/lycVzlBae50EzdNrb7sNbuEC8/svq3dK96zp6hu9K6W0DLmygDY9trBi5HudvVeaa8evBip3aPWF+01qvVnmEExEghvpdOjxMGTkGMQI0FaRsIdM6LNMyJ959oegzHZk/x+9oPAuNOF1aRstd7fKrfXBogZTeXyt4FGoOvKuDM6YkRbVlct4Bjnv472fLlqzcWIthIMxbRrXLfsQ81+dwKzvhJ4W635vr3OXIxoy9Veq7mO/fjS5f/6KkLNu/b6a+8dGQCqtU4MFu3xGe8p4/fuFr0Y0boy+rpUa4KrVjSGgBp4mV4MfOGXwMYngbfvNzwf3jIUzRMNl6tO7Ug409TrI10PMnZKVvpx8cJFCqjuB3lem8tVAVuzU5+1tWaXECOuetFwAGIuqu0vx85NI89FT5twHwCaiT1zRTnl/TvjUuCz5/X3hXYEziWPBrfP+FTvNBvec6a97sZ6LHe6up50m8nvvnW9ye5q95j8h/f48maq9bPiFuc72M6FzL0SKL9NKASqaweK9nly1Q1bMcIAVjMUxTe8sBdxsKVqxIcjuX8zmC6ANUKjaTy9qjm73dCISCo+EdYRQPjOAdXN4zI0ZIBeoHQbLCNynYFGoAcqYyTRljVQsJu2LIGC9AY65blxXdnwGPdrWi5NYGOgkQza5a46tfyuusDDHuV+u1vFsFJtem3t8Vd9LhobQO2dhhPtcFvjPWVmGZF43PrA1d5OVZS316rHY3Sjyvu/VnPeZRnkXFHtteq+tM+wrydtcNNoXbCy4e7tEL1e7fWr2a0/XtlwyGuRMV59rmPlptGWV96n8hzKXrtcPmWpaNC1gcHaOJNgMU6dEShRnfws709fVljvd+253fsfVSw0HFRz0ch18mYI8WHxxg2F8jzLCf4C5bcJBV1dGw4xor1+wzdQnmLEDKmCAfTADme6Jmizv2G9QGSH9trjRc9Ai7FHK9n5qnhPLVL9pL6heiYJhLSNmHFor1nvJRS0+wsl78Ng0LpJAlkLtI1ToERKOjESQgS+rGRkxafFOIrC7/cgRJIx74K8D9w95uXsbte7cBrL1IZda1kBRPyDzPVhLE840P6fsax+lhHNd2Mejr4u1QKhFWTGZzTXK0aaK8T/97hU1+OEs7zb12oCWDXPsHyefQGs3nOmfbadyap7w1WrP77GQ6pLCFDvf7lO3ky1dx4LN02PS7XsaJHn0Cgw8krV8ymPQd47obgbjJOK6iwjWvFm2IcUlrK+0q674x/qZ8Uthk5r/yOvVLhlnN4pO0IRAj7LSBjEyEA7OIHQWXiH79QTFCNm6MRIHFKyQhAj2l5VuANYAf94lXbvQ9nToa9UpA9WVhyAJgBWK0a8FbjW2mIMYPWJkZbQkw0B/m6aaGB00xjxuFWTbqB1gIG7aeT+ZUCgltZjYlI1MxRFL9gCVS46QVmnF1Nm29TtBaC5drp91Ou3McYGhV2MaN00BjHSn2XE6MboalF7rNpzYHxGEzPF7NuAuOa13nORlCtcAPK/fK4ATUMpG02fZcRbNxgTGvqEfr1e5CoeERcgkeey1kSMxMJNY7wvJD4xoqlv7InCkmO0NPlE4CAsI/I+cPd6y+SldrdY1umdwTlXI0aaK/QjBf3u290izkvGFclrbbymwSDbhP4maAwWnZtmkEOMFcXQqaIYGVloxr73Ig5ZuZqhkv2NpAEiG8Bqtv8+r6m6bg8ARQzN1CLNmoB/EiOPR9+ISWFjbADk1N2e3oH1DLQNuuydRpoTuWkaDweXB2SwlhFjsJu8PlohpMU4t0pAMRLATQOYH4tRUBjjZcy28ZU1jNYsd5/qAgJMxIfRUqJN0W6wjGiz2mrjXsyeUfkc1OzUxxDEp4tRM4BqLTGzjPgCWKVlJIAYaddYRrTPovxcv1/UL1rLiLSqxMJNY1rWeNV6oD2XudNFUKvvXBqsFv0F9huJN1h45X3QcFDUM7I8LUfVTpbFBuRMFZ8DnWft95qd6jrpJeoxyX0Hm0PJ4/YODUZ4LCOBXOIDobVS/4zQTTPC8KrgPsUKxWJFVp5GjITkpomEZcRk/65a1Vw5dqGaChswiBGDZaSzUZ8B0uUNjNUuA/RD9gYiJIxWh0ANcTjRuWnMGmeDhSZQoz9gy4h3/3IuDEDEG8k8AIGsDcblwbhp2qrVHDhAgOPtR4xoe49aZA6QcFpGGg7qLI8nDmDtx03jMhxzfz10X29eE8ORN9M7YkTGbHjdJGaWEV8GVmkZMXQ0ZKPdXKE2ntocKuNOFy5WT5/oOMgRHrlaN02QQ2PDiaw3tGVNylVHmWjPpbRKyAn05Lbt/YjAQARy08h7rWA2kOqtd2XwbFK2GB4NiOdVWgSmXKB3h8pjMV5ridMQB3QitBl8w24ZGWTHzOjyHcaZnilGzPBGzPfAjvzUeDhSstWbfShZRmQPoL1O7xfVPnjaz8kGy4jZcDltrIPssWkZSMCVb7ZO2dOOQhCrzjLST+PsO4cRCmBNzFIzdObOUJNeBXJXGcsVjGWkbp/acwPMLUGyUvb1GrXXQFEbR20vc9YV4r3laPgyVhqvfaAAVrMGw+jG0FpGtKNTzHroefK879JbJQB/gW9qGTHEjBhdsPI/yteKa5GYrcajyH3J/e19U1g04xLEyAefm8Y1MDfoYJD34cSzxb0K6GM/tJ/lOZTCTrobwxHA6u4WwcHaayPPl0+M5Krl6WlXh08XnaxmVgXU+7Zml94KJok3WLtOhFY8h8UyMsAOjhny+LRtwTCFQ3vN8OUYsaEoPUE/3v5ElhFHCgALhMskzBPlAeoD70gRJsvKLaJhkpV87gxhVixfK8zPci4G7baueq+LxnDjuuo1IwpSRaZFPz/9AB4e+fCVnCayfJ6op123TySVSkgXJu2K9frhkTnTRG4KRRH5O7ImiRFOMkgzb6bBMmISnCobZ1km7bno6xa9W+2QQkCNmaneLnIW2BNEwqGKjXprUuHJqvk1Pk3cM13NohKXvcujm0RW2rELVfMxoJ4bWa6AlhHN8tZj+t+M11VR1EpL/q9xG/ld/g4AY08VvdPWY6IHVnKayNpasxOARQxJDTU7q09sxYuK3c8y4j1vaWOA2haDZcQQ4Km1Bilu/5EgWrRBlzILq1xmXN9sNE13q3hmTmQZKV8n3vNm6BvA3JnC8lGxXmRFBoDcaaIsUvR7+sT/B1tvKIoYlmwWf5Q9xXyIZ3e7sIJlT/beF5rGP3eGqDe0okL7WYqQ+DQgbawYrVe7Z4ABrN7zanOo57SrVS1P7gyxzoF31XOanCNEjM0pxItcnjtTlK3eW2+MWyyWt9eIZIDy/yRSCFVuFcnxtBSe5H8/nMgy0tftzdLc4/8bIOrhkkWivgD09ZFutJhH1Eu508V94WoQ11bmhKreIfLUxDlFYr44R//1mLtXuAVzZwhLV3utWJZWJK595af6ZwgQiQIHmmV7kFCMmCFzjMCOgnTvDZTsHW9/IsuI1Soa8q4Wf19mOJD7z5shel+A3n+aN0PtJWdP0buKZI9Rcet7NBLtiAJnqrjptcF3gD5DZjB43OoNP+HsE4uRhkPAYwuEO+P6fwNrfgGs/bV+HWcqcN9eoGID8PxlwElfE9kg37hDpLb/+rsnDmD1De08y/8h/vBhYN1vgSuf8+/F7H9XZHaVmUlfvRXY96b+v7OnAilec3J8mvjccMBbaZaq+3/hcpEu/KoXgiuXlv6mUTceb3uNuN4Wq6iopdgwQ16j1DFCDObNFGKkdpcQH0+eqZapaB5wSz//ZYY0KxfNB46sC2wZSRsj9qmLGTFaRhrN92HWYcieIjKm+ix/VjX+wNij17lpvI1mb4feXWkUDMl5+vLnzhSiWSZVy5uhbt98RF0H0Oe66HEFL0Z2vw78/Qbz3xzJIturMTbjrW+LNPhf/68Q9J2N3nMxTdyb5WsNlhFN7p1cjbjKmyHEiJziAAjNMiKthTlTgcZyEYja3aq6cPNmqqMA5TmV7qPkPLFvGbwqhd+u10TD60wWgbZNh9VzrRWGMu38tufES0vmBOCubfpl2pFlZpaRD34ssmH3x8nXA1/6vfgcKIB161+AN+8FLvgZcNrtwHOXiPNxzy7xvP9xsbru4nuB8x5S61L53Gr/e91vRQbuLz8prEVPnS/qxW99JoTYc1/2L+flT/WfAymCUIyY4VW4PYhDfqq3Ylh8D7DrdTEPyIk46wHRe8yOQHKvaV8EDqwC5t0gxtUDYl8dDWqlkjVZVCozDTebzS4e8M4m86BFXa6FVHM3U6hmxY5GVRz54iV2B85+2HBIXQdQG+f0scKMXL1DlKGlUv3tyHrxXv6xus2J3DQur4k/f7b3e53omVitYr4aQKQB17oCulpVC9SR9eIYjnj3mTtTCL/j20QPTVZazlRRsThTxPwpiZnA/JvE9anfr5/Era9b/S5N/J2N/knHFKV/37DRVNt6XLwn5wNpxYG3A4Swq9sHTPLe53kzRO+0Zpcom6tO9PQ8feJYA2W3DYTW8nNkXeCAVZkNNdgAVkl8mnljHucAzv2+aLAAMceI7Klq3TqOZNVyAuitVlphaNzHtItEttaOBvEf828U52XpT0Vyr7xSMcx+39vif+xJwIJbxLY2u2oh6O0AEKS1Sd73KQWq+AWEy62nHajeKWJVtMh7+/BHQM/J4nPmRHEu5t8oGvB5N6jrp+QBp94mBJM2+VzeTHG81ds1c3aFYBmZdK44Z3OuBt7+jhAWXc1q7FL6WPFsTrtIBGnGJQCn3CR+O/N+YMtfAChizqHUQuDkG8TxLlwh1jn7e2I6DMUjRLO2Lp57jTdjq8bSpnhEfp3GMpFLRDsFg9biYTbiSV6HrEn6+wUQz0f9Pv28PYHyjMhstGUfiueweof4Xn/AP6ar4hNhNa7fL77L+qKrRdQjcU71Wpd9KKY1kEP7q3eoZU7KVTMCA6oAjAEUI2ZIMaLEITfFe1OWXi5ewXDqNyNUMAjLyNUvis/HNol36VOVlQoAXPak+fZJuUKMaHNTxCUIH7arTrV8OANU6qG6aWQFnpApei3WOOHCaDkmMmQakQ9nR4MYeSGFxAUPi1Tef5gngiC1YqrxsHjQfEm86vXllBN9SSuRx6PuR/qaPX1ivfg0dWhhuXfyKW3ZZEVSf0BU3F3NIr7mG6vF+frdHFEW2SOLTxUm2qnL1P+5aKWo+P50hr4yqvNOKR+f7s2J4O1Vu+r1ptOuFo27IEFN9OS7jgahojWjGxsM7fb2JCGWLn1M/d0s1qLIew06GsS5kpOZnYiuFjUR31jvxITa66QdySXFiPb8GOc+MbMO9dcgnv4t8TKitXYaYxlsduFG6e3QNyLGmJHUAuBr//T/bzk/CiDO7TV/Ny+bPVFc01CCWOX1OPchYO7V6vIXlwuhULNLL0ZcDaqls2an+nxLq0HOVOCrr/jv58KH/ZdJt0f5OrWzEcpomsRM1SK4+qdAK0Twr7RCJOWI8mmthpKTrxMvLck5+jmZZl8pXmYUzAZu+I9+maIAP8kV18A4BYPOTWOwjHg8qjXn6pf9R8+1VQO/mepNwtYJwOKfVFIir2fNLv/Eh7Kuy5kuAqBrdguR4+kTdXVeqdpJcNUJ4ev7v516a7T2WT7j28DCW83PU5RhAKsZ3oq+F3HITTVpkIcK0iwqo/e1pshA+LKw1qmNlBx/76rTz1xqjHgHQreMaIdbxjnUHkqg4aI+N5AiGjvjcE1tSnxfT1UBdmoaAm0grkTrG+1pg09kJGWrpmxXnT4ZmDEZVFerWh7FrfaysyerFXuu4RoYGzfjcm3PXxuEbLWpbrhA4sKZqvd5a6+jFq0Z3ehmlNsA5j5/X6zFbn0woLzXQhn2Kyvt1CIx1BIwiI0ONfZGNgbaytrPTWNiGQnFVWC2jdk9L6+VPK82Z/BzmgRLqCNqjPEeWnzXxuAOrTU0SGYjTYJFilT5jCRkDnzKAHl+ZabfQNatSGKx+I82lGjFiDEdfNNhcd/GxetHzkmS88S5UTyis2GM0ZD3vzYRX2ulanGV5ZF1QMkitUN34L9iWd4M/agwV534Dyl66vYBVdvV/9MG9mpjaWIMxYgZfdJNY0deagRGxIQLY+MRTKWivWHlQycD04xuGl1D6q18Q7WMyH3I/WrzPZihi/Wo809k5RsRZEjUtf1vmu1qNY28t9xaV43ch9UuKhGtwDEtlzz2FvN9Bhq9BJg3boA+FkFWdr5EWIbAykAzlibl6MWF7zr2s75fRk1NZWTWkGdPFuepp02dNC53hmZ4Zwgjo3TBiXLIbJvoXQLqdbHYVLdDf0N7zcTIQCYd025jjLHQLvNZEiNQJ4Sa+Kz1uGqVk7EvEmMeEIkxM6ycZG4gYiRrot46FMqwXiPyXpAu2lDcPeEkWVM3atG5aQyWEXlOc6bp3XsSi0V/PXz1kKE+lYn4JDs0FjRtPZhWpHbojPWPL9dNnf5au7tFVmVJxQZhhdJuOwSgGDFDaxlJGcqWkUGIEa2bRjYsWsuIM1XfkMpYg8FYRgB9T9sM7f83lauVszE9tTHmRZu1sfW4at2Q5dZWMNq03xaLPhmcWbm0x65t6OU+tb2LPENPw6xxA/S+5W5vIJ7fkFMZoBzI0pGjN43L69jr0jfcWjdNYqY6oZx2G/l/Rmx2UdEC6vFqh48PRIxoJyyDogYi+u69FP85YeRxaTG7FwdkGdEct5klSz4H8jpEotfuS3wWpGVEWjW0VjmJvKa1e1ShB+ivleIRQdXAwBokm10vggYjIJxGMTIIYTMYjEkhJf1ZRgJZp7RonxX5LMo6pdcl3NFGK5a2PjPm0JH/Z6x/dPVYP/8n0+SnFIQ+Gi6CUIyY0NUlbrgexCF3KFtGjA9tMCY3ba4Rn2VENmIdarbV+FR9Q5rlNUGGmm9C2ysH9DEIZpj5UO2JIkJe+z/G+VS0yEoNUIc3mllG5PH5JgPT9Ci0SZSyJor3nnbz5GDymIyfYfEO9TZBxiIA6jmVQkg2JlrhpUUXA6K5BzInqL12s4ysSble9483ENHm0OdnCGRVMAqs3OnqslDEiNYtYI9Xe9byesjzoLXK6SwjXmFqMVRb2lFrA2kUg3bTSMtIBMSIw3t/BytGzPJnSLImiXPb067GLgHm97YjWQzTHQgnErLBEm9w0wzEuhUOtBZSLdrRNEbLSG0IYqRWYxmR9Skg7nGzayPRummScvzreVnnJGvKH+j/tN+HkFUEoBgxpdUlKj23xY5k5xCO8dU+tI5k1Q/fH1q/qGzUMsapDaOsEJyp+kn5ZKM1aDeN90FqOKDPHSLRzd65U78toBEO/YgROY+FI1mof8DcMiIbGV+jX6dWLhPPVteXYgQwH9qsfai1gsCZIny5gdDmsNAGF8o4juQAlWOgGBCtODFmJwX8rUtGN0+gHqn2+NKKxdDInOkALMIHHkwKau2kZvL/jHEz8t5yauKV+rrU+0Q21AmG3lyG5r4fSEOWmAWf2bxfy0gkxYj3+QvWTeMTriYdEFucarWQjZLHrfaOtfd27oz+79H+0CVUHIybxvscyOd2KLtpwmUZSSlURXRXi/o/2msj0XYck3MMHR6o9YVufqTd/v+XmN2/SznGUIyY0NYuhnxZoh1EFSrx6cKfD6jzRpwIWWk0lvkyzQpzv/dGbvRaFeINbhopRgbrpkktEpWPp08dlqZFK3bkA6WtnGSD2XBAnSRN9pSNvQBnqnkFo42L0Zat6bA6/E1mcZRl1sUJaIIXnWnqyA9AWB6kWyNQ8Kq2fICojKQIyhjnbwUyywcjy208N8Ysu4AqTORv8t0oRgI1KNoesGz8HIlqwF4wkx+2HBMBddpEfFoxBugTxWnPnbxe0k0jLTuSDE1yr4GY+G1x6n/2axnxnkfbEHDTaIOdzdDmswFUl2dcvBgu61tvEAGMunijMLhpfP8VKzdNgBitQDEj2qBTY+C6FincXXXq9UjO0U81IK/nLM0IIFmfaTuOSbn6854+1r8eaz2m1q3a/8ubob9f+itzDKAYMaG9U6hfWyTmlgkn2niHYFWuXF/6ix3JomGRy2VQoFMbwGpRK3yZhbStWuT6MHtpk1EZEyJZLP7Bj4qiPuRasSMj9c0aTPlbfJrauBXMVsUZIB5SeVzNR9RyyUbPZxnxxl0c/si7j3w1J4o8Z9oKMylHnY03b4b/yAr5wAcKXtWWD9BnntRWFgHFiAzqzTaIEY2orD+gxqIYr0GSRowkamJOAg3NDNSb8vX4vBWs9joakceXPVUdYm2cPVUrEq021XWhHXFgVk6tZWSgjaLcrj/LyFBx02jzSwQSE77YLK9Q1AZaFsxW1wskZoLB7F4dCMbnJGZuGo3VVYsuZsR7f/d0ePMaKfpOgBla4a5NbS/FeP0BNfnctC+o7ssx88V76zH9kGfZoQPMr8GR9eqQ38nnq7/3N1XIEIBixIQOr5vG5hjC8SIS+RAEq3KNlYZvlIqhN6KNGUnM0mdD/M89Yuz8b2eYv345AdjujQY3m9bdGPz49+uBX08RPQBd3gmP/7a+LLLyN01PIW+mfzCibID3/Bv45Xhg2/P+MSPGHlHeDOHekVkik3P1FWZyrnq+zczksjzBWka0PSPt/4XipnGmijgMefzvPSSuQ9V2VWAah0fL4dbyOAP1SFPy1etvVpnJ3t7b/w/4xTh9zI7EOFJIlhnQWEYM7jNfEGuzeJcxI8agOykMgYE3ZHK7/kbTRMNNU7cX+NkY4M1vB1634YBonJypgZPYGYWi1p0ge+rA4IZ2ymGrwODcNE7DOY+VZSSgm0YbM9IpAuR/PQV40Ws9Dca6JNfRxtDJ+1wmRJNJ07K9LjaZyEzWdfIZ13botNfP2HnJmyGelZRCdV1ZDmtcZJJyDgKKERM6OkWlZ3cMcTcNINwJ6SXA1AuDWz+tWPT6bQ5hsp29XCyf+WURbGlzCEtD0TzRg8qdCcy5St+L3feW+Gy1i/W1L4sVgOKdMEyTKVQ34ZYm+NHdB+x7R1grqj83D5DtL64hKUekWs4YB5x0rb7XHJ8mjjV9rGryLNdk/ZSNzNjTRMI4m0M88HO+Kh74+V8XD+yYU/SNVFK2yFKZMR446Rr/8k77otjnzEv9f9OiPact3rlhtLkKZAxQY5k6KkJRVKuWzFKZP0u9jtO/5BUXFmFe3vE3iCGDFrXhmPYFEbQ4/WLxfc7VotdUONe8nBaLyGxZMFdkzpTIsrYcFe9la4RP/dhm//8wOz7jhGXaAFZA9AAB1RTuc9MYLCOJ2eL+LVkcXNyUGaWXi23Hn+n/m5w9VoqlSI6m2fMfMbpI5rAxQxsvEijfiRQjjYdEA6oNtHQkint73BLxnA8Ui0Vkbc2aDBQvHPj/GC0jsYoZCRTAapwor3qHOgLMkSLqixMx+yohumwO8dyOX6Ie9xGvGJHX7JSbhCCZe41+slLteZn/dSFetIndxswX29kcwtI211s3LfyGqCOmLgOKTxXz2pxyc2RmlR8EQzg6M3bI0TR2ZwTmlgk3i+4Ur2CxWsWcL0YCZSy8bb14b6kU7zLIDAC+U67GN0g2PyXmV3DV6TOF6ibc0viztbEr7XUBhmtqrR3JakZMQIiciWcD3/rc+90wMiKtCLh7h7CI/Ot2UdHILLU+N00WcNen/vs97yHx0q4rj2XKUvEyI2Oc2OeJ0FoGzCYby5ygTlbYdFgE0rZVe+eZ8cam2OOBFevUbaYsBb57BPjwF8CHP1PNwolZIjYCEPPT3KMp37Kfn7isZ31XvLRo8xoAqvA0C2jVDkf2Hb8hZqTLYBnJmyGyDNfsEvNlSBeGMWbEkQRc8cyJj6E/5t2gT4OuxdjzjUieEe9zJAWXDAw2szj0N5JGkpwnzpPMkmsMtLxoZXjKfe7/itdgMFoQY+Wmkee6s1F0kuTzYrSMSNEs588KhukXiZcWedy+SU6912b+jeIFiOdFjojS3guzrxAvLfFpwB2b/Pe9+B7xknz97eDKHGVoGTGhq0v4BZ3OYeCmiRbG3kvGeH8hAphneJXmRYmM/m6rAso/Upe3V6txDloCuZYAE0uJ5rtRQADehGiGANZgMLppwoHWMmDWWNvixMyugD5VNCB6RfZ+7k/Z6Mj5LcJVZi3avAbuXnX2WLNRTsYh3oC/ZaTb4D4zBmH63DRGMZKIiJI9VR8cbUwFHw7MjiFQYLBviHQ/7gGLRTXhH9sSXKBlrDC6xmLlpknIUIPhtZlStUN7Fbc+rm4wGOsfM3GpswrHSKRFCYoRE3p6hBiJjx8GlpFo4UjW53cI1CszS9dufIicKao5fcc/1OWNh6HLQigxNqS6ob6G35JNGjvtcle9f2xCMBgDWMOBb0hjs2ayMcPxGBtks9gLM4y/R6Iik+e+o1HMDCzpT4zoLFeGxGZGkegLwvQesy8BnsFNY08KveyhYI/XzzkSCcuI3UyM7DZf90QjaSTy9x3/QFCBlrFC+5xqcwpFG+0UDFrrntZNA6j3eqCEhsFi3N7smU6iGBnV9HYLMZKQQDHiw2LRN8gBxYicT6XOvLdv3F47m6UcIWNz6oPajA20rrdgaJgCZdPUBncZYxOCQRczEqZKQR5j85HAk40FGhVxokj49HH6RjoSFVlilhojVKvJ8GjqptEMTZScKIBVVs4tR8U1k7OsGgNYHREWI4A+UDASvnaHSQNsllCus0nMOwLo5xUyQ56/oxv034cauuc0hMn2IkGyxoIq0bppAPX+HqwY0dZxjhTz5HPa8xEJ6+YQgmLEgKu7DxavEk5KjLD5d7ihbbwDReHLB6a3Q83ZYdYbM2tMfRNlpeq36U9w9OemMRMQnj51XoaBWkbC7aaRx2022ZjfqAgZvHgCMWK16hufSFRk2myuWpeCMWNsb6ca8GdmuTLLwAoIs7kMYj2+TRVsxgDWSLtpAP39GpGYEZNjMKYIB9Trnzb2xI2h3wR6gxjGG0kcyfCN7omVi0ZiNgWDUYy0eZMThtNNEyhPFN00o5fatm7YIZJpOYbDaJpoolXygSo2R7KaWVD27MwqGDMxI1Ota4fkWu3qsFJJf4m6kgNYRuKcauUt9xNKzyY+Am4aWT5ZHjPB4BsVUSYaa9/8MEH4/s2G/YUbeZ20vfhAc+nYnPprYrSMaDOwSuRxHtWM0PGzjETBrB9xMaKx7hR580vU7hWBlFpqgnTTAfohvMCQmqFVh9Wq3gux7v2bJT7zc9NIy8ggxUhQluZ+6roRBsWIgfr2bjgs3gpgqGdgjTby4YtLUOd8MWKxqILAl23QrJHtp5cWn6r2UJJy/IcvGhN96X4LYBkx/mb2e39o1w23ZURiJhh8WVYVMezT0ytMuukmJl0j2nMcqYpMXid5rQER/6KdoE2ba0Z7LY2WkW4T95kvCNM7SiAu3l98mMVbhBttYxGJAFatS23aF8QxubtV16UkmLlQJNpkW8FuEyvkNY917z8oN403ZiSclpFA1ya5n7puhEExYqDR1QOH1zISkUpnOCMb5NwA02VL5ENT550d0swPLIetAv4uh/g0TYIuk237FSMBAljN1h2om8boJhgofmmwA1Q2skHe8Tfxbpb11YxwpevuD3md5LUGhCtMO4ePWa4ZQJ8OX1HUkVTxJha4o14xYk9Uh2YDACyG7xEirVgtb6TdNHmz1HgQ44gas+R4/SHvAYtVP8vuUMOXgDDGDa5xuDrgbxmRVpPBWkbiTSyAgcpj/DwCoRgx0NzRAwe8SphiRI+sjE8UryAtEL4Uxia9cu2w1QmGRFNaN41Zj14uM4u872/SM2NjOJChvfHp4QtgNFpmAlkvZIMsc4YE2xBF003jCRDkp/0cyDLV3SqCU7WZJiWyMZXixpGsFwOOpOCE2WDRDpWNSACrxjKSN1NtnF6/TWS1la9jW7zrBBn/IdfLmhQd0TZQhoybRjNcXWK8t+WIv0EHsBpiRkzLQzfNqKXR1euLGaEYMSCzNU4+r//1jI1+oIdo+sWixzbjEjUlOSAa/uJTAFhExkAjuTPEg2yW9dEWBxQvEMGg2jThgP7BtjlDc8PlTBem9LEm5RkowWaenHSO4fsJzr8kMVPEHyRkqBMdhptAQ0V1E/UFsIzIWKCedrW3aY3TN5rZU/QuqcK5QhhIQRINF41k8vkALMJyEW5SCsScSLkzgNRC9Rr3dYoRNPIFRQyLD/Z6TrlQnFPt5HhDkTHzRF0g42VihbTEaufXMrppJIN102SOF8/AmFP84+Ik6WPFvZE7MzqxUTGEGVgNCMsIY0ZMWfgNkfUv0IMjMUvZbsbi+4BTbxO9wuRctffrTAMmniMyvJr1PhIzgXt3q4GyRm54U0w7b7SamOW4CJbkHOC+veEdRupnuQkg2iadB9y3X7gznClAakHw+/j6OyKFtTNl4OXsDz+rlwWAog8A9MWMGC0j6aKh9PSpsRHOVL2lw2YHbt8ENB8VyzMniuVx8eK4ojGSRrLkPpGq+0T3/0CIc4oswFa7OM4ZlwD37gG62/3XTS9Ws4OeiMK5wHePRsa1FE7O/zGw5NtAQnpsy2EMqgb83TSSQVtGUoC7d/bfztjjgTs/Fc9JNCyAMYRixECjqwd2GcBqHGZJgquI/Ua4BGhkrVa1cU/KVWci9Q3tTA+8j/4aV5vd/Nr1F08SDIP1ERuRM9PK/Bn9uVJS8sQrVAKdi3BhLHPmeCEstD73QPlmrFaxrK1KnVzP7BzbE4CcKf7Lupqj21u0WCIjRCRGoZtaGKb/HQYpCiyW2AsRwD+oGoicZQQILsHbcLh+YYBuGgNNHb2amBFaRgaENujUbPTDibYJx0Nuuo8Aw35jiVnK+uGE0fUi4yp0bhqT7KsSed1lrpVgr0ss3DRk5KO1jCje2JBAYiTcnZNRDsWIgaaOHjjgFl9oGRkYuhTGucGZF40T3EWCaOwjVMxS1g8njAJKihHTAFaT45Pb+ywjQZq+ZVxJNLKvktGDvP/cPcINKD8biYunGz/MUIwYaNKOpuHNNjB0ScmCbGADTXAXTmgZCT/ac5qQoboWZJwI0L9lRC5rOCDegxUj0jJCMULCiTYbrHTV+I2mwdCpP0YQFCMGmlw9HE0zWPpL1x4IXZrwQQaGBdzHULSMeI/VOLPxcCHOoY6ESsr1Txrl7hVTssvfjch7pfmoeA+2kpeWEbppSDjRZoOVQazSTaN1Nw+V+mMEQTGiwe1R0NLZq2ZgpRgZGHKUBBD8xFeDDS4NBkeS2nhphxLHEl/myRhPEDYY5LVLyvFPGiUtJBabefCnTyDK3A0hxozQMkLCjTGIVbpptEHztIyEHYoRDa2dvfAooGVksMhREkDwiXqi4aYB1HINlcpElmM4umgk8hona8SIq1YEAEoLSVK2+URgA82Ky5gREil8lhHv9ATSMqK9N2kZCTsc2quhqUMoYCdjRgaPHLI5lNw0gGg4m48MncpElmM4Bq9KfJYRjZumrwt45ouqqTvQfWAUI4wZIbHGZxkxiBFtnTFUOjMjCFpGNEgx4rBwNM2gyfGmeg92PoyUAtEQJWREVozIcmknEIslMomXLNdwRHutHUliHhcAOPIxUL1D/c0Mo+UsWJGYUSLe00tCKyshJ0LWP/25aSJZR41SaBnR0OTqBaDAzjwjg+eLvwZOuVmkZg+GOCdwy2rxOZIi8MKHgZOuFSmYhwJzrwGyJwOFJ8W6JANn8T3A+DPUa33j28Cxzerv1jj/+YckRotJsD3OM/4fMOn8oXMdycghUACrzk1DMRJuKEY0NHb0wAYPrDKYjpaRgROfBow1mTumP7ImRqYsWpwpoZcrktjigJJFsS7F4LDHA+NOV7+nF4tXMPgmNgwxgNUeD5ScFkopCQkOYwCrh26aaEA3jQbdjL0AY0YIiTS2ODHXkMTJHieJMX6WkR79cmDoxJyNIChGNOhm7AU4moaQaJA0BPO/kNFLoABWJy0jkYRiRENzRw+cPjFiUXNlEEIiR7RGUhESDH4BrL365cbPJCxQjGhoNGZfHeFTNhMyJBiKafrJ6CWQmyaebppIQjGiobmjFw4Lc4wQElWkm8bmGJ4p8cnIwmcZMbppmIE1klCMaGjq6IGdM/YSEl2Sh1hWXDK6MVpGPMzAGg0oRjToZuxljhFCooO0jLCCJ0MBvwBWEzcNR32FHYoRL4qioKmjFw5fzAiDVwmJCjKbakpBbMtBCKAPYPW4AcUjvidmAVa7mGyTwjnssMX10tTRC7dHgd03Yy8tI4REhZLFwMW/A4qHUDI6MnqR7hjFrVpHADFVxfLngTgH3fgRgGLES3VLFwAgM8ECeMAcI4REC6sVmHdDrEtBiMCRBFhsQoy46tXlNgcw9cLYlWuEQzeNl5pWIUZyE72nhG4aQggZfVgs6siZDo0YsdIaEkkoRrxUe8VIdqI3twgtI4QQMjqRMSHSMmKxCQseiRg8u16kmyYrXlpGKEYIIWRUIoNYpWWE7UHEoRjx4hMjCV7LCFPBE0LI6EQO3XU1iHcGrEYcihEv0k2TKQfRUAkTQsjoRLppOihGosWAxMjjjz+O8ePHIz4+HvPmzcPatWsDrnvDDTfAYrH4vWbOnDngQkcCGcCaLrNRU4wQQsjoRA7vpZsmaoQsRl555RXcfffdePDBB7Ft2zYsWbIEy5YtQ0VFhen6v/vd71BVVeV7HT16FJmZmbjiiisGXfhwIi0jafKeoxImhJDRiTGAlSNpIk7IYmTlypW46aabcPPNN2P69Ol45JFHUFxcjCeeeMJ0/bS0NOTn5/teW7ZsQVNTE2688cZBFz5cdPW60dwh0sCnOhSxkGKEEEJGJzKAVYoRtgcRJyQx0tPTg61bt2Lp0qW65UuXLsX69euD+o+nnnoK5513HkpKSgKu093djdbWVt0rksjg1QS7DfEWOVEezXKEEDIqScwS723HxTvbg4gTkhipr6+H2+1GXl6ebnleXh6qq6tPuH1VVRXefvtt3Hzzzf2u9/DDDyMtLc33Ki4uDqWYISNdNPlp8bB4ZDp4KmFCCBmVJHlnkmYAa9QYUACrxWLRfVcUxW+ZGc888wzS09Nx6aWX9rveAw88gJaWFt/r6NGjAylm0Mjg1bxUpzpDI32EhBAyOknO1X+nGIk4ISXTyM7Ohs1m87OC1NbW+llLjCiKgqeffhrXXnstHI7+TV5OpxNOZ/QmqpNumvzUeFWM0CxHCCGjkySjGGF7EGlCsow4HA7MmzcPq1at0i1ftWoVFi1a1O+2a9aswcGDB3HTTTeFXsoIUyXFSFoCQDcNIYSMbmgZiTohpxm99957ce2112L+/Pk47bTT8OSTT6KiogIrVqwAIFwslZWVePbZZ3XbPfXUU1i4cCFKS0vDU/IwIt00+alOoEVaRnjzEULIqCQ+XZ25F6DbPgqELEaWL1+OhoYG/OhHP0JVVRVKS0vx1ltv+UbHVFVV+eUcaWlpwT//+U/87ne/C0+pw4w2gBWNdNMQQsioxmoVQazt3pAEtgcRZ0ATsNx222247bbbTH975pln/JalpaWho6NjILuKCvXt3QCAnBQn4KabhhBCRj3JWjHC9iDScG4aAE0ukfAsM8nJAFZCCCH6IFa2BxFn1IuRnj4P2ruFNSQj0c6hvYQQQtRcIwAtI1Fg1IuR5g4hPqwWIDXeDriFlYQ3HyGEjGKSKUaiyagXI03eOWnSEx2wWi2AR4oRmuUIIWTUQjdNVBn1YqTRJSwjGYle5evm0F5CCBn1aHON0G0fcUa9GJFumoxEr/Klm4YQQkhStvqZ7UHEGfVipFGKkSSjGKFZjhBCRi1000SVUS9Gmr0xI35uGprlCCFk9KJ109AyEnFGvRjxxYz4WUZ48xFCyKglMRuAdzZ6tgcRZ9SLkSZjzAhH0xBCCLHFAYmZ3s9sDyINxYjXMpLpC2DlaBpCCCFQE59RjEQcihFfnhEZM0I3DSGEEKhixDqgadxICFCMeN00mUlGywiVMCGEjGomLwUcKUDRvFiXZMQz6uWedNOk++UZoRghhJBRzel3AafdDlhtsS7JiGdUW0b63B60dmkmyQNUMUKzHCGEEAqRqDCqxUhzpxAeFguQlmBMB0/LCCGEEBINRrUYkS6a1Hg74mxWQFE4tJcQQgiJMqNbjHhH0viCVz196o82umkIIYSQaDCqxUijL3jV4KIBaBkhhBBCosSoFiNyxt5M40gagGKEEEIIiRKjWozIGXv9hvUCHE1DCCGERIlRLUaafTEjJjP2WiwxKhUhhBAyuhjVYqTRL+EZh/USQggh0WZUi5HOHjcAk9E0HElDCCGERI1R3eo+ds3JWNnnVhfQMkIIIYREnVEtRgDAGadJ9UsxQgghhESdUe2m8cMt3TT22JaDEEIIGUVQjGjRjqYhhBBCSFSgGNFCNw0hhBASdShGtHjopiGEEEKiDcWIFp9lhGKEEEIIiRYUI1ropiGEEEKiDsWIFjk3DS0jhBBCSNSgGNEixQhH0xBCCCFRg2JEC900hBBCSNShGNFCNw0hhBASdShGtHikGKFlhBBCCIkWFCNaOLSXEEIIiToUI1ropiGEEEKiDsWIFjfdNIQQQki0oRjRwonyCCGEkKhDMaKFbhpCCCEk6lCMaGGeEUIIISTqUIxo8dAyQgghhEQbihEtdNMQQgghUYdiRAvdNIQQQkjUoRjRwonyCCGEkKhDMaKFbhpCCCEk6lCMaKGbhhBCCIk6FCNaOFEeIYQQEnUoRrT43DRxsS0HIYQQMoqgGNFCNw0hhBASdShGtFCMEEIIIVGHYkSLu0+8W+mmIYQQQqIFxYgWWkYIIYSQqEMxooVihBBCCIk6FCNaPF43DUfTEEIIIVGDYkQLLSOEEEJI1KEY0UIxQgghhEQdihEtHE1DCCGERB2KES20jBBCCCFRh2JEoiicm4YQQgiJARQjEjkvDcDRNIQQQkgUoRiRdLV4P1gAR0pMi0IIIYSMJihGJK5a8Z6YScsIIYQQEkUoRiTtXjGSlBPbchBCCCGjDIoRiatevFOMEEIIIVFlQGLk8ccfx/jx4xEfH4958+Zh7dq1/a7f3d2NBx98ECUlJXA6nZg4cSKefvrpARU4Ykg3TXJubMtBCCGEjDJCDo545ZVXcPfdd+Pxxx/H6aefjj/96U9YtmwZdu/ejbFjx5puc+WVV6KmpgZPPfUUJk2ahNraWvT19Q268GGFbhpCCCEkJoQsRlauXImbbroJN998MwDgkUcewbvvvosnnngCDz/8sN/677zzDtasWYOysjJkZmYCAMaNGze4UkcCumkIIYSQmBCSm6anpwdbt27F0qVLdcuXLl2K9evXm27zxhtvYP78+fjlL3+JoqIiTJkyBd/+9rfR2dkZcD/d3d1obW3VvSIO3TSEEEJITAjJMlJfXw+32428vDzd8ry8PFRXV5tuU1ZWhnXr1iE+Ph6vvfYa6uvrcdttt6GxsTFg3MjDDz+MH/7wh6EUbfD43DQUI4QQQkg0GVAAq8Vi0X1XFMVvmcTj8cBiseCFF17AggUL8IUvfAErV67EM888E9A68sADD6ClpcX3Onr06ECKGRquOvFONw0hhBASVUKyjGRnZ8Nms/lZQWpra/2sJZKCggIUFRUhLS3Nt2z69OlQFAXHjh3D5MmT/bZxOp1wOp2hFG1wKIoqRpIpRgghhJBoEpJlxOFwYN68eVi1apVu+apVq7Bo0SLTbU4//XQcP34c7e3tvmX79++H1WrFmDFjBlDkCNDVos7YSzcNIYQQElVCdtPce++9+POf/4ynn34ae/bswT333IOKigqsWLECgHCxXHfddb71v/rVryIrKws33ngjdu/ejY8++gj3338/vv71ryMhISF8RzIYpFXEmQrY42NbFkIIIWSUEfLQ3uXLl6OhoQE/+tGPUFVVhdLSUrz11lsoKSkBAFRVVaGiosK3fnJyMlatWoU777wT8+fPR1ZWFq688kr85Cc/Cd9RDBZf8Gp2bMtBCCGEjEIsiqIosS7EiWhtbUVaWhpaWlqQmpoa/h3seh34+/VA8anATe+G//8JIYSQUUiw7TfnpgEYvEoIIYTEEIoRgDlGCCGEkBhCMQIwxwghhBASQyhGALppCCGEkBhCMQLQTUMIIYTEEIoRAGjxpptPKYhtOQghhJBRCMVIRyPQViU+50yNbVkIIYSQUQjFSO1u8Z4+FoiPQA4TQgghhPQLxUjNLvGeVxrbchBCCCGjFIqRmp3iPW9mbMtBCCGEjFIoRmq8bprcGbEtByGEEDJKGd1ixOMBaveIz3TTEEIIITFhdIuR5nKg1wXYnEDmhFiXhhBCCBmVjG4xIoNXc6cBtrjYloUQQggZpVCMAHTREEIIITGEYgRg8CohhBASQ0a3b2L2ciCtGBh3eqxLQgghhIxaRrcYmX6ReBFCCCEkZoxuNw0hhBBCYg7FCCGEEEJiCsUIIYQQQmIKxQghhBBCYgrFCCGEEEJiCsUIIYQQQmIKxQghhBBCYgrFCCGEEEJiCsUIIYQQQmIKxQghhBBCYgrFCCGEEEJiCsUIIYQQQmIKxQghhBBCYsqwmLVXURQAQGtra4xLQgghhJBgke22bMcDMSzESFtbGwCguLg4xiUhhBBCSKi0tbUhLS0t4O8W5URyZQjg8Xhw/PhxpKSkwGKxhO1/W1tbUVxcjKNHjyI1NTVs/0v84bmODjzP0YPnOnrwXEeHSJxnRVHQ1taGwsJCWK2BI0OGhWXEarVizJgxEfv/1NRU3uBRguc6OvA8Rw+e6+jBcx0dwn2e+7OISBjASgghhJCYQjFCCCGEkJgyqsWI0+nEQw89BKfTGeuijHh4rqMDz3P04LmOHjzX0SGW53lYBLASQgghZOQyqi0jhBBCCIk9FCOEEEIIiSkUI4QQQgiJKRQjhBBCCIkpo1qMPP744xg/fjzi4+Mxb948rF27NtZFGtb84Ac/gMVi0b3y8/N9vyuKgh/84AcoLCxEQkICzjrrLOzatSuGJR4+fPTRR7j44otRWFgIi8WC119/Xfd7MOe2u7sbd955J7Kzs5GUlIQvfelLOHbsWBSPYuhzovN8ww03+N3jp556qm4dnucT8/DDD+OUU05BSkoKcnNzcemll2Lfvn26dXhPh4dgzvVQuK9HrRh55ZVXcPfdd+PBBx/Etm3bsGTJEixbtgwVFRWxLtqwZubMmaiqqvK9duzY4fvtl7/8JVauXIlHH30UmzdvRn5+Ps4//3zf3EMkMC6XC3PmzMGjjz5q+nsw5/buu+/Ga6+9hpdffhnr1q1De3s7LrroIrjd7mgdxpDnROcZAC688ELdPf7WW2/pfud5PjFr1qzB7bffjg0bNmDVqlXo6+vD0qVL4XK5fOvwng4PwZxrYAjc18ooZcGCBcqKFSt0y6ZNm6Z897vfjVGJhj8PPfSQMmfOHNPfPB6Pkp+fr/z85z/3Levq6lLS0tKUP/7xj1Eq4cgAgPLaa6/5vgdzbpubmxW73a68/PLLvnUqKysVq9WqvPPOO1Er+3DCeJ4VRVGuv/565ZJLLgm4Dc/zwKitrVUAKGvWrFEUhfd0JDGea0UZGvf1qLSM9PT0YOvWrVi6dKlu+dKlS7F+/foYlWpkcODAARQWFmL8+PG46qqrUFZWBgA4fPgwqqurdefc6XTizDPP5DkfJMGc261bt6K3t1e3TmFhIUpLS3n+Q+TDDz9Ebm4upkyZgltuuQW1tbW+33ieB0ZLSwsAIDMzEwDv6UhiPNeSWN/Xo1KM1NfXw+12Iy8vT7c8Ly8P1dXVMSrV8GfhwoV49tln8e677+L//u//UF1djUWLFqGhocF3XnnOw08w57a6uhoOhwMZGRkB1yEnZtmyZXjhhRfwwQcf4De/+Q02b96Mc845B93d3QB4ngeCoii49957sXjxYpSWlgLgPR0pzM41MDTu62Exa2+ksFgsuu+KovgtI8GzbNky3+dZs2bhtNNOw8SJE/HXv/7VFwzFcx45BnJuef5DY/ny5b7PpaWlmD9/PkpKSvDmm2/isssuC7gdz3Ng7rjjDmzfvh3r1q3z+433dHgJdK6Hwn09Ki0j2dnZsNlsfoqutrbWT4mTgZOUlIRZs2bhwIEDvlE1POfhJ5hzm5+fj56eHjQ1NQVch4ROQUEBSkpKcODAAQA8z6Fy55134o033sDq1asxZswY33Le0+En0Lk2Ixb39agUIw6HA/PmzcOqVat0y1etWoVFixbFqFQjj+7ubuzZswcFBQUYP3488vPzdee8p6cHa9as4TkfJMGc23nz5sFut+vWqaqqws6dO3n+B0FDQwOOHj2KgoICADzPwaIoCu644w68+uqr+OCDDzB+/Hjd77ynw8eJzrUZMbmvwxIGOwx5+eWXFbvdrjz11FPK7t27lbvvvltJSkpSysvLY120Yct9992nfPjhh0pZWZmyYcMG5aKLLlJSUlJ85/TnP/+5kpaWprz66qvKjh07lKuvvlopKChQWltbY1zyoU9bW5uybds2Zdu2bQoAZeXKlcq2bduUI0eOKIoS3LldsWKFMmbMGOW9995TPv30U+Wcc85R5syZo/T19cXqsIYc/Z3ntrY25b777lPWr1+vHD58WFm9erVy2mmnKUVFRTzPIfLNb35TSUtLUz788EOlqqrK9+ro6PCtw3s6PJzoXA+V+3rUihFFUZTHHntMKSkpURwOh3LyySfrhjqR0Fm+fLlSUFCg2O12pbCwULnsssuUXbt2+X73eDzKQw89pOTn5ytOp1M544wzlB07dsSwxMOH1atXKwD8Xtdff72iKMGd287OTuWOO+5QMjMzlYSEBOWiiy5SKioqYnA0Q5f+znNHR4eydOlSJScnR7Hb7crYsWOV66+/3u8c8jyfGLNzDED5y1/+4luH93R4ONG5Hir3tcVbWEIIIYSQmDAqY0YIIYQQMnSgGCGEEEJITKEYIYQQQkhMoRghhBBCSEyhGCGEEEJITKEYIYQQQkhMoRghhBBCSEyhGCGEEEJITKEYIYQQQkhMoRghhBBCSEyhGCGEEEJITKEYIYQQQkhM+f9SW2Lnw8RCcAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])    # accuracy nin grafikte ki değişimi\n",
    "plt.plot(history.history['val_accuracy'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "394b693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derin öğrenme için datanın en az 1000 satır olması gerekiyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cadc087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5fd6d375",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle('kc_house.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c744396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>grade</th>\n",
       "      <th>view</th>\n",
       "      <th>basement</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>floors</th>\n",
       "      <th>age</th>\n",
       "      <th>renovated</th>\n",
       "      <th>...</th>\n",
       "      <th>zipcode_98146</th>\n",
       "      <th>zipcode_98148</th>\n",
       "      <th>zipcode_98155</th>\n",
       "      <th>zipcode_98166</th>\n",
       "      <th>zipcode_98168</th>\n",
       "      <th>zipcode_98177</th>\n",
       "      <th>zipcode_98178</th>\n",
       "      <th>zipcode_98188</th>\n",
       "      <th>zipcode_98198</th>\n",
       "      <th>zipcode_98199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1180</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>5.0625</td>\n",
       "      <td>2570</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>770</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>1960</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>1680</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrooms  bathrooms  sqft_living  grade  view  basement  waterfront  \\\n",
       "0         9     1.0000         1180      7     0         0           0   \n",
       "1         9     5.0625         2570      7     0         1           0   \n",
       "2         4     1.0000          770      6     0         0           0   \n",
       "3        16     9.0000         1960      7     0         1           0   \n",
       "4         9     4.0000         1680      8     0         0           0   \n",
       "\n",
       "   floors  age  renovated  ...  zipcode_98146  zipcode_98148  zipcode_98155  \\\n",
       "0     1.0   65          0  ...              0              0              0   \n",
       "1     2.0   69          1  ...              0              0              0   \n",
       "2     1.0   87          0  ...              0              0              0   \n",
       "3     1.0   55          0  ...              0              0              0   \n",
       "4     1.0   33          0  ...              0              0              0   \n",
       "\n",
       "   zipcode_98166  zipcode_98168  zipcode_98177  zipcode_98178  zipcode_98188  \\\n",
       "0              0              0              0              1              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98198  zipcode_98199  \n",
       "0              0              0  \n",
       "1              0              0  \n",
       "2              0              0  \n",
       "3              0              0  \n",
       "4              0              0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f87db143",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('price',axis=1)\n",
    "y=df[['price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1507229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=scale(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cdcdf90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()   \n",
    "model.add(Dense(120,activation='relu'))     #İlk 120 neronu bağlamış olduk,, relu veri önemliyse 1 in üstnde geliyor önemsizse es geçiyor\n",
    "model.add(Dense(80,activation='relu'))     # 2. layerı oluşturuyoruz\n",
    "model.add(Dense(64,activation='relu'))     # 3. layerı oluşturduk\n",
    "model.add(Dense(30,activation='relu'))      # 4. layerı oluşturduk\n",
    "model.add(Dense(4,activation='relu'))       # 5. layerı oluşturduk\n",
    "model.add(Dense(1))    # Son layerı oluşturduk Classifaction da sonuç evet veya hayır olacağı için sigmoid kullandık fakat burda fiyat tahmin ettiğimiz için sigmoidi sildik\n",
    "model.compile(loss='mse',optimizer='adam')   # Regression loss mse mean square error\n",
    "#son dense 1 kısmında kaç farklı sınıf varsa onu yazıyoruz mesela 4 farklı sınıf var kuş kedi köpek balık 4 yazıyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d99772ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "73fa5070",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "68ca0e02",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 277022441472.0000 - val_loss: 271207088128.0000\n",
      "Epoch 2/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 220487565312.0000 - val_loss: 24521412608.0000\n",
      "Epoch 3/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 16476502016.0000 - val_loss: 10333222912.0000\n",
      "Epoch 4/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 9273206784.0000 - val_loss: 9512604672.0000\n",
      "Epoch 5/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9053652992.0000 - val_loss: 9117257728.0000\n",
      "Epoch 6/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 8461303296.0000 - val_loss: 8872040448.0000\n",
      "Epoch 7/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8068302336.0000 - val_loss: 8690065408.0000\n",
      "Epoch 8/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8079002624.0000 - val_loss: 8575691776.0000\n",
      "Epoch 9/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 7863580160.0000 - val_loss: 8459908096.0000\n",
      "Epoch 10/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7792649216.0000 - val_loss: 8376233984.0000\n",
      "Epoch 11/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 7548657152.0000 - val_loss: 8313248768.0000\n",
      "Epoch 12/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7698088448.0000 - val_loss: 8261967360.0000\n",
      "Epoch 13/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7898707968.0000 - val_loss: 8230724608.0000\n",
      "Epoch 14/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 7569525248.0000 - val_loss: 8215928320.0000\n",
      "Epoch 15/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7530621440.0000 - val_loss: 8141802496.0000\n",
      "Epoch 16/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 7556672000.0000 - val_loss: 8223686656.0000\n",
      "Epoch 17/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7467077632.0000 - val_loss: 8113654784.0000\n",
      "Epoch 18/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 7026576384.0000 - val_loss: 8154725376.0000\n",
      "Epoch 19/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 7228133376.0000 - val_loss: 8037498368.0000\n",
      "Epoch 20/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7286573056.0000 - val_loss: 8143842304.0000\n",
      "Epoch 21/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7252994560.0000 - val_loss: 8095632896.0000\n",
      "Epoch 22/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7412311040.0000 - val_loss: 8021411840.0000\n",
      "Epoch 23/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 7270696448.0000 - val_loss: 8013099520.0000\n",
      "Epoch 24/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 7429215744.0000 - val_loss: 7988631552.0000\n",
      "Epoch 25/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 7299727872.0000 - val_loss: 8085945344.0000\n",
      "Epoch 26/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6895462912.0000 - val_loss: 7973814784.0000\n",
      "Epoch 27/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7326856192.0000 - val_loss: 7969752064.0000\n",
      "Epoch 28/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6983207936.0000 - val_loss: 7948503040.0000\n",
      "Epoch 29/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 7097984512.0000 - val_loss: 7991508480.0000\n",
      "Epoch 30/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6934938624.0000 - val_loss: 7942151168.0000\n",
      "Epoch 31/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6918914048.0000 - val_loss: 7957140992.0000\n",
      "Epoch 32/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6822484992.0000 - val_loss: 7902779904.0000\n",
      "Epoch 33/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6982031360.0000 - val_loss: 7902693376.0000\n",
      "Epoch 34/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 7013519872.0000 - val_loss: 7889021952.0000\n",
      "Epoch 35/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6877125632.0000 - val_loss: 7902352896.0000\n",
      "Epoch 36/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6740087296.0000 - val_loss: 7886657536.0000\n",
      "Epoch 37/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6903407616.0000 - val_loss: 7860186112.0000\n",
      "Epoch 38/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6959507968.0000 - val_loss: 7876574208.0000\n",
      "Epoch 39/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6967085568.0000 - val_loss: 7874565632.0000\n",
      "Epoch 40/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6903079424.0000 - val_loss: 7861108224.0000\n",
      "Epoch 41/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6880393728.0000 - val_loss: 7841839616.0000\n",
      "Epoch 42/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6806766592.0000 - val_loss: 7823057920.0000\n",
      "Epoch 43/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6920059904.0000 - val_loss: 7844884480.0000\n",
      "Epoch 44/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6870228992.0000 - val_loss: 7795271168.0000\n",
      "Epoch 45/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6646426112.0000 - val_loss: 7828818432.0000\n",
      "Epoch 46/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6680110592.0000 - val_loss: 7812269568.0000\n",
      "Epoch 47/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6821625856.0000 - val_loss: 7801781760.0000\n",
      "Epoch 48/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6518590464.0000 - val_loss: 7832541184.0000\n",
      "Epoch 49/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6802289152.0000 - val_loss: 7801383424.0000\n",
      "Epoch 50/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6766614016.0000 - val_loss: 7805556224.0000\n",
      "Epoch 51/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6765673984.0000 - val_loss: 7791334400.0000\n",
      "Epoch 52/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6749798912.0000 - val_loss: 7830752256.0000\n",
      "Epoch 53/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6462843392.0000 - val_loss: 7819155456.0000\n",
      "Epoch 54/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6734306816.0000 - val_loss: 7767258112.0000\n",
      "Epoch 55/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6726964224.0000 - val_loss: 7765979136.0000\n",
      "Epoch 56/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6746577408.0000 - val_loss: 7762877440.0000\n",
      "Epoch 57/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6694319616.0000 - val_loss: 7794266112.0000\n",
      "Epoch 58/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6948598784.0000 - val_loss: 7772233216.0000\n",
      "Epoch 59/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6467315200.0000 - val_loss: 7749685760.0000\n",
      "Epoch 60/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6794645504.0000 - val_loss: 7764935168.0000\n",
      "Epoch 61/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6532767232.0000 - val_loss: 7743867392.0000\n",
      "Epoch 62/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6443876864.0000 - val_loss: 7746059264.0000\n",
      "Epoch 63/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6670931968.0000 - val_loss: 7728181760.0000\n",
      "Epoch 64/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6428275200.0000 - val_loss: 7786618368.0000\n",
      "Epoch 65/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6538220032.0000 - val_loss: 7775373824.0000\n",
      "Epoch 66/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6543542272.0000 - val_loss: 7718986240.0000\n",
      "Epoch 67/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6764184064.0000 - val_loss: 7741304832.0000\n",
      "Epoch 68/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6628294656.0000 - val_loss: 7741227008.0000\n",
      "Epoch 69/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6636141568.0000 - val_loss: 7735449088.0000\n",
      "Epoch 70/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6452631040.0000 - val_loss: 7776515072.0000\n",
      "Epoch 71/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6860954112.0000 - val_loss: 7721490432.0000\n",
      "Epoch 72/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6424411648.0000 - val_loss: 7716833280.0000\n",
      "Epoch 73/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6636304896.0000 - val_loss: 7693858816.0000\n",
      "Epoch 74/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6612740096.0000 - val_loss: 7711457792.0000\n",
      "Epoch 75/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6588187648.0000 - val_loss: 7720125952.0000\n",
      "Epoch 76/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6248286720.0000 - val_loss: 7706486272.0000\n",
      "Epoch 77/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6904183808.0000 - val_loss: 7709260800.0000\n",
      "Epoch 78/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6641900544.0000 - val_loss: 7705603584.0000\n",
      "Epoch 79/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6513274368.0000 - val_loss: 7686787584.0000\n",
      "Epoch 80/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6300086784.0000 - val_loss: 7696044032.0000\n",
      "Epoch 81/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6560958976.0000 - val_loss: 7700546560.0000\n",
      "Epoch 82/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6402365440.0000 - val_loss: 7712795648.0000\n",
      "Epoch 83/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6485409280.0000 - val_loss: 7689398784.0000\n",
      "Epoch 84/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6575351808.0000 - val_loss: 7676620800.0000\n",
      "Epoch 85/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6508441600.0000 - val_loss: 7744142848.0000\n",
      "Epoch 86/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6817286656.0000 - val_loss: 7679704576.0000\n",
      "Epoch 87/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6327504896.0000 - val_loss: 7711586304.0000\n",
      "Epoch 88/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6244878848.0000 - val_loss: 7664861184.0000\n",
      "Epoch 89/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6358756352.0000 - val_loss: 7668604928.0000\n",
      "Epoch 90/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6501495296.0000 - val_loss: 7683456512.0000\n",
      "Epoch 91/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6651158016.0000 - val_loss: 7686583808.0000\n",
      "Epoch 92/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6611525632.0000 - val_loss: 7659795968.0000\n",
      "Epoch 93/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6488699392.0000 - val_loss: 7667346944.0000\n",
      "Epoch 94/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6631394816.0000 - val_loss: 7672409088.0000\n",
      "Epoch 95/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6447703040.0000 - val_loss: 7762559488.0000\n",
      "Epoch 96/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6252633088.0000 - val_loss: 7661069824.0000\n",
      "Epoch 97/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6223007232.0000 - val_loss: 7650237440.0000\n",
      "Epoch 98/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6398851584.0000 - val_loss: 7666953216.0000\n",
      "Epoch 99/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6410117632.0000 - val_loss: 7632167424.0000\n",
      "Epoch 100/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6355723264.0000 - val_loss: 7629146624.0000\n",
      "Epoch 101/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6457123328.0000 - val_loss: 7672544256.0000\n",
      "Epoch 102/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6163033088.0000 - val_loss: 7648185344.0000\n",
      "Epoch 103/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6468008448.0000 - val_loss: 7659302400.0000\n",
      "Epoch 104/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6305638400.0000 - val_loss: 7659514368.0000\n",
      "Epoch 105/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6392608768.0000 - val_loss: 7660901376.0000\n",
      "Epoch 106/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6264216576.0000 - val_loss: 7637640704.0000\n",
      "Epoch 107/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6510966784.0000 - val_loss: 7676795904.0000\n",
      "Epoch 108/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6184590336.0000 - val_loss: 7647720960.0000\n",
      "Epoch 109/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6139231232.0000 - val_loss: 7660295168.0000\n",
      "Epoch 110/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6361790976.0000 - val_loss: 7723148288.0000\n",
      "Epoch 111/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6337644032.0000 - val_loss: 7637956608.0000\n",
      "Epoch 112/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6299265024.0000 - val_loss: 7672055808.0000\n",
      "Epoch 113/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5944701952.0000 - val_loss: 7678922240.0000\n",
      "Epoch 114/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6425735168.0000 - val_loss: 7694478848.0000\n",
      "Epoch 115/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6202241024.0000 - val_loss: 7619453952.0000\n",
      "Epoch 116/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6264407040.0000 - val_loss: 7686514688.0000\n",
      "Epoch 117/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6432861696.0000 - val_loss: 7712838144.0000\n",
      "Epoch 118/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6425787392.0000 - val_loss: 7663659008.0000\n",
      "Epoch 119/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6038638592.0000 - val_loss: 7647126528.0000\n",
      "Epoch 120/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6194620928.0000 - val_loss: 7623887360.0000\n",
      "Epoch 121/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6190056448.0000 - val_loss: 7630130176.0000\n",
      "Epoch 122/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6119162368.0000 - val_loss: 7614865920.0000\n",
      "Epoch 123/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6127606272.0000 - val_loss: 7612583424.0000\n",
      "Epoch 124/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6242450944.0000 - val_loss: 7631390208.0000\n",
      "Epoch 125/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6259295232.0000 - val_loss: 7668243968.0000\n",
      "Epoch 126/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6080631296.0000 - val_loss: 7604887552.0000\n",
      "Epoch 127/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6258290688.0000 - val_loss: 7598204416.0000\n",
      "Epoch 128/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6028688896.0000 - val_loss: 7626890240.0000\n",
      "Epoch 129/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6193952256.0000 - val_loss: 7625026560.0000\n",
      "Epoch 130/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6169939456.0000 - val_loss: 7633729536.0000\n",
      "Epoch 131/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6247523328.0000 - val_loss: 7638982144.0000\n",
      "Epoch 132/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6030054400.0000 - val_loss: 7612550656.0000\n",
      "Epoch 133/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6268880896.0000 - val_loss: 7618037760.0000\n",
      "Epoch 134/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6369315840.0000 - val_loss: 7654601728.0000\n",
      "Epoch 135/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5925076992.0000 - val_loss: 7601633792.0000\n",
      "Epoch 136/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6465677312.0000 - val_loss: 7586514432.0000\n",
      "Epoch 137/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6019331072.0000 - val_loss: 7612779008.0000\n",
      "Epoch 138/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6235897344.0000 - val_loss: 7586191872.0000\n",
      "Epoch 139/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6064474624.0000 - val_loss: 7669778432.0000\n",
      "Epoch 140/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6155868160.0000 - val_loss: 7615947264.0000\n",
      "Epoch 141/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6064820224.0000 - val_loss: 7602387968.0000\n",
      "Epoch 142/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6261767168.0000 - val_loss: 7605492736.0000\n",
      "Epoch 143/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5946521600.0000 - val_loss: 7635029504.0000\n",
      "Epoch 144/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6305566720.0000 - val_loss: 7614175744.0000\n",
      "Epoch 145/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6018859520.0000 - val_loss: 7596132864.0000\n",
      "Epoch 146/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6145150976.0000 - val_loss: 7602632192.0000\n",
      "Epoch 147/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5811084288.0000 - val_loss: 7642528256.0000\n",
      "Epoch 148/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6202455552.0000 - val_loss: 7649271296.0000\n",
      "Epoch 149/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6014109184.0000 - val_loss: 7679149056.0000\n",
      "Epoch 150/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6036742656.0000 - val_loss: 7665147904.0000\n",
      "Epoch 151/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5893121536.0000 - val_loss: 7619699200.0000\n",
      "Epoch 152/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5923066368.0000 - val_loss: 7572482560.0000\n",
      "Epoch 153/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6018072064.0000 - val_loss: 7605961728.0000\n",
      "Epoch 154/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6041998336.0000 - val_loss: 7762337280.0000\n",
      "Epoch 155/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6004673536.0000 - val_loss: 7638627328.0000\n",
      "Epoch 156/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5877981696.0000 - val_loss: 7678122496.0000\n",
      "Epoch 157/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5880240640.0000 - val_loss: 7603302912.0000\n",
      "Epoch 158/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5988123648.0000 - val_loss: 7647049216.0000\n",
      "Epoch 159/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6057558528.0000 - val_loss: 7593417216.0000\n",
      "Epoch 160/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5847833088.0000 - val_loss: 7640248832.0000\n",
      "Epoch 161/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6083108864.0000 - val_loss: 7621253632.0000\n",
      "Epoch 162/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6024852992.0000 - val_loss: 7613380096.0000\n",
      "Epoch 163/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5944457728.0000 - val_loss: 7706014720.0000\n",
      "Epoch 164/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6211403264.0000 - val_loss: 7633720320.0000\n",
      "Epoch 165/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6028662272.0000 - val_loss: 7627661824.0000\n",
      "Epoch 166/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6048689152.0000 - val_loss: 7632596480.0000\n",
      "Epoch 167/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5854535168.0000 - val_loss: 7617268224.0000\n",
      "Epoch 168/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6008711680.0000 - val_loss: 7629978112.0000\n",
      "Epoch 169/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6200270336.0000 - val_loss: 7646557184.0000\n",
      "Epoch 170/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6106917888.0000 - val_loss: 7608844800.0000\n",
      "Epoch 171/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6016352768.0000 - val_loss: 7624839168.0000\n",
      "Epoch 172/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5885616128.0000 - val_loss: 7674836992.0000\n",
      "Epoch 173/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6241108992.0000 - val_loss: 7618220032.0000\n",
      "Epoch 174/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6094860800.0000 - val_loss: 7599843840.0000\n",
      "Epoch 175/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5816420864.0000 - val_loss: 7622529536.0000\n",
      "Epoch 176/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5780318720.0000 - val_loss: 7640474112.0000\n",
      "Epoch 177/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5849712128.0000 - val_loss: 7616321024.0000\n",
      "Epoch 178/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5950619136.0000 - val_loss: 7646310912.0000\n",
      "Epoch 179/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5711583232.0000 - val_loss: 7669800960.0000\n",
      "Epoch 180/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6014308864.0000 - val_loss: 7707464192.0000\n",
      "Epoch 181/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5769511936.0000 - val_loss: 7638218240.0000\n",
      "Epoch 182/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5967886848.0000 - val_loss: 7711321600.0000\n",
      "Epoch 183/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5831160832.0000 - val_loss: 7667295744.0000\n",
      "Epoch 184/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5845791232.0000 - val_loss: 7636365824.0000\n",
      "Epoch 185/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5762588672.0000 - val_loss: 7696795136.0000\n",
      "Epoch 186/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5639838720.0000 - val_loss: 7654812672.0000\n",
      "Epoch 187/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5577675776.0000 - val_loss: 7641686016.0000\n",
      "Epoch 188/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6090311168.0000 - val_loss: 7643344896.0000\n",
      "Epoch 189/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5896879616.0000 - val_loss: 7644187136.0000\n",
      "Epoch 190/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5964535808.0000 - val_loss: 7619462144.0000\n",
      "Epoch 191/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6077382656.0000 - val_loss: 7634677760.0000\n",
      "Epoch 192/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5830990336.0000 - val_loss: 7681424384.0000\n",
      "Epoch 193/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5915750400.0000 - val_loss: 7635662336.0000\n",
      "Epoch 194/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5833501696.0000 - val_loss: 7764246528.0000\n",
      "Epoch 195/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5766823936.0000 - val_loss: 7679425536.0000\n",
      "Epoch 196/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5974351872.0000 - val_loss: 7703992320.0000\n",
      "Epoch 197/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5703790080.0000 - val_loss: 7602215424.0000\n",
      "Epoch 198/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5759745024.0000 - val_loss: 7677084160.0000\n",
      "Epoch 199/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5862036480.0000 - val_loss: 7636734464.0000\n",
      "Epoch 200/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5775059456.0000 - val_loss: 7737818112.0000\n",
      "Epoch 201/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6000865280.0000 - val_loss: 7656264192.0000\n",
      "Epoch 202/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5861608448.0000 - val_loss: 7656359936.0000\n",
      "Epoch 203/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5788562432.0000 - val_loss: 7677426688.0000\n",
      "Epoch 204/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5728882688.0000 - val_loss: 7645686272.0000\n",
      "Epoch 205/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5742018048.0000 - val_loss: 7663507968.0000\n",
      "Epoch 206/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5772806656.0000 - val_loss: 7665006080.0000\n",
      "Epoch 207/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5837019648.0000 - val_loss: 7647401472.0000\n",
      "Epoch 208/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5933419008.0000 - val_loss: 7685075456.0000\n",
      "Epoch 209/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5874661376.0000 - val_loss: 7657084928.0000\n",
      "Epoch 210/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5756860928.0000 - val_loss: 7650703872.0000\n",
      "Epoch 211/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5723807232.0000 - val_loss: 7692564992.0000\n",
      "Epoch 212/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5883041792.0000 - val_loss: 7710138368.0000\n",
      "Epoch 213/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5931966464.0000 - val_loss: 7687562752.0000\n",
      "Epoch 214/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5685584896.0000 - val_loss: 7657129472.0000\n",
      "Epoch 215/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5936849408.0000 - val_loss: 7666888704.0000\n",
      "Epoch 216/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5733923840.0000 - val_loss: 7691092992.0000\n",
      "Epoch 217/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5721148416.0000 - val_loss: 7661682688.0000\n",
      "Epoch 218/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5628964352.0000 - val_loss: 7629042688.0000\n",
      "Epoch 219/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5780509696.0000 - val_loss: 7658987520.0000\n",
      "Epoch 220/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5969594880.0000 - val_loss: 7632792064.0000\n",
      "Epoch 221/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5855086080.0000 - val_loss: 7620395008.0000\n",
      "Epoch 222/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5971158528.0000 - val_loss: 7685038592.0000\n",
      "Epoch 223/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5721656320.0000 - val_loss: 7682389504.0000\n",
      "Epoch 224/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5686860800.0000 - val_loss: 7700514304.0000\n",
      "Epoch 225/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5789308928.0000 - val_loss: 7662403072.0000\n",
      "Epoch 226/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5721750528.0000 - val_loss: 7648368640.0000\n",
      "Epoch 227/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5706765312.0000 - val_loss: 7725836800.0000\n",
      "Epoch 228/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5637044736.0000 - val_loss: 7689194496.0000\n",
      "Epoch 229/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5547139072.0000 - val_loss: 7692715520.0000\n",
      "Epoch 230/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5912166912.0000 - val_loss: 7662146560.0000\n",
      "Epoch 231/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5817372160.0000 - val_loss: 7686540288.0000\n",
      "Epoch 232/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5781448704.0000 - val_loss: 7657908224.0000\n",
      "Epoch 233/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5660843520.0000 - val_loss: 7702900224.0000\n",
      "Epoch 234/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5709078016.0000 - val_loss: 7657349632.0000\n",
      "Epoch 235/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5576196096.0000 - val_loss: 7663591424.0000\n",
      "Epoch 236/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5785658880.0000 - val_loss: 7640796672.0000\n",
      "Epoch 237/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5746261504.0000 - val_loss: 7670213120.0000\n",
      "Epoch 238/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5600944128.0000 - val_loss: 7688770560.0000\n",
      "Epoch 239/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5496949248.0000 - val_loss: 7650473984.0000\n",
      "Epoch 240/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5656039424.0000 - val_loss: 7665453056.0000\n",
      "Epoch 241/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5587686400.0000 - val_loss: 7657661440.0000\n",
      "Epoch 242/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5565711360.0000 - val_loss: 7725578752.0000\n",
      "Epoch 243/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5847819776.0000 - val_loss: 7809933824.0000\n",
      "Epoch 244/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5707625984.0000 - val_loss: 7668509696.0000\n",
      "Epoch 245/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5651513856.0000 - val_loss: 7666290176.0000\n",
      "Epoch 246/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5678223872.0000 - val_loss: 7680178176.0000\n",
      "Epoch 247/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5754129408.0000 - val_loss: 7675824128.0000\n",
      "Epoch 248/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5755179008.0000 - val_loss: 7689906176.0000\n",
      "Epoch 249/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5430782976.0000 - val_loss: 7704579072.0000\n",
      "Epoch 250/250\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5684367360.0000 - val_loss: 7638414336.0000\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train, epochs=250,batch_size=128,validation_data=(x_test,y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "817e2b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "tahmin=model.predict(x_test)    # test dosyasından yeni değerleri tahmin ettiriyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "66cef2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9c431a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8507851329718039"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,tahmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cfccdcc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87398.02037640395"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,tahmin)**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1a6d20ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# çok hatalı çıktı burda nöron sayılarını değiştirebiiriz veya epoch değerini arttırabiliriz regressionda sigmoid olmayacak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "01ec8b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama.com dan setup ettik\n",
    "# Sonra ollama sitesinde aradığımız dil modelini yazıp kodu kopyalayıp terminalde bu kodu yazdığımızda offline şekilde bu dil modelini kullanabiliriz\n",
    "# ollama run llama3.2-vision:11b-instruct-q8_0  bunu kurduk ve deepsek  ollama run deepseek-r1 bunu kurduk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "72590549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('cars.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1bbfd439",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('Price',axis=True)\n",
    "y=df[['Price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c4ada085",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.get_dummies(x,drop_first=True)  # Yazı olan stünları rakama çeviriyorz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b0546389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "74b67138",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c2912bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()   \n",
    "model.add(Dense(64,activation='relu'))     #İlk 120 neronu bağlamış olduk,, relu veri önemliyse 1 in üstnde geliyor önemsizse es geçiyor\n",
    "model.add(Dense(128,activation='relu'))     # 2. layerı oluşturuyoruz\n",
    "model.add(Dense(256,activation='relu'))     # 3. layerı oluşturduk\n",
    "model.add(Dense(64,activation='relu'))      # 4. layerı oluşturduk\n",
    "model.add(Dense(32,activation='relu'))       # 5. layerı oluşturduk\n",
    "model.add(Dense(1))    # Son layerı oluşturduk Classifaction da sonuç evet veya hayır olacağı için sigmoid kullandık fakat burda fiyat tahmin ettiğimiz için sigmoidi sildik\n",
    "model.compile(loss='mse',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2dd2cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stoping  = En optimum epocu bulmaya yarar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f707084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ba3dd177",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop=EarlyStopping(monitor='val_loss',patience=10)   # 10 a kadar sabret sonra early stopping çalıştır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "537aa987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 7042609664.0000 - val_loss: 8063011328.0000\n",
      "Epoch 2/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 7178664960.0000 - val_loss: 8181268480.0000\n",
      "Epoch 3/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 7056420352.0000 - val_loss: 7988701696.0000\n",
      "Epoch 4/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 6807123456.0000 - val_loss: 7972537344.0000\n",
      "Epoch 5/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 7205625856.0000 - val_loss: 8798734336.0000\n",
      "Epoch 6/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6797082112.0000 - val_loss: 8041080320.0000\n",
      "Epoch 7/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 7037370368.0000 - val_loss: 7867946496.0000\n",
      "Epoch 8/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6595655168.0000 - val_loss: 8083630592.0000\n",
      "Epoch 9/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 7073758720.0000 - val_loss: 7863197696.0000\n",
      "Epoch 10/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6664116224.0000 - val_loss: 7923034112.0000\n",
      "Epoch 11/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6496136192.0000 - val_loss: 8082526208.0000\n",
      "Epoch 12/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 6802473984.0000 - val_loss: 8077759488.0000\n",
      "Epoch 13/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6482070016.0000 - val_loss: 8056784896.0000\n",
      "Epoch 14/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6714841600.0000 - val_loss: 7810268672.0000\n",
      "Epoch 15/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6705711616.0000 - val_loss: 7967824896.0000\n",
      "Epoch 16/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6600897536.0000 - val_loss: 7914497024.0000\n",
      "Epoch 17/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6625411584.0000 - val_loss: 7926339584.0000\n",
      "Epoch 18/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6487279104.0000 - val_loss: 7943258624.0000\n",
      "Epoch 19/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6301858816.0000 - val_loss: 7953901568.0000\n",
      "Epoch 20/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6627378688.0000 - val_loss: 7986761216.0000\n",
      "Epoch 21/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6587246080.0000 - val_loss: 8047949824.0000\n",
      "Epoch 22/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6486165504.0000 - val_loss: 8005178368.0000\n",
      "Epoch 23/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6389300736.0000 - val_loss: 7959054336.0000\n",
      "Epoch 24/30\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 6310413824.0000 - val_loss: 7844777472.0000\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=30,batch_size=32,callbacks=[early_stop],verbose=1)\n",
    "# early stop ile 3 te durdu bu 30 la 3 arasında bir fark yok demek epochs için en optimumu bulunca duruyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e7648d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "tahmin=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "eae9476b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8183404317720572"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(tahmin,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "19ef8f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Başarı oranını arttırmak için layer sayını değiştirebiliriz veya araya layer ekleyebiiriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "76ca1541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deeplearning de keras ve pytorch var keras çok kısa fakat pytorch daha uzun kod yazmamız gerekiyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c74de8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
